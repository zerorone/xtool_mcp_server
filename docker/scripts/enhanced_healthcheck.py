#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆå¥åº·æ£€æŸ¥è„šæœ¬ - æ”¯æŒæ–‡ä»¶å¤„ç†ä¼˜åŒ–å’Œç›‘æ§åŠŸèƒ½æ£€æŸ¥
"""

import json
import os
import subprocess
import sys
import time


def check_process():
    """æ£€æŸ¥ä¸»æœåŠ¡å™¨è¿›ç¨‹æ˜¯å¦è¿è¡Œ"""
    try:
        result = subprocess.run(["pgrep", "-f", "server.py"], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            return True, "æœåŠ¡å™¨è¿›ç¨‹æ­£å¸¸è¿è¡Œ"
        return False, f"è¿›ç¨‹æ£€æŸ¥å¤±è´¥: {result.stderr}"
    except Exception as e:
        return False, f"è¿›ç¨‹æ£€æŸ¥å¼‚å¸¸: {e}"


def check_python_imports():
    """æ£€æŸ¥å…³é”® Python æ¨¡å—æ˜¯å¦å¯ä»¥å¯¼å…¥"""
    critical_modules = [
        "mcp",
        "google.genai",
        "openai",
        "pydantic",
        "dotenv",
        # å¢å¼ºåŠŸèƒ½ç›¸å…³æ¨¡å—
        "asyncio",
        "threading",
        "hashlib",
        "sqlite3",
    ]

    failed_modules = []
    for module in critical_modules:
        try:
            __import__(module)
        except ImportError as e:
            failed_modules.append(f"{module}: {e}")
        except Exception as e:
            failed_modules.append(f"{module}: æ„å¤–é”™è¯¯ {e}")

    if failed_modules:
        return False, f"æ¨¡å—å¯¼å…¥å¤±è´¥: {', '.join(failed_modules)}"
    return True, f"æ‰€æœ‰ {len(critical_modules)} ä¸ªå…³é”®æ¨¡å—å¯¼å…¥æˆåŠŸ"


def check_directories():
    """æ£€æŸ¥å…³é”®ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”å¯å†™"""
    directories = [
        "/app/logs",
        "/app/.zen_memory",
        "/app/.zen_memory/file_cache",
        "/app/.zen_memory/workflow_states",
        "/app/tmp",
    ]

    failed_dirs = []
    for dir_path in directories:
        try:
            if not os.path.exists(dir_path):
                os.makedirs(dir_path, exist_ok=True)

            # æµ‹è¯•å†™æƒé™
            test_file = os.path.join(dir_path, ".health_check")
            with open(test_file, "w") as f:
                f.write("health_check")
            os.remove(test_file)

        except Exception as e:
            failed_dirs.append(f"{dir_path}: {e}")

    if failed_dirs:
        return False, f"ç›®å½•æ£€æŸ¥å¤±è´¥: {', '.join(failed_dirs)}"
    return True, f"æ‰€æœ‰ {len(directories)} ä¸ªç›®å½•å¯è®¿é—®"


def check_environment():
    """æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®"""
    # API å¯†é’¥æ£€æŸ¥
    api_keys = [
        "GEMINI_API_KEY",
        "GOOGLE_API_KEY",
        "OPENAI_API_KEY",
        "XAI_API_KEY",
        "DIAL_API_KEY",
        "OPENROUTER_API_KEY",
        "CUSTOM_API_KEY",
    ]

    valid_keys = []
    for key in api_keys:
        value = os.getenv(key)
        if value and len(value.strip()) >= 10:
            valid_keys.append(key)

    if not valid_keys:
        return False, "æœªæ‰¾åˆ°æœ‰æ•ˆçš„ API å¯†é’¥"

    # æ£€æŸ¥ä¼˜åŒ–åŠŸèƒ½é…ç½®
    optimization_enabled = os.getenv("ZEN_FILE_OPTIMIZATION_ENABLED", "true").lower() == "true"
    persistence_enabled = os.getenv("ZEN_WORKFLOW_PERSISTENCE_ENABLED", "true").lower() == "true"

    config_info = {
        "api_keys_count": len(valid_keys),
        "file_optimization": optimization_enabled,
        "workflow_persistence": persistence_enabled,
        "log_level": os.getenv("LOG_LEVEL", "INFO"),
    }

    return True, f"ç¯å¢ƒé…ç½®æ­£å¸¸: {json.dumps(config_info)}"


def check_enhanced_features():
    """æ£€æŸ¥å¢å¼ºåŠŸèƒ½æ˜¯å¦å¯ç”¨"""
    try:
        # æµ‹è¯•æ–‡ä»¶å¤„ç†ä¼˜åŒ–
        sys.path.append("/app")
        from utils.enhanced_file_processor import get_enhanced_file_processor
        from utils.file_processing_integration import get_file_processing_integration
        from utils.workflow_memory_fix import get_workflow_manager

        # åˆå§‹åŒ–ç»„ä»¶
        processor = get_enhanced_file_processor()
        integration = get_file_processing_integration()
        workflow_manager = get_workflow_manager()

        # è·å–çŠ¶æ€
        cache_stats = processor.get_cache_stats()
        workflow_stats = workflow_manager.get_global_stats()

        status = {
            "file_processor": "å¯ç”¨",
            "cache_items": cache_stats["cache_stats"]["memory_cache"]["items"]
            + cache_stats["cache_stats"]["disk_cache"]["items"],
            "workflow_manager": "å¯ç”¨",
            "active_workflows": workflow_stats["active_workflows"],
            "persistence_enabled": workflow_stats.get("persistence_enabled", False),
        }

        return True, f"å¢å¼ºåŠŸèƒ½æ£€æŸ¥é€šè¿‡: {json.dumps(status)}"

    except Exception as e:
        return False, f"å¢å¼ºåŠŸèƒ½æ£€æŸ¥å¤±è´¥: {e}"


def check_monitoring_endpoints():
    """æ£€æŸ¥ç›‘æ§ç«¯ç‚¹æ˜¯å¦å¯ç”¨"""
    try:
        sys.path.append("/app")
        from tools.file_optimization_monitor import FileOptimizationMonitorTool
        from tools.workflow_monitor import WorkflowMonitorTool

        # å®ä¾‹åŒ–ç›‘æ§å·¥å…·
        workflow_monitor = WorkflowMonitorTool()
        file_monitor = FileOptimizationMonitorTool()

        # éªŒè¯å·¥å…·åç§°
        assert workflow_monitor.get_name() == "workflow_monitor"
        assert file_monitor.get_name() == "file_optimization_monitor"

        return True, "ç›‘æ§ç«¯ç‚¹å¯ç”¨"

    except Exception as e:
        return False, f"ç›‘æ§ç«¯ç‚¹æ£€æŸ¥å¤±è´¥: {e}"


def check_storage_backends():
    """æ£€æŸ¥å­˜å‚¨åç«¯æ˜¯å¦æ­£å¸¸"""
    try:
        # æ£€æŸ¥ SQLite æ•°æ®åº“
        db_path = "/app/.zen_memory/workflow_states.db"
        if os.path.exists(db_path):
            import sqlite3

            conn = sqlite3.connect(db_path, timeout=5.0)
            cursor = conn.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
            table_count = cursor.fetchone()[0]
            conn.close()

            return True, f"SQLite åç«¯æ­£å¸¸ï¼ŒåŒ…å« {table_count} ä¸ªè¡¨"
        else:
            return True, "SQLite åç«¯å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åˆå§‹åŒ–"

    except Exception as e:
        return False, f"å­˜å‚¨åç«¯æ£€æŸ¥å¤±è´¥: {e}"


def main():
    """ä¸»å¥åº·æ£€æŸ¥å‡½æ•°"""
    # æ£€æŸ¥æ˜¯å¦ä¸ºå¢å¼ºæ¨¡å¼
    enhanced_mode = "--enhanced" in sys.argv

    # åŸºç¡€æ£€æŸ¥
    basic_checks = [
        ("è¿›ç¨‹çŠ¶æ€", check_process),
        ("Python æ¨¡å—", check_python_imports),
        ("ç›®å½•æƒé™", check_directories),
        ("ç¯å¢ƒé…ç½®", check_environment),
    ]

    # å¢å¼ºæ£€æŸ¥
    enhanced_checks = [
        ("å¢å¼ºåŠŸèƒ½", check_enhanced_features),
        ("ç›‘æ§ç«¯ç‚¹", check_monitoring_endpoints),
        ("å­˜å‚¨åç«¯", check_storage_backends),
    ]

    all_checks = basic_checks + (enhanced_checks if enhanced_mode else [])

    results = []
    failed_checks = []

    print(f"ğŸ¥ å¼€å§‹å¥åº·æ£€æŸ¥ ({'å¢å¼ºæ¨¡å¼' if enhanced_mode else 'åŸºç¡€æ¨¡å¼'})")
    print("=" * 60)

    for check_name, check_func in all_checks:
        try:
            start_time = time.time()
            success, message = check_func()
            duration = time.time() - start_time

            status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
            print(f"{status} {check_name}: {message} ({duration:.3f}s)")

            results.append({"name": check_name, "success": success, "message": message, "duration": duration})

            if not success:
                failed_checks.append(check_name)

        except Exception as e:
            print(f"âŒ {check_name}: æ£€æŸ¥å¼‚å¸¸ - {e}")
            failed_checks.append(check_name)
            results.append({"name": check_name, "success": False, "message": f"æ£€æŸ¥å¼‚å¸¸: {e}", "duration": 0})

    print("=" * 60)

    # ç”Ÿæˆæ€»ç»“
    total_checks = len(all_checks)
    passed_checks = total_checks - len(failed_checks)
    success_rate = (passed_checks / total_checks) * 100

    print(f"ğŸ“Š æ£€æŸ¥ç»“æœ: {passed_checks}/{total_checks} é€šè¿‡ ({success_rate:.1f}%)")

    if failed_checks:
        print(f"âŒ å¤±è´¥çš„æ£€æŸ¥: {', '.join(failed_checks)}")

        # å†™å…¥è¯¦ç»†æ—¥å¿—
        try:
            log_path = "/app/logs/health_check.json"
            with open(log_path, "w") as f:
                json.dump(
                    {
                        "timestamp": time.time(),
                        "enhanced_mode": enhanced_mode,
                        "success_rate": success_rate,
                        "failed_checks": failed_checks,
                        "results": results,
                    },
                    f,
                    indent=2,
                )
            print(f"ğŸ“ è¯¦ç»†æ—¥å¿—å·²ä¿å­˜åˆ°: {log_path}")
        except Exception as e:
            print(f"âš ï¸  æ— æ³•ä¿å­˜æ—¥å¿—: {e}")

        sys.exit(1)
    else:
        print("ğŸ‰ æ‰€æœ‰å¥åº·æ£€æŸ¥é€šè¿‡ï¼")
        sys.exit(0)


if __name__ == "__main__":
    main()

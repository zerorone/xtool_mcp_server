# Zen MCP Server 智能记忆增强与思维工具箱系统 - 完整实施计划 v2.0

## 🎯 项目愿景与目标

### 核心愿景
将 Zen MCP Server 升级为具有**专家级思维灵魂**的智能开发助手，通过深度集成25种思维模式和三层记忆系统，实现真正的AI智慧伙伴。

### 系统目标
1. **思维智能化**：集成25种专家思维模式，实现多维度深度分析
2. **记忆持久化**：三层记忆体系（全局/项目/会话），智能存储和检索
3. **任务自动化**：TODO驱动开发，智能任务分支管理
4. **环境感知化**：自动识别项目环境，智能路径推荐
5. **学习进化性**：从每次交互中学习，持续优化响应质量

## 📊 系统架构设计

### 整体架构图
```
┌─────────────────────────────────────────────────────────────┐
│                    Zen MCP Server 增强系统                    │
├─────────────────────────────────────────────────────────────┤
│                      触发与协调层                              │
│  ┌─────────────┐  ┌──────────────┐  ┌──────────────┐       │
│  │ 自动触发器  │  │ 上下文管理器  │  │  任务协调器   │       │
│  └─────────────┘  └──────────────┘  └──────────────┘       │
├─────────────────────────────────────────────────────────────┤
│                      核心功能层                                │
│  ┌─────────────────────────┐  ┌─────────────────────┐       │
│  │    增强记忆系统          │  │   思维工具箱系统     │       │
│  │  ├─ 全局记忆            │  │  ├─ 25种思维模式    │       │
│  │  ├─ 项目记忆            │  │  ├─ 智能模式选择    │       │
│  │  └─ 会话记忆            │  │  └─ 深度分析引擎    │       │
│  └─────────────────────────┘  └─────────────────────┘       │
│  ┌─────────────────────────┐  ┌─────────────────────┐       │
│  │    任务管理系统          │  │   路径智能系统       │       │
│  │  ├─ TODO解析器          │  │  ├─ 环境检测器      │       │
│  │  ├─ 主线维护器          │  │  ├─ 路径记忆器      │       │
│  │  └─ 分支管理器          │  │  └─ 智能推荐器      │       │
│  └─────────────────────────┘  └─────────────────────┘       │
├─────────────────────────────────────────────────────────────┤
│                      基础设施层                                │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐    │
│  │ 存储引擎  │  │ 索引系统  │  │ 缓存系统  │  │ 日志系统  │    │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘    │
└─────────────────────────────────────────────────────────────┘
```

### 核心组件详解

#### 1. 增强记忆系统
- **三层记忆架构**：全局偏好 → 项目特定 → 会话临时
- **智能索引**：多维度索引支持快速检索
- **记忆衰减**：基于访问频率和时间的智能衰减
- **模式记忆**：成功的思维模式组合持久化

#### 2. 思维工具箱系统
- **25种专家思维模式**：完整的思维模式库
- **智能激活引擎**：基于上下文自动选择最佳模式
- **组合优化**：多模式协同分析
- **深度控制**：浅层到专家级的灵活深度

#### 3. 任务管理系统
- **TODO文件解析**：智能解析和跟踪任务进度
- **主线保持**：确保不偏离主要任务
- **分支管理**：临时任务的智能分支和回归
- **上下文切换**：无缝的任务上下文切换

#### 4. 路径智能系统
- **环境自动检测**：虚拟环境、项目结构识别
- **智能路径推荐**：基于文件类型和项目结构
- **学习优化**：从用户行为中学习路径偏好

## 🚀 详细实施计划

### 第一阶段：核心基础设施（Day 1-3）

#### 1.1 增强记忆系统实现

```python
# utils/enhanced_memory.py
"""增强版记忆系统 - 集成思维模式和智能管理"""

import json
import os
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple, Set
from collections import defaultdict, Counter
from utils.conversation_memory import ConversationMemory
import numpy as np

class EnhancedMemory(ConversationMemory):
    """增强版记忆系统 - 支持三层记忆、思维模式学习和智能管理"""
    
    def __init__(self):
        super().__init__()
        
        # 记忆存储配置
        self.memory_base = Path(os.getenv("WORKSPACE_ROOT", ".")) / ".zen_memory"
        self.memory_base.mkdir(exist_ok=True)
        
        # 初始化存储文件
        self.storage_files = {
            "global": self.memory_base / "global_memory.json",
            "project": self.memory_base / "project_memory.json",
            "thinking": self.memory_base / "thinking_patterns.json",
            "paths": self.memory_base / "path_memory.json",
            "todo": self.memory_base / "todo_state.json"
        }
        
        # 加载所有持久化数据
        self.memories = {
            "global": self._load_memory_file(self.storage_files["global"]),
            "project": self._load_memory_file(self.storage_files["project"]),
            "session": {}  # 会话记忆不持久化
        }
        
        # 初始化各子系统
        self._init_thinking_system()
        self._init_path_system()
        self._init_todo_system()
        self._init_indexing_system()
        self._init_learning_system()
    
    def _init_thinking_system(self):
        """初始化思维模式系统"""
        thinking_data = self._load_memory_file(self.storage_files["thinking"])
        
        # 思维模式效果追踪
        self.pattern_effectiveness = defaultdict(lambda: {
            "success_count": 0,
            "total_count": 0,
            "avg_quality": 0.0,
            "problem_types": Counter(),
            "combinations": Counter(),
            "last_used": None
        })
        
        if "pattern_effectiveness" in thinking_data:
            for pattern, data in thinking_data["pattern_effectiveness"].items():
                self.pattern_effectiveness[pattern].update(data)
        
        # 思维模式组合记录
        self.successful_combinations = thinking_data.get("successful_combinations", [])
        
        # 问题-模式映射学习
        self.problem_pattern_mapping = defaultdict(Counter)
        if "problem_patterns" in thinking_data:
            for problem_type, patterns in thinking_data["problem_patterns"].items():
                self.problem_pattern_mapping[problem_type].update(patterns)
    
    def _init_path_system(self):
        """初始化路径智能系统"""
        path_data = self._load_memory_file(self.storage_files["paths"])
        
        self.path_memory = {
            "virtual_envs": path_data.get("virtual_envs", {}),
            "project_structures": path_data.get("project_structures", {}),
            "file_patterns": path_data.get("file_patterns", {}),
            "command_contexts": path_data.get("command_contexts", {}),
            "common_locations": path_data.get("common_locations", defaultdict(list))
        }
        
        # 路径使用频率追踪
        self.path_usage = defaultdict(int)
        if "path_usage" in path_data:
            self.path_usage.update(path_data["path_usage"])
    
    def _init_todo_system(self):
        """初始化TODO管理系统"""
        todo_data = self._load_memory_file(self.storage_files["todo"])
        
        self.todo_manager = {
            "main_thread": todo_data.get("main_thread", []),
            "branches": todo_data.get("branches", {}),
            "current_context": todo_data.get("current_context", "main"),
            "task_history": todo_data.get("task_history", []),
            "completed_tasks": todo_data.get("completed_tasks", []),
            "task_dependencies": todo_data.get("task_dependencies", {})
        }
        
        # 任务模式学习
        self.task_patterns = todo_data.get("task_patterns", {
            "average_completion_time": {},
            "common_blockers": [],
            "success_patterns": []
        })
    
    def _init_indexing_system(self):
        """初始化智能索引系统"""
        self.indices = {
            "by_tag": defaultdict(set),
            "by_type": defaultdict(set),
            "by_pattern": defaultdict(set),
            "by_timestamp": defaultdict(set),
            "by_quality": defaultdict(set),
            "by_frequency": defaultdict(int)
        }
        
        # 重建所有索引
        self._rebuild_all_indices()
    
    def _init_learning_system(self):
        """初始化学习优化系统"""
        self.learning_metrics = {
            "recall_precision": [],  # 召回精确度历史
            "pattern_success_rate": defaultdict(list),  # 模式成功率
            "user_satisfaction": [],  # 用户满意度（隐式）
            "optimization_history": []  # 优化历史
        }
    
    # ========== 核心记忆操作 ==========
    
    def save_enhanced_memory(self, content: Any, metadata: Dict[str, Any]) -> str:
        """保存增强记忆，包含思维模式和质量评分"""
        memory_id = self._generate_memory_id()
        
        memory_item = {
            "id": memory_id,
            "content": content,
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "type": metadata.get("type", "general"),
                "tags": metadata.get("tags", []),
                "thinking_modes": metadata.get("thinking_modes", []),
                "quality_score": metadata.get("quality_score", 0.5),
                "context": metadata.get("context", {}),
                "source": metadata.get("source", "user_interaction")
            },
            "usage": {
                "access_count": 0,
                "last_accessed": None,
                "usefulness_score": 0.5,
                "decay_factor": 1.0
            }
        }
        
        # 决定存储层级
        memory_type = self._determine_memory_type(memory_item)
        
        # 存储到对应层级
        if memory_type not in self.memories:
            memory_type = "session"
        
        if memory_id not in self.memories[memory_type]:
            self.memories[memory_type][memory_id] = memory_item
        
        # 更新索引
        self._update_indices(memory_item, memory_type)
        
        # 更新思维模式效果
        if metadata.get("thinking_modes"):
            self._update_pattern_learning(
                metadata["thinking_modes"],
                metadata.get("quality_score", 0.5),
                metadata.get("problem_type", "general")
            )
        
        # 持久化
        self._persist_memory(memory_type)
        
        return memory_id
    
    def recall_with_thinking(self, query: str, context: Dict[str, Any]) -> List[Dict]:
        """基于查询和思维上下文智能召回记忆"""
        # 提取查询特征
        query_features = self._extract_query_features(query, context)
        
        # 多策略召回
        candidates = []
        
        # 1. 关键词匹配
        keyword_matches = self._keyword_based_recall(query_features["keywords"])
        candidates.extend(keyword_matches)
        
        # 2. 思维模式匹配
        if "thinking_modes" in context:
            pattern_matches = self._pattern_based_recall(context["thinking_modes"])
            candidates.extend(pattern_matches)
        
        # 3. 上下文相似度匹配
        context_matches = self._context_based_recall(query_features, context)
        candidates.extend(context_matches)
        
        # 4. 时间相关性匹配
        if context.get("temporal_relevance"):
            temporal_matches = self._temporal_based_recall(context["temporal_window"])
            candidates.extend(temporal_matches)
        
        # 去重和评分
        unique_candidates = self._deduplicate_candidates(candidates)
        scored_candidates = self._score_and_rank(unique_candidates, query_features, context)
        
        # 更新访问统计
        for candidate in scored_candidates[:10]:  # 只更新前10个
            self._update_access_stats(candidate["id"], candidate["memory_type"])
        
        # 学习反馈
        self._learn_from_recall(query_features, scored_candidates)
        
        return scored_candidates
    
    # ========== 路径智能功能 ==========
    
    def detect_and_learn_environment(self, project_path: str) -> Dict[str, Any]:
        """检测并学习项目环境"""
        project_path = Path(project_path)
        environment_info = {
            "project_root": str(project_path),
            "detected_at": datetime.now().isoformat(),
            "virtual_env": None,
            "project_type": None,
            "structure": {},
            "dependencies": []
        }
        
        # 检测虚拟环境
        venv_info = self._detect_virtual_environment(project_path)
        if venv_info:
            environment_info["virtual_env"] = venv_info
            self.path_memory["virtual_envs"][str(project_path)] = venv_info
        
        # 分析项目结构
        structure_info = self._analyze_project_structure(project_path)
        environment_info["structure"] = structure_info
        self.path_memory["project_structures"][str(project_path)] = structure_info
        
        # 检测项目类型
        project_type = self._detect_project_type(project_path, structure_info)
        environment_info["project_type"] = project_type
        
        # 保存环境记忆
        self.save_enhanced_memory(
            content=environment_info,
            metadata={
                "type": "environment",
                "tags": ["project", "setup", project_type],
                "quality_score": 0.9
            }
        )
        
        # 持久化路径记忆
        self._save_memory_file(self.storage_files["paths"], self.path_memory)
        
        return environment_info
    
    def get_smart_file_location(self, filename: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """智能推荐文件创建位置"""
        suggestions = {
            "primary": None,
            "alternatives": [],
            "reasoning": []
        }
        
        file_ext = Path(filename).suffix
        project_root = Path(context.get("project_root", "."))
        
        # 基于项目结构的推荐
        if str(project_root) in self.path_memory["project_structures"]:
            structure = self.path_memory["project_structures"][str(project_root)]
            
            # 查找相似文件的位置模式
            similar_files = self._find_similar_files(filename, structure)
            if similar_files:
                common_dir = self._find_common_directory(similar_files)
                suggestions["primary"] = str(project_root / common_dir / filename)
                suggestions["reasoning"].append(f"类似文件通常在 {common_dir}")
        
        # 基于文件类型的智能推荐
        type_suggestions = self._get_type_based_suggestions(file_ext, project_root)
        suggestions["alternatives"].extend(type_suggestions)
        
        # 基于使用频率的推荐
        frequent_paths = self._get_frequent_paths_for_type(file_ext)
        if frequent_paths:
            suggestions["alternatives"].extend(frequent_paths[:3])
            suggestions["reasoning"].append("基于历史使用频率")
        
        # 如果没有主推荐，使用第一个备选
        if not suggestions["primary"] and suggestions["alternatives"]:
            suggestions["primary"] = suggestions["alternatives"][0]
            suggestions["alternatives"] = suggestions["alternatives"][1:]
        
        # 默认推荐
        if not suggestions["primary"]:
            suggestions["primary"] = str(project_root / filename)
            suggestions["reasoning"].append("默认项目根目录")
        
        # 学习用户选择
        self._learn_path_preference(filename, suggestions["primary"], context)
        
        return suggestions
    
    # ========== TODO管理功能 ==========
    
    def parse_and_manage_todo(self, todo_path: str) -> Dict[str, Any]:
        """解析TODO文件并建立任务管理体系"""
        todo_path = Path(todo_path)
        
        if not todo_path.exists():
            return {"error": "TODO file not found", "path": str(todo_path)}
        
        # 解析TODO内容
        parsed_tasks = self._parse_todo_file(todo_path)
        
        # 分析任务结构
        task_structure = self._analyze_task_structure(parsed_tasks)
        
        # 更新主线任务
        self.todo_manager["main_thread"] = task_structure["main_tasks"]
        self.todo_manager["task_dependencies"] = task_structure["dependencies"]
        
        # 识别任务模式
        patterns = self._identify_task_patterns(parsed_tasks)
        self.task_patterns.update(patterns)
        
        # 创建任务记忆
        self.save_enhanced_memory(
            content={
                "todo_file": str(todo_path),
                "task_count": len(parsed_tasks),
                "structure": task_structure,
                "parsed_at": datetime.now().isoformat()
            },
            metadata={
                "type": "todo_parsing",
                "tags": ["todo", "task_management"],
                "quality_score": 0.95
            }
        )
        
        # 持久化TODO状态
        self._save_memory_file(self.storage_files["todo"], self.todo_manager)
        
        return {
            "status": "success",
            "main_tasks": len(task_structure["main_tasks"]),
            "total_tasks": len(parsed_tasks),
            "current_context": self.todo_manager["current_context"],
            "patterns_identified": len(patterns)
        }
    
    def create_intelligent_branch(self, reason: str, context: Dict[str, Any]) -> str:
        """智能创建任务分支"""
        # 分析分支必要性
        branch_analysis = self._analyze_branch_necessity(reason, context)
        
        if not branch_analysis["should_branch"]:
            return None
        
        # 生成分支信息
        branch_id = f"branch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        branch_name = self._generate_branch_name(reason, context)
        
        branch_info = {
            "id": branch_id,
            "name": branch_name,
            "reason": reason,
            "created_at": datetime.now().isoformat(),
            "parent_context": self.todo_manager["current_context"],
            "expected_duration": branch_analysis["expected_duration"],
            "auto_return": branch_analysis["auto_return"],
            "tasks": [],
            "context_snapshot": self._create_context_snapshot()
        }
        
        # 创建分支
        self.todo_manager["branches"][branch_id] = branch_info
        self.todo_manager["current_context"] = branch_id
        
        # 记录分支创建
        self.save_enhanced_memory(
            content={
                "action": "branch_created",
                "branch": branch_info,
                "main_task_interrupted": self._get_current_main_task()
            },
            metadata={
                "type": "task_branching",
                "tags": ["todo", "branch", "context_switch"],
                "thinking_modes": ["task_planning", "priority_assessment"]
            }
        )
        
        # 持久化
        self._save_memory_file(self.storage_files["todo"], self.todo_manager)
        
        return branch_id
    
    def smart_return_to_main(self) -> Dict[str, Any]:
        """智能返回主线，带上下文恢复"""
        current_context = self.todo_manager["current_context"]
        
        if current_context == "main":
            return {"status": "already_on_main"}
        
        if current_context not in self.todo_manager["branches"]:
            return {"status": "error", "message": "Invalid branch context"}
        
        branch = self.todo_manager["branches"][current_context]
        
        # 总结分支工作
        branch_summary = self._summarize_branch_work(branch)
        
        # 保存分支完成记忆
        self.save_enhanced_memory(
            content={
                "branch_completed": branch,
                "summary": branch_summary,
                "duration": self._calculate_duration(branch["created_at"])
            },
            metadata={
                "type": "branch_completion",
                "tags": ["todo", "branch", "completion"],
                "quality_score": branch_summary.get("completion_quality", 0.7)
            }
        )
        
        # 标记分支完成
        branch["completed_at"] = datetime.now().isoformat()
        branch["summary"] = branch_summary
        
        # 恢复主线上下文
        self.todo_manager["current_context"] = "main"
        
        # 获取主线任务状态
        main_task_status = self._get_main_task_status()
        
        # 持久化
        self._save_memory_file(self.storage_files["todo"], self.todo_manager)
        
        return {
            "status": "returned_to_main",
            "branch_summary": branch_summary,
            "main_task_status": main_task_status,
            "next_action": self._suggest_next_action()
        }
    
    # ========== 思维模式学习 ==========
    
    def _update_pattern_learning(self, modes: List[str], quality: float, problem_type: str):
        """更新思维模式学习数据"""
        # 更新单个模式效果
        for mode in modes:
            stats = self.pattern_effectiveness[mode]
            stats["total_count"] += 1
            if quality > 0.7:  # 成功阈值
                stats["success_count"] += 1
            
            # 更新平均质量（移动平均）
            alpha = 0.1  # 学习率
            stats["avg_quality"] = (1 - alpha) * stats["avg_quality"] + alpha * quality
            
            # 更新问题类型分布
            stats["problem_types"][problem_type] += 1
            stats["last_used"] = datetime.now().isoformat()
        
        # 更新模式组合效果
        if len(modes) > 1 and quality > 0.8:  # 组合成功阈值更高
            combination = tuple(sorted(modes))
            self.successful_combinations.append({
                "modes": combination,
                "quality": quality,
                "problem_type": problem_type,
                "timestamp": datetime.now().isoformat()
            })
            
            # 只保留最近的1000个成功组合
            if len(self.successful_combinations) > 1000:
                self.successful_combinations = self.successful_combinations[-1000:]
        
        # 更新问题-模式映射
        self.problem_pattern_mapping[problem_type][tuple(modes)] += quality
        
        # 持久化学习数据
        self._persist_thinking_patterns()
    
    def get_recommended_thinking_modes(self, problem: str, context: Dict[str, Any]) -> List[str]:
        """基于学习推荐最佳思维模式组合"""
        recommendations = []
        
        # 1. 基于问题类型的历史成功模式
        problem_type = self._classify_problem_type(problem, context)
        if problem_type in self.problem_pattern_mapping:
            type_patterns = self.problem_pattern_mapping[problem_type]
            # 获取该问题类型下最成功的模式组合
            best_patterns = sorted(type_patterns.items(), key=lambda x: x[1], reverse=True)[:3]
            for pattern, score in best_patterns:
                recommendations.extend(list(pattern))
        
        # 2. 基于单个模式的整体表现
        high_performing_modes = []
        for mode, stats in self.pattern_effectiveness.items():
            if stats["total_count"] > 5 and stats["avg_quality"] > 0.75:
                success_rate = stats["success_count"] / stats["total_count"]
                if success_rate > 0.7:
                    high_performing_modes.append((mode, stats["avg_quality"]))
        
        # 按质量排序并添加到推荐
        high_performing_modes.sort(key=lambda x: x[1], reverse=True)
        recommendations.extend([mode for mode, _ in high_performing_modes[:3]])
        
        # 3. 基于最近的成功组合
        recent_successes = [
            combo for combo in self.successful_combinations[-50:]
            if combo["quality"] > 0.85
        ]
        for combo in recent_successes[-10:]:
            recommendations.extend(combo["modes"])
        
        # 去重并限制数量
        unique_recommendations = []
        seen = set()
        for mode in recommendations:
            if mode not in seen:
                seen.add(mode)
                unique_recommendations.append(mode)
                if len(unique_recommendations) >= 5:
                    break
        
        return unique_recommendations
    
    # ========== 辅助方法 ==========
    
    def _determine_memory_type(self, memory_item: Dict) -> str:
        """智能决定记忆应该存储在哪一层"""
        content = memory_item["content"]
        metadata = memory_item["metadata"]
        
        # 规则基础的分类
        if any(tag in metadata["tags"] for tag in ["preference", "setting", "always", "never"]):
            return "global"
        
        if any(tag in metadata["tags"] for tag in ["project", "architecture", "decision", "convention"]):
            return "project"
        
        # 基于内容的智能分类
        if isinstance(content, str):
            content_lower = content.lower()
            if any(keyword in content_lower for keyword in ["always", "prefer", "my style", "i like"]):
                return "global"
            if any(keyword in content_lower for keyword in ["this project", "in this codebase", "here we"]):
                return "project"
        
        # 基于质量分数的分类
        if metadata.get("quality_score", 0) > 0.9 and metadata.get("source") == "user_feedback":
            return "global"  # 高质量的用户反馈应该全局记住
        
        # 默认为会话级别
        return "session"
    
    def _calculate_memory_relevance(self, memory: Dict, query_features: Dict, context: Dict) -> float:
        """计算记忆与当前查询的相关度"""
        relevance_score = 0.0
        
        # 1. 关键词匹配度
        memory_text = str(memory["content"]).lower()
        keyword_matches = sum(1 for kw in query_features["keywords"] if kw in memory_text)
        relevance_score += keyword_matches * 0.2
        
        # 2. 思维模式匹配度
        if "thinking_modes" in context and "thinking_modes" in memory["metadata"]:
            mode_overlap = set(context["thinking_modes"]) & set(memory["metadata"]["thinking_modes"])
            relevance_score += len(mode_overlap) * 0.3
        
        # 3. 时间相关性（最近的记忆更相关）
        memory_time = datetime.fromisoformat(memory["metadata"]["timestamp"])
        time_diff = datetime.now() - memory_time
        time_factor = 1.0 / (1.0 + time_diff.days * 0.1)  # 随时间衰减
        relevance_score += time_factor * 0.2
        
        # 4. 使用频率和有用性
        usage_score = memory["usage"]["usefulness_score"] * memory["usage"]["access_count"] * 0.01
        relevance_score += min(usage_score, 0.3)  # 上限0.3
        
        # 5. 上下文相似度
        if "context" in memory["metadata"] and context:
            context_similarity = self._calculate_context_similarity(
                memory["metadata"]["context"], 
                context
            )
            relevance_score += context_similarity * 0.2
        
        # 应用衰减因子
        relevance_score *= memory["usage"]["decay_factor"]
        
        return min(relevance_score, 1.0)  # 确保不超过1.0
    
    def _generate_memory_id(self) -> str:
        """生成唯一的记忆ID"""
        timestamp = datetime.now().isoformat()
        random_str = os.urandom(8).hex()
        return hashlib.sha256(f"{timestamp}_{random_str}".encode()).hexdigest()[:16]
    
    def _persist_memory(self, memory_type: str):
        """持久化特定类型的记忆"""
        if memory_type in ["global", "project"]:
            self._save_memory_file(
                self.storage_files[memory_type], 
                self.memories[memory_type]
            )
    
    def _persist_thinking_patterns(self):
        """持久化思维模式学习数据"""
        thinking_data = {
            "pattern_effectiveness": dict(self.pattern_effectiveness),
            "successful_combinations": self.successful_combinations,
            "problem_patterns": dict(self.problem_pattern_mapping),
            "last_updated": datetime.now().isoformat()
        }
        self._save_memory_file(self.storage_files["thinking"], thinking_data)
```

#### 1.2 思维工具箱实现

```python
# tools/workflow/thinking_enhanced.py
"""增强版思维工具箱 - 25种专家级思维模式"""

from typing import Dict, List, Optional, Tuple, Any
from tools.workflow.base_workflow import BaseWorkflowTool
from utils.enhanced_memory import EnhancedMemory
from tools.base_tool import ToolRequest, ToolOutput
import json
import re
from datetime import datetime
from collections import defaultdict, Counter

class EnhancedThinkingTool(BaseWorkflowTool):
    """集成25种专家思维模式的智能思考工具"""
    
    def __init__(self):
        super().__init__()
        self.memory_system = EnhancedMemory()
        
        # 初始化思维模式库
        self._init_thinking_modes()
        
        # 初始化触发系统
        self._init_trigger_system()
        
        # 初始化分析引擎
        self._init_analysis_engine()
    
    def _init_thinking_modes(self):
        """初始化完整的25种思维模式"""
        self.thinking_modes = {
            # ===== 深度理解类 =====
            "socratic_questioning": {
                "name": "苏格拉底式提问",
                "category": "deep_understanding",
                "description": "通过连续提问揭示深层需求和隐含假设",
                "process": [
                    {"step": "表层理解", "prompt": "用户说了什么？字面意思是什么？"},
                    {"step": "目的探究", "prompt": "这解决了什么根本问题？真正的需求是什么？"},
                    {"step": "时机分析", "prompt": "为什么是现在？如果不做会有什么后果？"},
                    {"step": "方案质疑", "prompt": "有没有更简单的解决方案？现有方案的假设是什么？"},
                    {"step": "深层洞察", "prompt": "隐含的需求是什么？用户没说但很重要的是什么？"}
                ],
                "output_format": {
                    "surface_understanding": "表面需求",
                    "real_needs": "真实需求",
                    "hidden_assumptions": "隐含假设",
                    "alternative_solutions": "替代方案",
                    "key_insights": "关键洞察"
                },
                "suitable_for": ["需求分析", "产品设计", "问题定义", "方案评估"]
            },
            
            "five_whys": {
                "name": "5 Whys根因分析",
                "category": "deep_understanding",
                "description": "通过递进式追问找到问题根源",
                "process": [
                    {"step": "问题识别", "prompt": "明确描述表面问题是什么？"},
                    {"step": "第一层原因", "prompt": "为什么会出现这个问题？直接原因是什么？"},
                    {"step": "第二层原因", "prompt": "为什么会有上述原因？更深层的原因是什么？"},
                    {"step": "第三层原因", "prompt": "继续追问，这个原因背后的原因是什么？"},
                    {"step": "根本原因", "prompt": "持续深入直到找到根本原因"},
                    {"step": "因果验证", "prompt": "验证因果链：如果解决根因，问题会消失吗？"}
                ],
                "output_format": {
                    "problem_statement": "问题描述",
                    "causal_chain": ["原因1", "原因2", "...", "根本原因"],
                    "root_cause": "根本原因",
                    "verification": "因果链验证",
                    "solution_direction": "解决方向"
                },
                "suitable_for": ["故障排查", "质量改进", "流程优化", "事故分析"]
            },
            
            "first_principles": {
                "name": "第一性原理思维",
                "category": "deep_understanding",
                "description": "回归事物最基本的真理，重新思考和构建",
                "process": [
                    {"step": "现状分解", "prompt": "当前的解决方案包含哪些组成部分？"},
                    {"step": "假设识别", "prompt": "哪些是约定俗成？哪些是真正的限制？"},
                    {"step": "基本原理", "prompt": "这个问题的物理/逻辑/商业基本原理是什么？"},
                    {"step": "重新构建", "prompt": "从基本原理出发，如何重新设计解决方案？"},
                    {"step": "创新验证", "prompt": "新方案是否突破了原有限制？是否更接近本质？"}
                ],
                "output_format": {
                    "current_solution": "现有方案分解",
                    "assumptions": "识别的假设",
                    "fundamental_truths": "基本原理",
                    "new_approach": "创新方案",
                    "breakthrough_points": "突破点"
                },
                "suitable_for": ["创新设计", "成本优化", "突破性思考", "颠覆式创新"]
            },
            
            # ===== 结构化分析类 =====
            "mece_decomposition": {
                "name": "MECE原则分解",
                "category": "structured_analysis",
                "description": "相互独立、完全穷尽的结构化分解",
                "process": [
                    {"step": "目标定义", "prompt": "需要分解什么？分解的目的是什么？"},
                    {"step": "维度识别", "prompt": "可以从哪些维度进行分解？时间/空间/功能/流程？"},
                    {"step": "独立性检查", "prompt": "各子项之间是否有重叠？如何确保相互独立？"},
                    {"step": "完整性验证", "prompt": "是否覆盖了所有情况？有无遗漏？"},
                    {"step": "层级优化", "prompt": "分解的层级是否合理？需要进一步细分吗？"}
                ],
                "output_format": {
                    "decomposition_target": "分解目标",
                    "dimensions": "分解维度",
                    "structure": {
                        "level1": ["子项1", "子项2"],
                        "level2": {"子项1": ["细分1", "细分2"]}
                    },
                    "completeness_check": "完整性验证",
                    "independence_check": "独立性验证"
                },
                "suitable_for": ["项目规划", "问题分析", "组织设计", "工作分解"]
            },
            
            "pyramid_principle": {
                "name": "金字塔原理",
                "category": "structured_analysis",
                "description": "结论先行，层层支撑，逻辑递进",
                "process": [
                    {"step": "中心思想", "prompt": "核心观点/结论是什么？一句话说清楚"},
                    {"step": "支撑论点", "prompt": "支撑核心观点的3-5个关键论点是什么？"},
                    {"step": "论据组织", "prompt": "每个论点的具体论据和例证是什么？"},
                    {"step": "逻辑检验", "prompt": "纵向是否问答逻辑？横向是否归类清晰？"},
                    {"step": "SCQA引入", "prompt": "如何用情境-冲突-问题-答案引入？"}
                ],
                "output_format": {
                    "central_message": "中心思想",
                    "key_points": ["论点1", "论点2", "论点3"],
                    "supporting_evidence": {
                        "论点1": ["论据1", "论据2"],
                        "论点2": ["论据1", "论据2"]
                    },
                    "scqa_intro": {
                        "situation": "情境",
                        "complication": "冲突",
                        "question": "问题",
                        "answer": "答案"
                    }
                },
                "suitable_for": ["报告撰写", "方案汇报", "观点表达", "说服沟通"]
            },
            
            "mind_mapping": {
                "name": "思维导图法",
                "category": "structured_analysis",
                "description": "放射性思考，展现知识关联",
                "process": [
                    {"step": "中心主题", "prompt": "核心概念或问题是什么？"},
                    {"step": "主分支", "prompt": "围绕中心的5-7个主要方面是什么？"},
                    {"step": "细分延伸", "prompt": "每个主分支可以如何进一步细分？"},
                    {"step": "关联识别", "prompt": "不同分支之间有什么联系？"},
                    {"step": "重点标注", "prompt": "哪些是关键节点？优先级如何？"}
                ],
                "output_format": {
                    "central_topic": "中心主题",
                    "main_branches": ["分支1", "分支2", "分支3"],
                    "sub_branches": {
                        "分支1": ["子分支1", "子分支2"],
                        "分支2": ["子分支1", "子分支2"]
                    },
                    "cross_links": [{"from": "节点A", "to": "节点B", "relation": "关系"}],
                    "priorities": {"high": ["节点1"], "medium": ["节点2"], "low": ["节点3"]}
                },
                "suitable_for": ["知识整理", "创意发散", "复杂关系梳理", "学习笔记"]
            },
            
            # ===== 系统思考类 =====
            "systems_thinking": {
                "name": "系统思维分析",
                "category": "systems_thinking",
                "description": "关注整体和部分的相互关系",
                "process": [
                    {"step": "系统边界", "prompt": "系统的边界在哪里？包含哪些要素？"},
                    {"step": "要素关系", "prompt": "要素之间如何相互作用？输入输出是什么？"},
                    {"step": "反馈回路", "prompt": "存在哪些正反馈和负反馈回路？"},
                    {"step": "瓶颈识别", "prompt": "系统的瓶颈和关键节点在哪里？"},
                    {"step": "涌现特性", "prompt": "整体表现出哪些单个部分没有的特性？"},
                    {"step": "演化预测", "prompt": "系统可能如何演化？有哪些可能的状态？"}
                ],
                "output_format": {
                    "system_boundary": "系统边界",
                    "elements": ["要素1", "要素2", "要素3"],
                    "relationships": [{"from": "要素1", "to": "要素2", "type": "关系类型"}],
                    "feedback_loops": {
                        "positive": ["增强回路1"],
                        "negative": ["平衡回路1"]
                    },
                    "bottlenecks": ["瓶颈1", "瓶颈2"],
                    "emergent_properties": ["涌现特性1", "涌现特性2"],
                    "evolution_scenarios": ["场景1", "场景2"]
                },
                "suitable_for": ["架构设计", "影响分析", "复杂问题", "生态设计"]
            },
            
            "value_chain": {
                "name": "价值链分析",
                "category": "systems_thinking",
                "description": "识别价值创造和传递的全过程",
                "process": [
                    {"step": "价值定义", "prompt": "什么是价值？对谁有价值？"},
                    {"step": "活动识别", "prompt": "哪些是主要活动？哪些是支持活动？"},
                    {"step": "价值流动", "prompt": "价值如何从一个环节流向下一个？"},
                    {"step": "成本分析", "prompt": "每个环节的成本是多少？价值增值多少？"},
                    {"step": "优化机会", "prompt": "哪里有优化空间？如何提升价值？"}
                ],
                "output_format": {
                    "value_definition": "价值定义",
                    "primary_activities": ["活动1", "活动2", "活动3"],
                    "support_activities": ["支持1", "支持2"],
                    "value_flow": [
                        {"activity": "活动1", "input_value": 100, "output_value": 150, "cost": 30}
                    ],
                    "optimization_opportunities": [
                        {"activity": "活动2", "opportunity": "自动化", "impact": "成本降低30%"}
                    ]
                },
                "suitable_for": ["业务优化", "成本控制", "流程改进", "竞争分析"]
            },
            
            "ecosystem_thinking": {
                "name": "生态系统思维",
                "category": "systems_thinking",
                "description": "从生态视角看待参与者关系",
                "process": [
                    {"step": "参与者识别", "prompt": "生态中有哪些参与者？各自的角色？"},
                    {"step": "价值交换", "prompt": "参与者之间如何交换价值？"},
                    {"step": "网络效应", "prompt": "存在哪些网络效应和正反馈？"},
                    {"step": "关键物种", "prompt": "谁是关键物种？谁是基石物种？"},
                    {"step": "演进路径", "prompt": "生态系统可能如何演进？"}
                ],
                "output_format": {
                    "participants": {
                        "producers": ["生产者1"],
                        "consumers": ["消费者1"],
                        "enablers": ["使能者1"]
                    },
                    "value_exchanges": [
                        {"from": "A", "to": "B", "value": "价值类型"}
                    ],
                    "network_effects": ["效应1", "效应2"],
                    "keystone_species": ["关键物种1"],
                    "evolution_path": ["阶段1", "阶段2", "阶段3"]
                },
                "suitable_for": ["平台设计", "商业生态", "合作策略", "生态构建"]
            },
            
            # ===== 创新思维类 =====
            "design_thinking": {
                "name": "设计思维",
                "category": "innovation",
                "description": "以人为本的创新方法论",
                "process": [
                    {"step": "共情理解", "prompt": "用户是谁？他们的需求、痛点、情感是什么？"},
                    {"step": "问题定义", "prompt": "真正要解决的问题是什么？POV陈述？"},
                    {"step": "创意构思", "prompt": "有哪些可能的解决方案？疯狂的想法？"},
                    {"step": "原型制作", "prompt": "如何快速验证？最小可行原型是什么？"},
                    {"step": "测试迭代", "prompt": "用户反馈如何？如何改进？"}
                ],
                "output_format": {
                    "user_insights": {
                        "needs": ["需求1", "需求2"],
                        "pain_points": ["痛点1", "痛点2"],
                        "emotions": ["情感1", "情感2"]
                    },
                    "problem_statement": "我们如何为[用户]解决[问题]以实现[目标]",
                    "ideas": {
                        "practical": ["实用想法1"],
                        "innovative": ["创新想法1"],
                        "wild": ["疯狂想法1"]
                    },
                    "prototype_plan": "原型方案",
                    "test_results": "测试结果和迭代方向"
                },
                "suitable_for": ["产品创新", "服务设计", "用户体验", "社会创新"]
            },
            
            "reverse_thinking": {
                "name": "逆向思维",
                "category": "innovation",
                "description": "从相反方向思考问题",
                "process": [
                    {"step": "常规思路", "prompt": "通常的思路和做法是什么？"},
                    {"step": "完全反转", "prompt": "如果完全相反会怎样？目标反转？"},
                    {"step": "假设挑战", "prompt": "如果关键假设不存在会怎样？"},
                    {"step": "失败分析", "prompt": "如果要故意失败，会怎么做？"},
                    {"step": "洞察提取", "prompt": "反向思考带来什么新洞察？"}
                ],
                "output_format": {
                    "conventional_approach": "常规方法",
                    "reversed_approach": "反向方法",
                    "challenged_assumptions": ["假设1被挑战", "假设2被挑战"],
                    "failure_analysis": "故意失败的方法",
                    "new_insights": ["洞察1", "洞察2"],
                    "innovative_solutions": ["创新方案1", "创新方案2"]
                },
                "suitable_for": ["创新突破", "问题预防", "风险识别", "策略制定"]
            },
            
            "analogical_thinking": {
                "name": "类比思维",
                "category": "innovation",
                "description": "通过相似性迁移解决方案",
                "process": [
                    {"step": "问题抽象", "prompt": "问题的本质特征是什么？"},
                    {"step": "领域搜索", "prompt": "哪些领域有类似的问题？"},
                    {"step": "案例分析", "prompt": "成功案例是如何解决的？"},
                    {"step": "映射转换", "prompt": "如何将解决方案映射到当前问题？"},
                    {"step": "适配调整", "prompt": "需要做哪些调整以适应当前情境？"}
                ],
                "output_format": {
                    "problem_abstraction": "问题本质",
                    "similar_domains": ["领域1", "领域2"],
                    "successful_cases": [
                        {"domain": "领域1", "solution": "解决方案", "key_insight": "关键洞察"}
                    ],
                    "mapping": {
                        "source_element": "原始元素",
                        "target_element": "目标元素",
                        "transformation": "转换方式"
                    },
                    "adapted_solution": "适配后的方案"
                },
                "suitable_for": ["创新设计", "问题解决", "知识迁移", "跨界创新"]
            },
            
            # ===== 决策分析类 =====
            "swot_analysis": {
                "name": "SWOT分析",
                "category": "decision_making",
                "description": "全面评估内外部因素",
                "process": [
                    {"step": "优势识别", "prompt": "内部优势是什么？核心竞争力？"},
                    {"step": "劣势分析", "prompt": "内部劣势是什么？短板在哪？"},
                    {"step": "机会扫描", "prompt": "外部机会有哪些？趋势是什么？"},
                    {"step": "威胁评估", "prompt": "外部威胁是什么？风险在哪？"},
                    {"step": "策略制定", "prompt": "SO/WO/ST/WT策略分别是什么？"}
                ],
                "output_format": {
                    "strengths": ["优势1", "优势2"],
                    "weaknesses": ["劣势1", "劣势2"],
                    "opportunities": ["机会1", "机会2"],
                    "threats": ["威胁1", "威胁2"],
                    "strategies": {
                        "SO": "发挥优势抓住机会",
                        "WO": "克服劣势抓住机会",
                        "ST": "利用优势规避威胁",
                        "WT": "减少劣势规避威胁"
                    }
                },
                "suitable_for": ["战略制定", "竞争分析", "项目评估", "个人规划"]
            },
            
            "decision_tree": {
                "name": "决策树分析",
                "category": "decision_making",
                "description": "可视化决策路径和结果",
                "process": [
                    {"step": "决策识别", "prompt": "需要做什么决策？有哪些选项？"},
                    {"step": "不确定性", "prompt": "每个选项面临哪些不确定性？"},
                    {"step": "概率评估", "prompt": "各种情况的概率是多少？"},
                    {"step": "结果预测", "prompt": "每条路径的最终结果是什么？"},
                    {"step": "期望计算", "prompt": "计算期望值，哪个选项最优？"}
                ],
                "output_format": {
                    "decision_points": ["决策1", "决策2"],
                    "options": {
                        "决策1": ["选项A", "选项B"]
                    },
                    "uncertainties": {
                        "选项A": [
                            {"event": "事件1", "probability": 0.6, "outcome": "结果1"}
                        ]
                    },
                    "expected_values": {
                        "选项A": 85,
                        "选项B": 72
                    },
                    "recommendation": "推荐选项A"
                },
                "suitable_for": ["投资决策", "项目选择", "风险评估", "资源分配"]
            },
            
            "cost_benefit": {
                "name": "成本效益分析",
                "category": "decision_making",
                "description": "量化评估投入产出比",
                "process": [
                    {"step": "成本识别", "prompt": "所有成本项是什么？直接/间接/机会成本？"},
                    {"step": "效益评估", "prompt": "所有收益是什么？有形/无形收益？"},
                    {"step": "时间价值", "prompt": "如何考虑时间价值？折现率？"},
                    {"step": "量化计算", "prompt": "NPV、ROI、回收期是多少？"},
                    {"step": "敏感分析", "prompt": "关键变量变化对结果的影响？"}
                ],
                "output_format": {
                    "costs": {
                        "direct": [{"item": "成本项1", "amount": 1000}],
                        "indirect": [{"item": "成本项2", "amount": 500}],
                        "opportunity": [{"item": "机会成本", "amount": 300}]
                    },
                    "benefits": {
                        "tangible": [{"item": "收益1", "amount": 2000}],
                        "intangible": [{"item": "品牌价值", "estimate": "高"}]
                    },
                    "financial_metrics": {
                        "NPV": 5000,
                        "ROI": "150%",
                        "payback_period": "2年"
                    },
                    "sensitivity": {
                        "critical_variables": ["变量1", "变量2"],
                        "impact_analysis": "变量1变化10%，NPV变化20%"
                    }
                },
                "suitable_for": ["投资评估", "项目审批", "资源配置", "方案比较"]
            },
            
            # ===== 优化改进类 =====
            "lean_thinking": {
                "name": "精益思维",
                "category": "optimization",
                "description": "消除浪费，创造价值",
                "process": [
                    {"step": "价值识别", "prompt": "什么是客户真正的价值？"},
                    {"step": "价值流图", "prompt": "价值如何流动？每步耗时？"},
                    {"step": "浪费识别", "prompt": "七大浪费在哪里？如何量化？"},
                    {"step": "流动优化", "prompt": "如何让价值流动更顺畅？"},
                    {"step": "持续改进", "prompt": "建立什么机制持续优化？"}
                ],
                "output_format": {
                    "customer_value": "客户价值定义",
                    "value_stream": [
                        {"step": "步骤1", "value_added": true, "time": 10, "wait_time": 5}
                    ],
                    "wastes_identified": {
                        "overproduction": "过度生产示例",
                        "waiting": "等待时间",
                        "transport": "不必要的运输",
                        "overprocessing": "过度加工",
                        "inventory": "库存积压",
                        "motion": "不必要的动作",
                        "defects": "缺陷率"
                    },
                    "improvements": ["改进1", "改进2"],
                    "kaizen_plan": "持续改进计划"
                },
                "suitable_for": ["流程优化", "效率提升", "成本降低", "质量改进"]
            },
            
            "pareto_principle": {
                "name": "帕累托原则（80/20法则）",
                "category": "optimization",
                "description": "识别关键少数，产生主要影响",
                "process": [
                    {"step": "数据收集", "prompt": "收集相关数据，确保完整准确"},
                    {"step": "分类排序", "prompt": "按影响程度排序，计算累积百分比"},
                    {"step": "关键识别", "prompt": "哪20%产生80%的影响？"},
                    {"step": "深入分析", "prompt": "为什么这些是关键？特征是什么？"},
                    {"step": "策略制定", "prompt": "如何集中资源优化关键部分？"}
                ],
                "output_format": {
                    "data_analysis": {
                        "total_items": 100,
                        "total_impact": 1000
                    },
                    "pareto_distribution": [
                        {"item": "项目1", "impact": 300, "cumulative_percent": 30}
                    ],
                    "vital_few": ["关键项1", "关键项2", "关键项3"],
                    "characteristics": "关键项的共同特征",
                    "optimization_strategy": "资源集中策略"
                },
                "suitable_for": ["问题优先级", "资源分配", "重点识别", "效果最大化"]
            },
            
            "constraint_theory": {
                "name": "约束理论（TOC）",
                "category": "optimization",
                "description": "系统的产出受限于最薄弱环节",
                "process": [
                    {"step": "约束识别", "prompt": "系统的瓶颈在哪里？如何确认？"},
                    {"step": "约束利用", "prompt": "如何充分利用约束资源？"},
                    {"step": "系统从属", "prompt": "其他部分如何配合约束？"},
                    {"step": "约束提升", "prompt": "如何提升约束的能力？"},
                    {"step": "循环改进", "prompt": "新的约束在哪里？继续优化"}
                ],
                "output_format": {
                    "current_constraint": "当前约束",
                    "constraint_utilization": "约束利用率",
                    "subordination_plan": "系统配合方案",
                    "elevation_options": [
                        {"option": "方案1", "cost": 1000, "capacity_increase": "20%"}
                    ],
                    "next_constraint": "预期的下一个约束"
                },
                "suitable_for": ["生产优化", "项目管理", "性能提升", "流程改进"]
            },
            
            # ===== 批判思考类 =====
            "critical_thinking": {
                "name": "批判性思维",
                "category": "critical_thinking",
                "description": "理性分析，独立判断",
                "process": [
                    {"step": "信息评估", "prompt": "信息来源可靠吗？证据充分吗？"},
                    {"step": "逻辑检验", "prompt": "推理过程严密吗？有逻辑谬误吗？"},
                    {"step": "偏见识别", "prompt": "存在什么偏见？如何影响判断？"},
                    {"step": "假设质疑", "prompt": "隐含假设是什么？合理吗？"},
                    {"step": "结论形成", "prompt": "基于分析，合理的结论是什么？"}
                ],
                "output_format": {
                    "information_quality": {
                        "sources": ["来源1可靠性: 高"],
                        "evidence_strength": "证据强度评估"
                    },
                    "logical_analysis": {
                        "reasoning_chain": "推理链",
                        "fallacies_found": ["逻辑谬误1"]
                    },
                    "biases_identified": ["确认偏见", "幸存者偏差"],
                    "assumptions_challenged": ["假设1: 不成立"],
                    "balanced_conclusion": "平衡的结论"
                },
                "suitable_for": ["信息评估", "决策验证", "风险识别", "真相追求"]
            },
            
            "occams_razor": {
                "name": "奥卡姆剃刀",
                "category": "critical_thinking",
                "description": "如无必要，勿增实体",
                "process": [
                    {"step": "方案列举", "prompt": "所有可能的解释或方案是什么？"},
                    {"step": "复杂度评估", "prompt": "每个方案的复杂度如何？假设多少？"},
                    {"step": "充分性检验", "prompt": "最简单的方案能充分解释吗？"},
                    {"step": "必要性分析", "prompt": "复杂元素真的必要吗？"},
                    {"step": "简化选择", "prompt": "选择最简单充分的方案"}
                ],
                "output_format": {
                    "all_explanations": [
                        {"explanation": "方案1", "complexity": 3, "assumptions": 2}
                    ],
                    "sufficiency_test": {
                        "simplest": "最简方案",
                        "is_sufficient": true,
                        "gaps": []
                    },
                    "unnecessary_elements": ["不必要的复杂性1"],
                    "recommended_solution": "推荐的简单方案"
                },
                "suitable_for": ["方案选择", "问题诊断", "设计简化", "理论构建"]
            },
            
            # ===== 创意发散类 =====
            "brainstorming": {
                "name": "头脑风暴法",
                "category": "creative_expansion",
                "description": "发散思维，延迟判断",
                "process": [
                    {"step": "问题明确", "prompt": "要解决什么问题？目标是什么？"},
                    {"step": "自由发散", "prompt": "不评判，追求数量，越多越好"},
                    {"step": "联想激发", "prompt": "基于已有想法，能联想到什么？"},
                    {"step": "狂野思考", "prompt": "最疯狂的想法是什么？"},
                    {"step": "整理归类", "prompt": "将想法分类整理，识别模式"}
                ],
                "output_format": {
                    "problem_statement": "问题陈述",
                    "ideas_raw": ["想法1", "想法2", "..."],
                    "idea_categories": {
                        "practical": ["实用想法"],
                        "innovative": ["创新想法"],
                        "wild": ["疯狂想法"]
                    },
                    "patterns_found": ["模式1", "模式2"],
                    "promising_directions": ["有潜力的方向1"]
                },
                "suitable_for": ["创意生成", "问题解决", "产品创新", "团队协作"]
            },
            
            "six_thinking_hats": {
                "name": "六顶思考帽",
                "category": "creative_expansion",
                "description": "平行思维，全面考虑",
                "process": [
                    {"step": "白帽思考", "prompt": "客观事实和数据是什么？"},
                    {"step": "红帽思考", "prompt": "直觉和情感告诉我们什么？"},
                    {"step": "黑帽思考", "prompt": "风险和问题在哪里？"},
                    {"step": "黄帽思考", "prompt": "积极面和价值是什么？"},
                    {"step": "绿帽思考", "prompt": "有什么创新想法和可能？"},
                    {"step": "蓝帽思考", "prompt": "如何组织思考过程？下一步？"}
                ],
                "output_format": {
                    "white_hat": {
                        "facts": ["事实1", "事实2"],
                        "data": ["数据1", "数据2"]
                    },
                    "red_hat": {
                        "feelings": ["感受1"],
                        "intuitions": ["直觉1"]
                    },
                    "black_hat": {
                        "risks": ["风险1"],
                        "problems": ["问题1"]
                    },
                    "yellow_hat": {
                        "benefits": ["好处1"],
                        "values": ["价值1"]
                    },
                    "green_hat": {
                        "ideas": ["创意1"],
                        "alternatives": ["替代方案1"]
                    },
                    "blue_hat": {
                        "process": "思考过程总结",
                        "next_steps": ["下一步1"]
                    }
                },
                "suitable_for": ["全面分析", "团队决策", "平衡思考", "复杂评估"]
            },
            
            # ===== 逻辑推理类 =====
            "inductive_deductive": {
                "name": "归纳与演绎",
                "category": "logical_reasoning",
                "description": "从特殊到一般，从一般到特殊",
                "process": [
                    {"step": "观察收集", "prompt": "具体案例和观察是什么？"},
                    {"step": "模式识别", "prompt": "案例中的共同模式是什么？"},
                    {"step": "规律提炼", "prompt": "能归纳出什么一般规律？"},
                    {"step": "演绎应用", "prompt": "将规律应用到新情况会怎样？"},
                    {"step": "验证调整", "prompt": "预测准确吗？规律需要调整吗？"}
                ],
                "output_format": {
                    "observations": ["观察1", "观察2", "观察3"],
                    "patterns": ["模式1", "模式2"],
                    "general_rule": "归纳出的一般规律",
                    "deductive_predictions": [
                        {"case": "新情况1", "prediction": "预测结果1"}
                    ],
                    "validation": {
                        "accuracy": "预测准确率",
                        "adjustments": "规律调整"
                    }
                },
                "suitable_for": ["规律发现", "理论应用", "预测分析", "科学研究"]
            },
            
            "hypothesis_driven": {
                "name": "假设驱动思维",
                "category": "logical_reasoning",
                "description": "先假设后验证，快速迭代",
                "process": [
                    {"step": "假设形成", "prompt": "基于现有信息，最可能的解释是什么？"},
                    {"step": "验证设计", "prompt": "如何验证这个假设？需要什么证据？"},
                    {"step": "数据收集", "prompt": "收集关键数据，不求完美"},
                    {"step": "假设检验", "prompt": "数据支持还是反驳假设？"},
                    {"step": "迭代优化", "prompt": "如何修正假设？下一个假设是什么？"}
                ],
                "output_format": {
                    "initial_hypothesis": "初始假设",
                    "validation_plan": {
                        "key_questions": ["关键问题1"],
                        "required_evidence": ["所需证据1"],
                        "validation_method": "验证方法"
                    },
                    "findings": {
                        "supporting": ["支持证据1"],
                        "contradicting": ["反驳证据1"]
                    },
                    "hypothesis_status": "假设状态：支持/反驳/需修正",
                    "next_hypothesis": "下一个假设"
                },
                "suitable_for": ["快速决策", "敏捷开发", "科学研究", "问题诊断"]
            },
            
            # ===== 场景规划类 =====
            "user_journey": {
                "name": "用户旅程映射",
                "category": "scenario_planning",
                "description": "从用户视角审视全过程",
                "process": [
                    {"step": "用户定义", "prompt": "用户是谁？目标和需求是什么？"},
                    {"step": "阶段划分", "prompt": "用户经历哪些阶段？"},
                    {"step": "触点识别", "prompt": "每个阶段的接触点是什么？"},
                    {"step": "情绪曲线", "prompt": "用户情绪如何变化？高低点在哪？"},
                    {"step": "机会发现", "prompt": "哪里有改进机会？痛点如何解决？"}
                ],
                "output_format": {
                    "user_persona": {
                        "demographics": "用户画像",
                        "goals": ["目标1", "目标2"],
                        "needs": ["需求1", "需求2"]
                    },
                    "journey_stages": ["认知", "考虑", "决策", "使用", "分享"],
                    "touchpoints": {
                        "认知": ["广告", "口碑"],
                        "考虑": ["官网", "评测"]
                    },
                    "emotion_curve": {
                        "认知": 0,
                        "考虑": 0.5,
                        "决策": -0.3,
                        "使用": 0.8
                    },
                    "opportunities": [
                        {"stage": "决策", "pain_point": "选择困难", "solution": "决策辅助工具"}
                    ]
                },
                "suitable_for": ["服务设计", "体验优化", "产品改进", "客户洞察"]
            }
        }
    
    def _init_trigger_system(self):
        """初始化智能触发系统"""
        # 关键词触发映射
        self.keyword_triggers = {
            "socratic_questioning": ["需求", "功能", "feature", "想要", "需要", "期望", "要求", "希望"],
            "five_whys": ["问题", "bug", "错误", "失败", "异常", "故障", "为什么", "原因"],
            "first_principles": ["本质", "根本", "原理", "基础", "核心", "创新", "突破", "重新"],
            "mece_decomposition": ["分解", "拆分", "breakdown", "任务", "计划", "组织", "结构", "分类"],
            "pyramid_principle": ["报告", "汇报", "总结", "表达", "沟通", "逻辑", "说服", "展示"],
            "mind_mapping": ["整理", "梳理", "关联", "brainstorm", "全景", "脉络", "关系", "联系"],
            "systems_thinking": ["系统", "架构", "整体", "全局", "影响", "生态", "关系", "相互"],
            "value_chain": ["价值", "流程", "效率", "优化", "成本", "收益", "价值链", "增值"],
            "ecosystem_thinking": ["生态", "平台", "网络效应", "协同", "共生", "参与者", "互动"],
            "design_thinking": ["设计", "用户体验", "创新", "原型", "迭代", "用户", "体验", "人性化"],
            "reverse_thinking": ["反向", "逆向", "相反", "如果不", "假如", "反过来", "颠倒"],
            "analogical_thinking": ["类似", "像", "参考", "借鉴", "对比", "相似", "类比", "比喻"],
            "swot_analysis": ["优势", "劣势", "机会", "威胁", "评估", "分析", "SWOT", "战略"],
            "decision_tree": ["决策", "选择", "如果", "分支", "概率", "风险", "选项", "路径"],
            "cost_benefit": ["成本", "收益", "投资回报", "ROI", "效益", "价值", "投入产出"],
            "lean_thinking": ["精益", "浪费", "效率", "改进", "优化", "流程", "价值流", "消除"],
            "pareto_principle": ["重点", "关键", "主要", "优先级", "80/20", "帕累托", "少数"],
            "constraint_theory": ["瓶颈", "约束", "限制", "产能", "吞吐量", "制约", "TOC"],
            "critical_thinking": ["质疑", "验证", "证据", "逻辑", "偏见", "假设", "批判", "客观"],
            "occams_razor": ["简化", "简单", "复杂", "精简", "本质", "奥卡姆", "必要性"],
            "brainstorming": ["创意", "点子", "方案", "可能性", "brainstorm", "想法", "创新"],
            "six_thinking_hats": ["全面", "角度", "视角", "立场", "平衡", "六顶帽子", "多角度"],
            "inductive_deductive": ["推理", "逻辑", "结论", "规律", "推导", "归纳", "演绎"],
            "hypothesis_driven": ["假设", "验证", "假如", "如果", "测试", "猜测", "推测"],
            "user_journey": ["用户", "体验", "流程", "触点", "旅程", "路径", "历程"]
        }
        
        # 场景触发映射
        self.scenario_triggers = {
            "需求分析": ["socratic_questioning", "first_principles", "design_thinking", "user_journey"],
            "问题解决": ["five_whys", "systems_thinking", "constraint_theory", "critical_thinking"],
            "创新设计": ["design_thinking", "reverse_thinking", "analogical_thinking", "brainstorming"],
            "项目规划": ["mece_decomposition", "value_chain", "pareto_principle", "decision_tree"],
            "决策制定": ["swot_analysis", "decision_tree", "cost_benefit", "six_thinking_hats"],
            "优化改进": ["lean_thinking", "pareto_principle", "constraint_theory", "value_chain"],
            "战略分析": ["swot_analysis", "ecosystem_thinking", "systems_thinking", "value_chain"],
            "批判评估": ["critical_thinking", "occams_razor", "hypothesis_driven", "six_thinking_hats"]
        }
        
        # 模式组合推荐
        self.pattern_combinations = {
            "deep_analysis": ["five_whys", "systems_thinking", "first_principles"],
            "innovation_kit": ["design_thinking", "reverse_thinking", "analogical_thinking"],
            "decision_toolkit": ["swot_analysis", "decision_tree", "cost_benefit"],
            "optimization_suite": ["lean_thinking", "constraint_theory", "pareto_principle"],
            "critical_review": ["critical_thinking", "occams_razor", "six_thinking_hats"],
            "strategic_planning": ["swot_analysis", "value_chain", "ecosystem_thinking"],
            "problem_solving": ["five_whys", "mece_decomposition", "hypothesis_driven"],
            "user_centered": ["design_thinking", "user_journey", "socratic_questioning"]
        }
    
    def _init_analysis_engine(self):
        """初始化分析引擎"""
        self.analysis_metrics = {
            "depth_levels": {
                "shallow": {"rounds": 2, "modes": 1, "detail": "low"},
                "medium": {"rounds": 5, "modes": 3, "detail": "medium"},
                "deep": {"rounds": 8, "modes": 4, "detail": "high"},
                "expert": {"rounds": 12, "modes": 5, "detail": "exhaustive"}
            },
            "quality_thresholds": {
                "insight_quality": 0.7,
                "pattern_confidence": 0.8,
                "recommendation_strength": 0.75
            }
        }
    
    def get_name(self) -> str:
        return "think"
    
    def get_description(self) -> str:
        return "25种专家级思维模式的智能思考工具，提供多维度深度分析"
    
    def get_system_prompt_name(self) -> str:
        return "thinking_enhanced"
    
    def get_workflow_prompt_name(self) -> str:
        return "thinking_workflow_enhanced"
    
    async def run_workflow(self, request: ToolRequest) -> ToolOutput:
        """执行增强的思维工作流"""
        try:
            problem = request.params.get("problem", "")
            mode = request.params.get("mode", "auto")
            depth = request.params.get("depth", "medium")
            context = request.params.get("context", {})
            
            # 获取记忆推荐
            memory_recommendations = self.memory_system.get_recommended_thinking_modes(
                problem, context
            )
            
            # 智能选择思维模式
            if mode == "auto":
                selected_modes = await self._intelligent_mode_selection(
                    problem, context, memory_recommendations
                )
            else:
                selected_modes = [mode] if isinstance(mode, str) else mode
            
            # 验证模式有效性
            selected_modes = [m for m in selected_modes if m in self.thinking_modes]
            
            if not selected_modes:
                selected_modes = ["systems_thinking", "first_principles"]
            
            # 收集增强的上下文
            enhanced_context = await self._gather_enhanced_context(problem, context)
            
            # 执行多模式分析
            analysis_results = {}
            for thinking_mode in selected_modes:
                self.update_confidence(0.2)  # 每个模式增加信心
                
                mode_result = await self._execute_thinking_mode(
                    mode=thinking_mode,
                    problem=problem,
                    context=enhanced_context,
                    depth=depth
                )
                
                analysis_results[thinking_mode] = mode_result
                
                # 检查是否需要专家介入
                if self.should_consult_expert():
                    expert_result = await self._consult_thinking_expert(
                        mode=thinking_mode,
                        analysis=mode_result,
                        problem=problem
                    )
                    analysis_results[f"{thinking_mode}_expert"] = expert_result
            
            # 综合多模式结果
            synthesis = await self._synthesize_thinking_results(
                analysis_results, problem, selected_modes
            )
            
            # 生成深度洞察
            insights = await self._generate_deep_insights(synthesis, enhanced_context)
            
            # 任务管理建议
            task_recommendations = await self._generate_task_recommendations(
                problem, insights, enhanced_context
            )
            
            # 保存思维模式效果
            quality_score = self._evaluate_thinking_quality(insights)
            self.memory_system.save_enhanced_memory(
                content={
                    "problem": problem,
                    "analysis": synthesis,
                    "insights": insights,
                    "recommendations": task_recommendations
                },
                metadata={
                    "thinking_modes": selected_modes,
                    "quality_score": quality_score,
                    "type": "thinking_analysis",
                    "tags": ["thinking", "analysis"] + selected_modes
                }
            )
            
            # 更新学习系统
            self.memory_system._update_pattern_learning(
                selected_modes,
                quality_score,
                self._classify_problem_type(problem)
            )
            
            return ToolOutput(
                status="success",
                content=json.dumps({
                    "thinking_modes_used": selected_modes,
                    "analysis_depth": depth,
                    "key_insights": insights["key_insights"],
                    "synthesis": synthesis,
                    "recommendations": {
                        "immediate_actions": task_recommendations["immediate"],
                        "strategic_considerations": task_recommendations["strategic"],
                        "task_management": task_recommendations["task_management"]
                    },
                    "patterns_discovered": insights.get("patterns", []),
                    "confidence_level": quality_score
                }, indent=2),
                metadata={
                    "thinking_modes": selected_modes,
                    "depth": depth,
                    "quality_score": quality_score
                }
            )
            
        except Exception as e:
            return ToolOutput(
                status="error",
                error=f"思维分析过程出错：{str(e)}"
            )
    
    async def _intelligent_mode_selection(self, problem: str, context: Dict, 
                                        memory_recommendations: List[str]) -> List[str]:
        """智能选择最适合的思维模式组合"""
        selected_modes = []
        problem_lower = problem.lower()
        
        # 1. 基于关键词匹配
        keyword_scores = defaultdict(int)
        for mode, keywords in self.keyword_triggers.items():
            for keyword in keywords:
                if keyword in problem_lower:
                    keyword_scores[mode] += 1
        
        # 2. 基于场景识别
        detected_scenario = self._detect_scenario(problem, context)
        scenario_modes = []
        if detected_scenario:
            scenario_modes = self.scenario_triggers.get(detected_scenario, [])
        
        # 3. 基于记忆推荐
        memory_modes = memory_recommendations[:3]
        
        # 4. 综合评分
        all_modes = set()
        
        # 添加关键词匹配的前3个
        keyword_top = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)[:3]
        all_modes.update([mode for mode, _ in keyword_top if _ > 0])
        
        # 添加场景推荐的前2个
        all_modes.update(scenario_modes[:2])
        
        # 添加记忆推荐
        all_modes.update(memory_modes)
        
        # 5. 根据问题复杂度确定模式数量
        complexity = self._assess_problem_complexity(problem, context)
        mode_count = {
            "simple": 2,
            "moderate": 3,
            "complex": 4,
            "very_complex": 5
        }.get(complexity, 3)
        
        # 6. 优先级排序
        prioritized_modes = []
        
        # 优先记忆推荐（已被验证有效）
        for mode in memory_modes:
            if mode in all_modes and mode not in prioritized_modes:
                prioritized_modes.append(mode)
        
        # 然后是场景推荐
        for mode in scenario_modes:
            if mode in all_modes and mode not in prioritized_modes:
                prioritized_modes.append(mode)
        
        # 最后是关键词匹配
        for mode, _ in keyword_top:
            if mode in all_modes and mode not in prioritized_modes:
                prioritized_modes.append(mode)
        
        # 7. 选择最终模式
        selected_modes = prioritized_modes[:mode_count]
        
        # 8. 确保至少有基础模式
        if len(selected_modes) < 2:
            defaults = ["systems_thinking", "first_principles", "mece_decomposition"]
            for default in defaults:
                if default not in selected_modes:
                    selected_modes.append(default)
                    if len(selected_modes) >= 2:
                        break
        
        return selected_modes
    
    async def _execute_thinking_mode(self, mode: str, problem: str, 
                                   context: Dict, depth: str) -> Dict:
        """执行特定思维模式的分析"""
        mode_config = self.thinking_modes.get(mode, {})
        
        if not mode_config:
            return {"error": f"Unknown thinking mode: {mode}"}
        
        results = {
            "mode": mode,
            "mode_name": mode_config["name"],
            "category": mode_config["category"],
            "process_results": [],
            "key_findings": [],
            "patterns": [],
            "recommendations": []
        }
        
        # 根据深度确定执行轮数
        depth_config = self.analysis_metrics["depth_levels"][depth]
        rounds = min(len(mode_config["process"]), depth_config["rounds"])
        
        # 执行思维流程
        for i, step in enumerate(mode_config["process"][:rounds]):
            step_result = await self._execute_thinking_step(
                mode=mode,
                step=step,
                problem=problem,
                context=context,
                previous_results=results["process_results"]
            )
            
            results["process_results"].append({
                "step_name": step["step"],
                "prompt": step["prompt"],
                "analysis": step_result.get("analysis", ""),
                "findings": step_result.get("findings", [])
            })
            
            # 提取关键发现
            if "findings" in step_result:
                results["key_findings"].extend(step_result["findings"])
        
        # 识别模式
        if len(results["key_findings"]) > 3:
            patterns = self._identify_patterns(results["key_findings"])
            results["patterns"] = patterns
        
        # 生成模式特定的建议
        results["recommendations"] = self._generate_mode_recommendations(
            mode, results["key_findings"], context
        )
        
        return results
    
    async def _synthesize_thinking_results(self, all_results: Dict, 
                                         problem: str, modes: List[str]) -> Dict:
        """综合多种思维模式的分析结果"""
        synthesis = {
            "problem": problem,
            "modes_applied": modes,
            "converging_insights": [],
            "unique_perspectives": [],
            "contradictions": [],
            "integrated_view": "",
            "confidence_distribution": {}
        }
        
        # 收集所有发现
        all_findings = []
        for mode, result in all_results.items():
            if "key_findings" in result:
                for finding in result["key_findings"]:
                    all_findings.append({
                        "mode": mode,
                        "finding": finding,
                        "category": result.get("category", "unknown")
                    })
        
        # 分析收敛点
        finding_clusters = self._cluster_findings(all_findings)
        
        for cluster_id, cluster in finding_clusters.items():
            if len(cluster["modes"]) >= 2:
                synthesis["converging_insights"].append({
                    "insight": cluster["representative"],
                    "supported_by": cluster["modes"],
                    "strength": len(cluster["modes"]) / len(modes),
                    "findings": cluster["findings"]
                })
            else:
                synthesis["unique_perspectives"].append({
                    "perspective": cluster["representative"],
                    "from_mode": cluster["modes"][0],
                    "category": cluster["category"]
                })
        
        # 识别矛盾
        contradictions = self._identify_contradictions(all_findings)
        synthesis["contradictions"] = contradictions
        
        # 生成综合视图
        synthesis["integrated_view"] = self._create_integrated_view(
            synthesis["converging_insights"],
            synthesis["unique_perspectives"],
            synthesis["contradictions"]
        )
        
        # 计算置信度分布
        for mode in modes:
            if mode in all_results:
                findings_count = len(all_results[mode].get("key_findings", []))
                synthesis["confidence_distribution"][mode] = min(findings_count * 0.1, 1.0)
        
        return synthesis
    
    async def _generate_deep_insights(self, synthesis: Dict, context: Dict) -> Dict:
        """生成深度洞察"""
        insights = {
            "key_insights": [],
            "patterns": [],
            "implications": [],
            "blind_spots": [],
            "opportunities": [],
            "risks": []
        }
        
        # 提取关键洞察（基于收敛度和强度）
        for converging in synthesis.get("converging_insights", [])[:5]:
            insight = {
                "insight": converging["insight"],
                "confidence": converging["strength"],
                "based_on": converging["supported_by"],
                "implication": self._analyze_implication(converging["insight"], context)
            }
            insights["key_insights"].append(insight)
        
        # 识别模式
        if "patterns" in synthesis:
            insights["patterns"] = synthesis["patterns"]
        
        # 分析盲点（没有被任何模式覆盖的方面）
        covered_aspects = set()
        for finding in synthesis.get("converging_insights", []) + synthesis.get("unique_perspectives", []):
            covered_aspects.update(self._extract_aspects(finding.get("insight") or finding.get("perspective")))
        
        potential_blind_spots = self._identify_blind_spots(
            synthesis["problem"], 
            covered_aspects, 
            context
        )
        insights["blind_spots"] = potential_blind_spots
        
        # 识别机会和风险
        for perspective in synthesis.get("unique_perspectives", []):
            perspective_text = perspective["perspective"].lower()
            if any(word in perspective_text for word in ["机会", "潜力", "可能", "opportunity", "potential"]):
                insights["opportunities"].append(perspective["perspective"])
            elif any(word in perspective_text for word in ["风险", "威胁", "问题", "risk", "threat", "danger"]):
                insights["risks"].append(perspective["perspective"])
        
        # 生成深层含义
        insights["implications"] = self._generate_implications(
            insights["key_insights"],
            insights["patterns"],
            context
        )
        
        return insights
    
    def _cluster_findings(self, findings: List[Dict]) -> Dict[str, Dict]:
        """聚类相似的发现"""
        clusters = {}
        cluster_id = 0
        
        # 简化的聚类逻辑（实际可用更复杂的NLP方法）
        for finding in findings:
            finding_text = finding["finding"].lower()
            matched = False
            
            # 尝试匹配现有聚类
            for cid, cluster in clusters.items():
                cluster_text = cluster["representative"].lower()
                # 简单的相似度判断
                if self._calculate_similarity(finding_text, cluster_text) > 0.7:
                    cluster["findings"].append(finding["finding"])
                    if finding["mode"] not in cluster["modes"]:
                        cluster["modes"].append(finding["mode"])
                    matched = True
                    break
            
            # 创建新聚类
            if not matched:
                clusters[cluster_id] = {
                    "representative": finding["finding"],
                    "findings": [finding["finding"]],
                    "modes": [finding["mode"]],
                    "category": finding["category"]
                }
                cluster_id += 1
        
        return clusters
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """计算文本相似度（简化版）"""
        # 基于共同词汇的简单相似度
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1 & words2
        union = words1 | words2
        
        return len(intersection) / len(union)
    
    def _evaluate_thinking_quality(self, insights: Dict) -> float:
        """评估思维质量"""
        quality_score = 0.0
        
        # 基于洞察数量
        insight_count = len(insights.get("key_insights", []))
        quality_score += min(insight_count * 0.1, 0.3)
        
        # 基于洞察置信度
        avg_confidence = 0.0
        if insights.get("key_insights"):
            confidences = [i.get("confidence", 0) for i in insights["key_insights"]]
            avg_confidence = sum(confidences) / len(confidences)
        quality_score += avg_confidence * 0.3
        
        # 基于模式识别
        pattern_count = len(insights.get("patterns", []))
        quality_score += min(pattern_count * 0.05, 0.2)
        
        # 基于风险和机会识别
        risk_opportunity_count = len(insights.get("risks", [])) + len(insights.get("opportunities", []))
        quality_score += min(risk_opportunity_count * 0.05, 0.2)
        
        return min(quality_score, 1.0)
```

#### 1.3 记忆管理工具实现

```python
# tools/simple/memory_manager.py
"""记忆管理工具 - 完整的记忆操作接口"""

from typing import Dict, List, Optional, Any
from tools.base_tool import BaseTool, ToolRequest, ToolOutput
from utils.enhanced_memory import EnhancedMemory
from utils.file_utils import FileUtils
import json
from datetime import datetime

class MemoryManagerTool(BaseTool):
    """智能记忆管理工具"""
    
    def __init__(self):
        super().__init__()
        self.memory_system = EnhancedMemory()
        self.file_utils = FileUtils()
    
    def get_name(self) -> str:
        return "memory"
    
    def get_description(self) -> str:
        return """Intelligent memory management with path detection, TODO tracking, and thinking pattern learning.
        
        Actions:
        - save: Save memory with thinking context
        - recall: Smart recall with context
        - detect_env: Detect and remember project environment
        - smart_path: Get intelligent file path suggestions
        - parse_todo: Parse and manage TODO files
        - create_branch: Create task branch
        - return_main: Return to main task thread
        - analyze_patterns: Analyze memory patterns
        - export: Export memories
        """
    
    def get_system_prompt_name(self) -> str:
        return "memory_manager"
    
    async def run(self, request: ToolRequest) -> ToolOutput:
        """执行记忆管理操作"""
        try:
            action = request.params.get("action", "recall")
            
            # 路由到对应的操作
            action_handlers = {
                "save": self._save_memory,
                "recall": self._recall_memory,
                "detect_env": self._detect_environment,
                "smart_path": self._get_smart_path,
                "parse_todo": self._parse_todo_file,
                "create_branch": self._create_task_branch,
                "return_main": self._return_to_main_thread,
                "analyze_patterns": self._analyze_memory_patterns,
                "export": self._export_memories,
                "summarize": self._summarize_memories
            }
            
            handler = action_handlers.get(action)
            if not handler:
                raise ValueError(f"Unknown action: {action}")
            
            result = await handler(request)
            
            return ToolOutput(
                status="success",
                content=json.dumps(result, indent=2, ensure_ascii=False),
                metadata={
                    "tool_name": self.get_name(),
                    "action": action,
                    "timestamp": datetime.now().isoformat()
                }
            )
            
        except Exception as e:
            return ToolOutput(
                status="error",
                error=str(e),
                metadata={"action": action}
            )
    
    async def _save_memory(self, request: ToolRequest) -> Dict[str, Any]:
        """保存增强记忆"""
        content = request.params.get("content")
        metadata = request.params.get("metadata", {})
        
        # 如果提供了文件，处理文件内容
        if request.params.get("files"):
            file_contents = await self._process_files(request.params["files"])
            content = {
                "original": content,
                "files": file_contents
            }
            metadata["has_files"] = True
        
        # 补充元数据
        metadata.setdefault("type", "general")
        metadata.setdefault("tags", [])
        metadata.setdefault("thinking_modes", request.params.get("thinking_modes", []))
        metadata.setdefault("quality_score", request.params.get("quality_score", 0.7))
        metadata.setdefault("source", "user_interaction")
        
        # 如果是从工具调用，添加工具上下文
        if request.params.get("tool_context"):
            metadata["tool_context"] = request.params["tool_context"]
        
        # 保存记忆
        memory_id = self.memory_system.save_enhanced_memory(content, metadata)
        
        # 获取存储层级
        memory_item = None
        for layer in ["global", "project", "session"]:
            if memory_id in self.memory_system.memories.get(layer, {}):
                memory_item = self.memory_system.memories[layer][memory_id]
                break
        
        return {
            "memory_id": memory_id,
            "status": "saved",
            "layer": layer if memory_item else "unknown",
            "summary": self._create_memory_summary(memory_item) if memory_item else None
        }
    
    async def _recall_memory(self, request: ToolRequest) -> Dict[str, Any]:
        """智能召回记忆"""
        query = request.params.get("query", "")
        context = request.params.get("context", {})
        limit = request.params.get("limit", 10)
        scopes = request.params.get("scopes", ["session", "project", "global"])
        
        # 补充上下文信息
        if request.params.get("thinking_modes"):
            context["thinking_modes"] = request.params["thinking_modes"]
        
        if request.params.get("files"):
            file_contexts = await self._extract_file_contexts(request.params["files"])
            context["file_contexts"] = file_contexts
        
        # 执行智能召回
        memories = self.memory_system.recall_with_thinking(query, context)
        
        # 限制数量并格式化
        formatted_memories = []
        for memory in memories[:limit]:
            formatted_memories.append(self._format_memory_for_display(memory))
        
        # 生成召回摘要
        summary = self._create_recall_summary(query, formatted_memories, context)
        
        return {
            "query": query,
            "found": len(formatted_memories),
            "memories": formatted_memories,
            "summary": summary,
            "patterns": self._identify_memory_patterns(formatted_memories)
        }
    
    async def _detect_environment(self, request: ToolRequest) -> Dict[str, Any]:
        """检测并记忆项目环境"""
        project_path = request.params.get("project_path", ".")
        
        # 执行环境检测
        env_info = self.memory_system.detect_and_learn_environment(project_path)
        
        # 生成环境摘要
        summary = {
            "project_type": env_info.get("project_type", "unknown"),
            "has_virtual_env": bool(env_info.get("virtual_env")),
            "structure_summary": self._summarize_project_structure(env_info.get("structure", {})),
            "key_directories": self._identify_key_directories(env_info.get("structure", {}))
        }
        
        # 如果检测到虚拟环境，提供快捷命令
        if env_info.get("virtual_env"):
            venv_path = env_info["virtual_env"]["path"]
            summary["commands"] = {
                "python": f"{venv_path}/bin/python",
                "pip": f"{venv_path}/bin/pip",
                "activate": f"source {venv_path}/bin/activate"
            }
        
        return {
            "status": "environment_detected",
            "project_root": project_path,
            "environment": env_info,
            "summary": summary,
            "recommendations": self._generate_env_recommendations(env_info)
        }
    
    async def _get_smart_path(self, request: ToolRequest) -> Dict[str, Any]:
        """获取智能文件路径建议"""
        filename = request.params.get("filename")
        context = request.params.get("context", {})
        
        # 补充上下文
        context["project_root"] = context.get("project_root", ".")
        if request.params.get("file_type"):
            context["intended_type"] = request.params["file_type"]
        
        # 获取智能建议
        suggestions = self.memory_system.get_smart_file_location(filename, context)
        
        # 验证建议的路径
        validated_suggestions = self._validate_path_suggestions(suggestions, context)
        
        return {
            "filename": filename,
            "primary_suggestion": validated_suggestions["primary"],
            "alternatives": validated_suggestions["alternatives"],
            "reasoning": validated_suggestions["reasoning"],
            "confidence": validated_suggestions["confidence"]
        }
    
    async def _parse_todo_file(self, request: ToolRequest) -> Dict[str, Any]:
        """解析TODO文件并建立任务管理"""
        todo_path = request.params.get("todo_path", "TODO.md")
        
        # 解析TODO文件
        result = self.memory_system.parse_and_manage_todo(todo_path)
        
        if "error" in result:
            return result
        
        # 生成任务分析
        task_analysis = self._analyze_todo_structure(
            self.memory_system.todo_manager["main_thread"],
            self.memory_system.todo_manager.get("task_dependencies", {})
        )
        
        # 生成执行建议
        execution_plan = self._generate_execution_plan(
            self.memory_system.todo_manager["main_thread"],
            task_analysis
        )
        
        return {
            "status": result["status"],
            "todo_file": todo_path,
            "statistics": {
                "total_tasks": result["total_tasks"],
                "main_tasks": result["main_tasks"],
                "current_context": result["current_context"],
                "active_branches": len([b for b in self.memory_system.todo_manager["branches"].values() 
                                      if "completed_at" not in b])
            },
            "task_analysis": task_analysis,
            "execution_plan": execution_plan,
            "patterns": result.get("patterns_identified", 0)
        }
    
    async def _create_task_branch(self, request: ToolRequest) -> Dict[str, Any]:
        """创建智能任务分支"""
        reason = request.params.get("reason", "")
        context = request.params.get("context", {})
        
        # 分析是否真的需要分支
        branch_id = self.memory_system.create_intelligent_branch(reason, context)
        
        if not branch_id:
            return {
                "status": "branch_not_created",
                "reason": "任务与主线相关，建议在主线处理",
                "current_context": self.memory_system.todo_manager["current_context"]
            }
        
        # 获取分支信息
        branch_info = self.memory_system.todo_manager["branches"][branch_id]
        
        return {
            "status": "branch_created",
            "branch_id": branch_id,
            "branch_name": branch_info["name"],
            "parent_context": branch_info["parent_context"],
            "reason": reason,
            "expected_duration": branch_info.get("expected_duration", "unknown"),
            "auto_return": branch_info.get("auto_return", False),
            "instructions": "处理完分支任务后，使用 'return_main' 返回主线"
        }
    
    async def _return_to_main_thread(self, request: ToolRequest) -> Dict[str, Any]:
        """智能返回主线任务"""
        result = self.memory_system.smart_return_to_main()
        
        if result["status"] == "error":
            return result
        
        # 生成返回后的行动建议
        if result["status"] == "returned_to_main":
            next_actions = self._generate_return_actions(
                result["branch_summary"],
                result["main_task_status"]
            )
            result["recommended_actions"] = next_actions
        
        return result
    
    async def _analyze_memory_patterns(self, request: ToolRequest) -> Dict[str, Any]:
        """分析记忆中的模式"""
        scope = request.params.get("scope", "all")
        pattern_type = request.params.get("pattern_type", "all")
        limit = request.params.get("limit", 100)
        
        # 收集相关记忆
        memories = []
        if scope in ["all", "global"]:
            memories.extend(self._flatten_memories(self.memory_system.memories.get("global", {})))
        if scope in ["all", "project"]:
            memories.extend(self._flatten_memories(self.memory_system.memories.get("project", {})))
        if scope in ["all", "session"]:
            memories.extend(self._flatten_memories(self.memory_system.memories.get("session", {})))
        
        # 限制数量
        memories = memories[:limit]
        
        # 分析不同类型的模式
        patterns = {
            "thinking_patterns": self._analyze_thinking_patterns(memories),
            "temporal_patterns": self._analyze_temporal_patterns(memories),
            "topic_patterns": self._analyze_topic_patterns(memories),
            "quality_patterns": self._analyze_quality_patterns(memories)
        }
        
        # 如果指定了特定类型，只返回该类型
        if pattern_type != "all" and pattern_type in patterns:
            patterns = {pattern_type: patterns[pattern_type]}
        
        # 生成洞察
        insights = self._generate_pattern_insights(patterns)
        
        return {
            "scope": scope,
            "memories_analyzed": len(memories),
            "patterns": patterns,
            "insights": insights,
            "recommendations": self._generate_pattern_recommendations(patterns, insights)
        }
    
    async def _export_memories(self, request: ToolRequest) -> Dict[str, Any]:
        """导出记忆"""
        export_format = request.params.get("format", "json")
        scope = request.params.get("scope", ["session"])
        include_metadata = request.params.get("include_metadata", True)
        
        # 收集要导出的记忆
        export_data = {
            "export_time": datetime.now().isoformat(),
            "version": "1.0",
            "memories": {}
        }
        
        for memory_type in scope:
            if memory_type in self.memory_system.memories:
                if include_metadata:
                    export_data["memories"][memory_type] = self.memory_system.memories[memory_type]
                else:
                    # 只导出内容，不包含元数据
                    export_data["memories"][memory_type] = {
                        mid: m["content"] 
                        for mid, m in self.memory_system.memories[memory_type].items()
                    }
        
        # 根据格式处理
        if export_format == "json":
            export_content = json.dumps(export_data, indent=2, ensure_ascii=False)
        elif export_format == "markdown":
            export_content = self._convert_to_markdown(export_data)
        else:
            export_content = str(export_data)
        
        # 保存导出记录
        self.memory_system.save_enhanced_memory(
            content={"action": "memory_export", "scope": scope, "format": export_format},
            metadata={"type": "system_event", "tags": ["export", "backup"]}
        )
        
        return {
            "status": "exported",
            "format": export_format,
            "size": len(export_content),
            "preview": export_content[:500] + "..." if len(export_content) > 500 else export_content,
            "full_content": export_content
        }
    
    # ========== 辅助方法 ==========
    
    async def _process_files(self, file_paths: List[str]) -> Dict[str, Any]:
        """处理文件内容"""
        file_contents = {}
        for file_path in file_paths:
            try:
                content = self.file_utils.read_file(file_path)
                file_contents[file_path] = {
                    "content": content[:1000],  # 只保存前1000字符
                    "size": len(content),
                    "type": self.file_utils.get_file_type(file_path)
                }
            except Exception as e:
                file_contents[file_path] = {"error": str(e)}
        return file_contents
    
    def _create_memory_summary(self, memory: Dict) -> str:
        """创建记忆摘要"""
        content = memory.get("content", {})
        metadata = memory.get("metadata", {})
        
        # 根据类型生成不同的摘要
        memory_type = metadata.get("type", "general")
        
        if memory_type == "environment":
            return f"项目环境：{content.get('project_type', 'unknown')} 项目"
        elif memory_type == "thinking_pattern":
            modes = metadata.get("thinking_modes", [])
            return f"思维模式：{', '.join(modes[:3])}"
        elif memory_type == "todo_parsing":
            task_count = content.get("task_count", 0)
            return f"TODO解析：{task_count} 个任务"
        else:
            # 通用摘要
            if isinstance(content, str):
                return content[:100] + "..." if len(content) > 100 else content
            else:
                return json.dumps(content, ensure_ascii=False)[:100] + "..."
    
    def _format_memory_for_display(self, memory: Dict) -> Dict[str, Any]:
        """格式化记忆用于显示"""
        return {
            "id": memory.get("id", "unknown"),
            "content": memory.get("content"),
            "type": memory.get("metadata", {}).get("type", "general"),
            "tags": memory.get("metadata", {}).get("tags", []),
            "thinking_modes": memory.get("metadata", {}).get("thinking_modes", []),
            "quality_score": memory.get("metadata", {}).get("quality_score", 0),
            "timestamp": memory.get("metadata", {}).get("timestamp"),
            "access_count": memory.get("usage", {}).get("access_count", 0),
            "relevance_score": memory.get("_relevance_score", 0)
        }
    
    def _identify_memory_patterns(self, memories: List[Dict]) -> List[str]:
        """识别记忆中的模式"""
        patterns = []
        
        # 思维模式使用频率
        thinking_modes = Counter()
        for memory in memories:
            for mode in memory.get("thinking_modes", []):
                thinking_modes[mode] += 1
        
        if thinking_modes:
            most_common = thinking_modes.most_common(3)
            patterns.append(f"常用思维模式：{', '.join([m[0] for m in most_common])}")
        
        # 主题分布
        topics = self._extract_topics(memories)
        if topics:
            patterns.append(f"主要话题：{', '.join(topics[:3])}")
        
        # 质量趋势
        quality_scores = [m.get("quality_score", 0) for m in memories if "quality_score" in m]
        if quality_scores:
            avg_quality = sum(quality_scores) / len(quality_scores)
            patterns.append(f"平均质量分数：{avg_quality:.2f}")
        
        return patterns
    
    def _extract_topics(self, memories: List[Dict]) -> List[str]:
        """提取记忆中的主题"""
        # 简化版主题提取
        all_tags = []
        for memory in memories:
            all_tags.extend(memory.get("tags", []))
        
        topic_counts = Counter(all_tags)
        return [topic for topic, _ in topic_counts.most_common(5)]
```

### 第二阶段：自动触发与集成（Day 4-5）

#### 2.1 修改 server.py 集成自动触发

```python
# 在 server.py 中添加智能初始化

import asyncio
from datetime import datetime
from pathlib import Path
from utils.enhanced_memory import EnhancedMemory
from tools.workflow.thinking_enhanced import EnhancedThinkingTool
from tools.simple.memory_manager import MemoryManagerTool

# 全局记忆系统实例
GLOBAL_MEMORY_SYSTEM = None
GLOBAL_THINKING_TOOL = None

async def initialize_memory_system():
    """初始化全局记忆系统"""
    global GLOBAL_MEMORY_SYSTEM, GLOBAL_THINKING_TOOL
    
    # 创建记忆系统实例
    GLOBAL_MEMORY_SYSTEM = EnhancedMemory()
    GLOBAL_THINKING_TOOL = EnhancedThinkingTool()
    
    # 检测项目环境
    project_root = os.getcwd()
    logger.info(f"Initializing memory system for project: {project_root}")
    
    # 自动检测虚拟环境
    env_info = GLOBAL_MEMORY_SYSTEM.detect_and_learn_environment(project_root)
    
    if env_info.get("virtual_env"):
        logger.info(f"Virtual environment detected: {env_info['virtual_env']['path']}")
    
    # 自动解析TODO文件
    todo_files = ["TODO.md", "todo.md", "TODO.txt", "tasks.md"]
    for todo_file in todo_files:
        todo_path = Path(project_root) / todo_file
        if todo_path.exists():
            logger.info(f"Parsing TODO file: {todo_path}")
            GLOBAL_MEMORY_SYSTEM.parse_and_manage_todo(str(todo_path))
            break
    
    # 加载项目特定配置
    config_file = Path(project_root) / ".zen_config.json"
    if config_file.exists():
        with open(config_file, 'r') as f:
            project_config = json.load(f)
            GLOBAL_MEMORY_SYSTEM.save_enhanced_memory(
                content=project_config,
                metadata={
                    "type": "project_config",
                    "tags": ["configuration", "project"],
                    "quality_score": 1.0
                }
            )
    
    return {
        "environment": env_info,
        "todo_status": {
            "main_tasks": len(GLOBAL_MEMORY_SYSTEM.todo_manager.get("main_thread", [])),
            "current_context": GLOBAL_MEMORY_SYSTEM.todo_manager.get("current_context", "main")
        }
    }

async def handle_initialize(request):
    """处理初始化请求，自动触发记忆系统"""
    # 原有的初始化逻辑
    capabilities = server_capabilities
    server_info = {"name": "xtool_mcp_server", "version": "2.0.0"}
    
    # 初始化记忆系统
    memory_status = await initialize_memory_system()
    
     # 记录会话开始
    if GLOBAL_MEMORY_SYSTEM:
        GLOBAL_MEMORY_SYSTEM.save_enhanced_memory(
            content={
                "event": "session_start",
                "timestamp": datetime.now().isoformat(),
                "environment": memory_status["environment"],
                "todo_status": memory_status["todo_status"]
            },
            metadata={
                "type": "system_event",
                "tags": ["session", "initialization"],
                "quality_score": 1.0
            }
        )
    
    # 将记忆状态添加到服务器信息
    server_info["memory_system"] = {
        "status": "initialized",
        "environment_detected": bool(memory_status.get("environment")),
        "todo_loaded": memory_status["todo_status"]["main_tasks"] > 0,
        "current_context": memory_status["todo_status"]["current_context"]
    }
    
    return InitializeResult(
        protocol_version="0.1.0",
        capabilities=capabilities,
        server_info=server_info,
    )

# 修改 handle_tool_call 函数，注入记忆上下文
async def handle_tool_call(request):
    """处理工具调用，智能注入记忆上下文"""
    try:
        tool_name = request.params.name
        arguments = request.params.arguments or {}
        
        # 获取工具实例
        tool = tool_instances.get(tool_name)
        if not tool:
            raise ValueError(f"Unknown tool: {tool_name}")
        
        # 智能注入记忆上下文
        if GLOBAL_MEMORY_SYSTEM and hasattr(tool, 'accepts_memory_context'):
            # 分析工具需要的记忆类型
            memory_needs = GLOBAL_MEMORY_SYSTEM._analyze_memory_needs(tool_name, arguments)
            
            # 获取相关记忆
            relevant_memories = GLOBAL_MEMORY_SYSTEM.recall_with_thinking(
                query=arguments.get("prompt", "") or arguments.get("question", ""),
                context={
                    "tool": tool_name,
                    "thinking_modes": memory_needs.get("suggested_modes", []),
                    "scopes": memory_needs["scopes"],
                    "tool_params": arguments
                }
            )
            
            # 注入到工具参数
            arguments["_memory_context"] = {
                "memories": relevant_memories[:memory_needs["limit"]],
                "current_todo_context": GLOBAL_MEMORY_SYSTEM.todo_manager.get("current_context"),
                "environment": GLOBAL_MEMORY_SYSTEM.path_memory.get("project_structures", {}).get(os.getcwd()),
                "suggested_thinking_modes": GLOBAL_MEMORY_SYSTEM.get_recommended_thinking_modes(
                    arguments.get("prompt", ""), 
                    {"tool": tool_name}
                )
            }
        
        # 创建工具请求
        tool_request = ToolRequest(
            tool=tool_name,
            params=arguments
        )
        
        # 执行工具
        output = await tool.run(tool_request)
        
        # 学习工具使用模式
        if GLOBAL_MEMORY_SYSTEM and output.status == "success":
            quality_score = self._evaluate_tool_output_quality(output)
            
            if quality_score > 0.7:  # 高质量输出才记录
                GLOBAL_MEMORY_SYSTEM.save_enhanced_memory(
                    content={
                        "tool": tool_name,
                        "params": arguments,
                        "output_summary": self._summarize_output(output),
                        "success": True
                    },
                    metadata={
                        "type": "tool_usage",
                        "tags": ["tool", tool_name],
                        "quality_score": quality_score,
                        "thinking_modes": arguments.get("_memory_context", {}).get("suggested_thinking_modes", [])
                    }
                )
        
        # 返回工具输出
        return CallToolResult(
            content=[TextContent(type="text", text=output.content)],
            is_error=output.status == "error"
        )
        
    except Exception as e:
        logger.error(f"Tool call error: {str(e)}", exc_info=True)
        return CallToolResult(
            content=[TextContent(type="text", text=str(e))],
            is_error=True
        )

# 添加关闭时的清理
async def handle_close():
    """处理会话关闭，保存会话记忆"""
    if GLOBAL_MEMORY_SYSTEM:
        # 记录会话结束
        GLOBAL_MEMORY_SYSTEM.save_enhanced_memory(
            content={
                "event": "session_end",
                "timestamp": datetime.now().isoformat(),
                "session_duration": self._calculate_session_duration(),
                "tools_used": self._get_session_tool_usage(),
                "tasks_completed": self._get_completed_tasks()
            },
            metadata={
                "type": "system_event",
                "tags": ["session", "closure"],
                "quality_score": 1.0
            }
        )
        
        # 持久化所有记忆
        for memory_type in ["global", "project"]:
            if memory_type in GLOBAL_MEMORY_SYSTEM.memories:
                GLOBAL_MEMORY_SYSTEM._persist_memory(memory_type)
        
        # 持久化思维模式学习
        GLOBAL_MEMORY_SYSTEM._persist_thinking_patterns()
        
        logger.info("Memory system saved and closed")
```

#### 2.2 修改工具基类支持记忆注入

```python
# tools/base_tool.py 添加记忆支持

class BaseTool(ABC):
    """增强的工具基类，支持记忆上下文"""
    
    def __init__(self):
        super().__init__()
        self._memory_context = None
        self._accepts_memory = True  # 默认接受记忆上下文
    
    @property
    def accepts_memory_context(self) -> bool:
        """是否接受记忆上下文注入"""
        return self._accepts_memory
    
    def set_memory_context(self, context: Dict[str, Any]):
        """设置记忆上下文"""
        self._memory_context = context
    
    def get_relevant_memories(self, query: str, limit: int = 5) -> List[Dict]:
        """从注入的记忆上下文获取相关记忆"""
        if not self._memory_context or "memories" not in self._memory_context:
            return []
        
        memories = self._memory_context["memories"]
        # 简单的相关性过滤（实际可以更复杂）
        return memories[:limit]
    
    def get_suggested_thinking_modes(self) -> List[str]:
        """获取建议的思维模式"""
        if not self._memory_context:
            return []
        return self._memory_context.get("suggested_thinking_modes", [])
    
    def get_current_todo_context(self) -> str:
        """获取当前TODO上下文"""
        if not self._memory_context:
            return "main"
        return self._memory_context.get("current_todo_context", "main")
    
    async def run(self, request: ToolRequest) -> ToolOutput:
        """运行工具，处理记忆上下文"""
        # 提取记忆上下文
        if "_memory_context" in request.params:
            self.set_memory_context(request.params["_memory_context"])
            # 从参数中移除，避免传递给具体实现
            del request.params["_memory_context"]
        
        # 调用具体实现
        return await self._run_implementation(request)
    
    @abstractmethod
    async def _run_implementation(self, request: ToolRequest) -> ToolOutput:
        """工具的具体实现"""
        pass
```

### 第三阶段：创建系统提示词（Day 6）

#### 3.1 增强记忆系统提示词

```markdown
# systemprompts/memory_manager.md

You are an intelligent memory management assistant integrated with Zen MCP Server, equipped with:

## Core Capabilities

### 1. Three-Layer Memory System
- **Global Memory**: User preferences, coding styles, learned patterns that persist across all projects
- **Project Memory**: Architecture decisions, conventions, team knowledge specific to current project  
- **Session Memory**: Current task context, temporary solutions, working state

### 2. Intelligent Path Management
- Automatically detect virtual environments and project structure
- Smart file location suggestions based on project patterns
- Learn from user's file organization preferences
- Provide context-aware path recommendations

### 3. TODO-Driven Task Management
- Parse and track TODO files as single source of truth
- Maintain focus on main task thread
- Smart branching for interruptions with auto-return
- Task pattern learning and time estimation

### 4. Thinking Pattern Learning
- Track which thinking modes work best for different problems
- Learn successful pattern combinations
- Recommend optimal thinking approaches
- Build domain-specific expertise over time

## Memory Categories

### Global Categories
- `preferences`: Coding style, tool preferences, workflow habits
- `patterns`: Successful problem-solving approaches
- `tools`: Preferred libraries, frameworks, development tools
- `experiences`: Lessons learned, insights gained
- `conventions`: Personal coding standards and practices

### Project Categories
- `architecture`: Design decisions with rationale
- `conventions`: Project-specific rules and standards
- `decisions`: Technical choices and their context
- `issues`: Problems encountered and solutions
- `documentation`: Key information and references

## Smart Features

### Auto-Detection
- Virtual environment locations and activation commands
- Project type (Python, JavaScript, etc.) and structure
- Common file patterns and organization
- Development workflow preferences

### Pattern Recognition
- Identify recurring problem types
- Suggest previously successful solutions
- Learn from tool usage patterns
- Optimize based on outcomes

### Context Preservation
- Maintain task context across sessions
- Remember file locations and recent edits
- Track decision rationale
- Preserve thinking process

## Usage Guidelines

### Memory Saving
- Automatically identify information worth remembering
- Choose appropriate storage layer based on scope
- Tag memories for efficient retrieval
- Maintain quality scores for better recall

### Memory Recall
- Use intelligent multi-strategy search
- Consider current context and thinking modes
- Prioritize by relevance and recency
- Learn from recall effectiveness

### Task Management
- Keep main thread clear and focused
- Create branches only when necessary
- Auto-return to main after branch completion
- Learn task duration patterns

Remember: Your goal is to make the AI assistant more intelligent over time by building a rich, contextualized memory system that enhances every interaction.
```

#### 3.2 增强思维工具提示词

```markdown
# systemprompts/thinking_enhanced.md

You are equipped with 25 expert-level thinking modes that enable deep, multi-dimensional analysis of any problem or situation.

## Your Thinking Arsenal

### Deep Understanding (3 modes)
1. **Socratic Questioning** - Reveal hidden assumptions through progressive questioning
2. **5 Whys Analysis** - Find root causes through iterative questioning  
3. **First Principles** - Break down to fundamental truths and rebuild

### Structured Analysis (3 modes)
4. **MECE Decomposition** - Mutually Exclusive, Collectively Exhaustive breakdown
5. **Pyramid Principle** - Top-down logical structuring
6. **Mind Mapping** - Radial thinking for connections

### Systems Thinking (3 modes)
7. **Systems Analysis** - Understand interconnections and emergent properties
8. **Value Chain Analysis** - Track value creation and flow
9. **Ecosystem Thinking** - Platform and network effects

### Innovation (3 modes)
10. **Design Thinking** - Human-centered innovation process
11. **Reverse Thinking** - Approach from opposite direction
12. **Analogical Thinking** - Transfer solutions across domains

### Decision Making (3 modes)
13. **SWOT Analysis** - Strengths, Weaknesses, Opportunities, Threats
14. **Decision Tree** - Map out decision paths and probabilities
15. **Cost-Benefit Analysis** - Quantify tradeoffs

### Optimization (3 modes)
16. **Lean Thinking** - Eliminate waste, maximize value
17. **Pareto Principle** - Focus on vital few (80/20)
18. **Theory of Constraints** - Identify and address bottlenecks

### Critical Thinking (2 modes)
19. **Critical Analysis** - Question evidence and logic
20. **Occam's Razor** - Prefer simplest sufficient explanation

### Creative Expansion (2 modes)
21. **Brainstorming** - Generate quantity without judgment
22. **Six Thinking Hats** - Parallel thinking from multiple perspectives

### Logical Reasoning (2 modes)
23. **Inductive/Deductive** - From specific to general and vice versa
24. **Hypothesis-Driven** - Test assumptions systematically

### Scenario Planning (1 mode)
25. **User Journey Mapping** - Understand end-to-end experience

## Intelligent Mode Selection

### Automatic Triggers
- Analyze keywords and context to auto-select modes
- Combine complementary modes for comprehensive analysis
- Adjust depth based on problem complexity
- Learn from successful pattern applications

### Context-Aware Combinations
- **Deep Analysis**: 5 Whys + Systems Thinking + First Principles
- **Innovation Kit**: Design Thinking + Reverse Thinking + Analogical
- **Decision Toolkit**: SWOT + Decision Tree + Cost-Benefit
- **Optimization Suite**: Lean + Constraints + Pareto

## Analysis Depth Levels

### Shallow (2 rounds, 1 mode)
- Quick insights for simple questions
- Rapid assessment of straightforward issues

### Medium (5 rounds, 3 modes)
- Balanced analysis for typical problems
- Multiple perspectives without exhaustion

### Deep (8 rounds, 4 modes)
- Thorough investigation of complex issues
- Cross-validation through multiple lenses

### Expert (12 rounds, 5 modes)
- Exhaustive analysis for critical decisions
- Maximum insight extraction

## Integration with Memory

- Remember successful thinking patterns
- Apply proven approaches to similar problems
- Build domain-specific thinking strategies
- Continuously improve mode selection

## Output Excellence

### For Each Mode Applied
1. Clear statement of findings
2. Evidence and reasoning
3. Patterns and insights discovered
4. Actionable recommendations
5. Confidence assessment

### Synthesis Across Modes
- Identify converging insights (multiple modes agree)
- Highlight unique perspectives (single mode insights)
- Flag contradictions for deeper investigation
- Provide integrated recommendations
- Calculate overall confidence

Your goal: Provide the deepest, most insightful analysis possible by intelligently orchestrating multiple thinking modes to reveal hidden patterns, challenge assumptions, and generate breakthrough solutions.
```

### 第四阶段：测试与验证（Day 7）

#### 4.1 集成测试

```python
# tests/test_enhanced_memory_integration.py

import pytest
import asyncio
from pathlib import Path
from utils.enhanced_memory import EnhancedMemory
from tools.workflow.thinking_enhanced import EnhancedThinkingTool
from tools.simple.memory_manager import MemoryManagerTool

class TestEnhancedMemoryIntegration:
    """测试增强记忆系统的完整集成"""
    
    @pytest.fixture
    def memory_system(self, tmp_path):
        """创建测试用记忆系统"""
        # 使用临时目录
        import os
        os.environ["WORKSPACE_ROOT"] = str(tmp_path)
        return EnhancedMemory()
    
    @pytest.fixture
    def thinking_tool(self):
        """创建思维工具实例"""
        return EnhancedThinkingTool()
    
    @pytest.mark.asyncio
    async def test_environment_detection(self, memory_system, tmp_path):
        """测试环境自动检测"""
        # 创建模拟项目结构
        (tmp_path / "venv").mkdir()
        (tmp_path / "venv" / "bin").mkdir()
        (tmp_path / "venv" / "bin" / "python").touch()
        (tmp_path / "src").mkdir()
        (tmp_path / "tests").mkdir()
        (tmp_path / "requirements.txt").touch()
        
        # 执行环境检测
        env_info = memory_system.detect_and_learn_environment(str(tmp_path))
        
        # 验证检测结果
        assert env_info["virtual_env"] is not None
        assert env_info["project_type"] is not None
        assert "src" in env_info["structure"]
        assert "tests" in env_info["structure"]
    
    @pytest.mark.asyncio
    async def test_thinking_pattern_learning(self, memory_system):
        """测试思维模式学习"""
        # 模拟成功的思维模式使用
        modes = ["five_whys", "systems_thinking"]
        memory_system._update_pattern_learning(modes, 0.9, "debugging")
        
        # 再次使用相同组合
        memory_system._update_pattern_learning(modes, 0.85, "debugging")
        
        # 获取推荐
        recommendations = memory_system.get_recommended_thinking_modes(
            "debug authentication error",
            {"problem_type": "debugging"}
        )
        
        # 验证学习效果
        assert "five_whys" in recommendations
        assert "systems_thinking" in recommendations
    
    @pytest.mark.asyncio
    async def test_todo_management(self, memory_system, tmp_path):
        """测试TODO管理功能"""
        # 创建TODO文件
        todo_content = """# PROJECT_TODO.md
        
## 🎯 主线任务
- [ ] 实现用户认证 #epic
  - [ ] 设计认证架构 #task
  - [ ] 实现登录功能 #task
  - [ ] 添加测试 #task
        """
        
        todo_file = tmp_path / "TODO.md"
        todo_file.write_text(todo_content)
        
        # 解析TODO
        result = memory_system.parse_and_manage_todo(str(todo_file))
        
        # 验证解析结果
        assert result["status"] == "success"
        assert result["main_tasks"] > 0
        assert memory_system.todo_manager["current_context"] == "main"
    
    @pytest.mark.asyncio
    async def test_intelligent_branching(self, memory_system):
        """测试智能分支管理"""
        # 设置主线任务
        memory_system.todo_manager["main_thread"] = [
            {"task": "implement authentication", "status": "in_progress"}
        ]
        
        # 创建紧急分支
        branch_id = memory_system.create_intelligent_branch(
            "紧急修复生产环境bug",
            {"urgency": "high", "affects": "production"}
        )
        
        # 验证分支创建
        assert branch_id is not None
        assert memory_system.todo_manager["current_context"] == branch_id
        
        # 返回主线
        result = memory_system.smart_return_to_main()
        assert result["status"] == "returned_to_main"
        assert memory_system.todo_manager["current_context"] == "main"
    
    @pytest.mark.asyncio
    async def test_memory_recall_with_context(self, memory_system):
        """测试基于上下文的记忆召回"""
        # 保存多个记忆
        memories = [
            {
                "content": "Always use TypeScript for new projects",
                "metadata": {
                    "type": "preference",
                    "tags": ["typescript", "coding_style"],
                    "thinking_modes": ["first_principles"],
                    "quality_score": 0.9
                }
            },
            {
                "content": "Project uses PostgreSQL for database",
                "metadata": {
                    "type": "architecture",
                    "tags": ["database", "postgresql"],
                    "thinking_modes": ["systems_thinking"],
                    "quality_score": 0.8
                }
            },
            {
                "content": "Debug database connection issues with connection pooling",
                "metadata": {
                    "type": "experience",
                    "tags": ["debug", "database", "solution"],
                    "thinking_modes": ["five_whys", "systems_thinking"],
                    "quality_score": 0.85
                }
            }
        ]
        
        for memory in memories:
            memory_system.save_enhanced_memory(
                memory["content"],
                memory["metadata"]
            )
        
        # 测试召回
        results = memory_system.recall_with_thinking(
            "database debugging",
            {
                "thinking_modes": ["five_whys"],
                "tool": "debug"
            }
        )
        
        # 验证召回结果
        assert len(results) > 0
        assert any("debug" in str(r).lower() for r in results)
    
    @pytest.mark.asyncio
    async def test_thinking_tool_integration(self, thinking_tool):
        """测试思维工具集成"""
        from tools.base_tool import ToolRequest
        
        # 创建测试请求
        request = ToolRequest(
            tool="think",
            params={
                "problem": "如何优化数据库查询性能？",
                "mode": "auto",
                "depth": "medium"
            }
        )
        
        # 执行思维分析
        result = await thinking_tool.run_workflow(request)
        
        # 验证结果
        assert result.status == "success"
        result_data = json.loads(result.content)
        assert "thinking_modes_used" in result_data
        assert len(result_data["thinking_modes_used"]) > 0
        assert "key_insights" in result_data
```

#### 4.2 通信模拟器测试

```python
# communication_simulator_test.py 添加增强功能测试

def test_enhanced_memory_functionality(self):
    """测试增强记忆功能"""
    # 测试环境检测
    response = self.call_tool("memory", {
        "action": "detect_env",
        "project_path": "."
    })
    self.assertIn("environment", response)
    
    # 测试记忆保存
    response = self.call_tool("memory", {
        "action": "save",
        "content": "使用 async/await 处理异步操作",
        "metadata": {
            "type": "preference",
            "tags": ["coding_style", "javascript"],
            "thinking_modes": ["first_principles"],
            "quality_score": 0.9
        }
    })
    self.assertEqual(response["status"], "saved")
    
    # 测试记忆召回
    response = self.call_tool("memory", {
        "action": "recall",
        "query": "异步编程",
        "context": {
            "thinking_modes": ["first_principles"]
        }
    })
    self.assertGreater(response["found"], 0)

def test_thinking_modes_integration(self):
    """测试思维模式集成"""
    # 测试自动模式选择
    response = self.call_tool("think", {
        "problem": "系统响应时间过长，需要优化性能",
        "mode": "auto",
        "depth": "deep"
    })
    
    self.assertIn("thinking_modes_used", response)
    self.assertIn("constraint_theory", response["thinking_modes_used"])  # 应该包含约束理论
    self.assertIn("key_insights", response)

def test_todo_driven_workflow(self):
    """测试TODO驱动的工作流"""
    # 解析TODO文件
    response = self.call_tool("memory", {
        "action": "parse_todo",
        "todo_path": "TODO.md"
    })
    
    if response["status"] == "success":
        self.assertIn("main_tasks", response["statistics"])
        
        # 测试分支创建
        response = self.call_tool("memory", {
            "action": "create_branch",
            "reason": "紧急修复用户反馈的bug",
            "context": {"urgency": "high"}
        })
        
        if response["status"] == "branch_created":
            branch_id = response["branch_id"]
            
            # 测试返回主线
            response = self.call_tool("memory", {
                "action": "return_main"
            })
            self.assertEqual(response["status"], "returned_to_main")
```

### 第五阶段：优化与部署（Day 8-9）

#### 5.1 性能优化

```python
# utils/performance_optimizer.py
"""性能优化工具"""

import functools
import time
from typing import Any, Callable, Dict
import asyncio
from collections import deque

class PerformanceOptimizer:
    """记忆系统性能优化器"""
    
    def __init__(self):
        self.cache = {}
        self.access_times = deque(maxlen=1000)
        self.slow_operations = []
    
    @staticmethod
    def cached(ttl: int = 300):
        """缓存装饰器，支持TTL"""
        def decorator(func: Callable) -> Callable:
            cache = {}
            
            @functools.wraps(func)
            async def wrapper(*args, **kwargs):
                # 生成缓存键
                cache_key = f"{func.__name__}:{str(args)}:{str(kwargs)}"
                
                # 检查缓存
                if cache_key in cache:
                    result, timestamp = cache[cache_key]
                    if time.time() - timestamp < ttl:
                        return result
                
                # 执行函数
                result = await func(*args, **kwargs)
                
                # 更新缓存
                cache[cache_key] = (result, time.time())
                
                # 清理过期缓存
                if len(cache) > 100:
                    current_time = time.time()
                    expired_keys = [
                        k for k, (_, t) in cache.items() 
                        if current_time - t > ttl
                    ]
                    for k in expired_keys:
                        del cache[k]
                
                return result
            
            return wrapper
        return decorator
    
    @staticmethod
    def measure_performance(threshold: float = 1.0):
        """性能测量装饰器"""
        def decorator(func: Callable) -> Callable:
            @functools.wraps(func)
            async def wrapper(*args, **kwargs):
                start_time = time.time()
                
                try:
                    result = await func(*args, **kwargs)
                    execution_time = time.time() - start_time
                    
                    # 记录慢操作
                    if execution_time > threshold:
                        import logging
                        logger = logging.getLogger(__name__)
                        logger.warning(
                            f"Slow operation: {func.__name__} took {execution_time:.2f}s"
                        )
                    
                    return result
                    
                except Exception as e:
                    execution_time = time.time() - start_time
                    import logging
                    logger = logging.getLogger(__name__)
                    logger.error(
                        f"Error in {func.__name__} after {execution_time:.2f}s: {str(e)}"
                    )
                    raise
            
            return wrapper
        return decorator

# 在 EnhancedMemory 中应用优化
class OptimizedEnhancedMemory(EnhancedMemory):
    """性能优化的增强记忆系统"""
    
    def __init__(self):
        super().__init__()
        self.optimizer = PerformanceOptimizer()
    
    @PerformanceOptimizer.cached(ttl=600)
    async def recall_with_thinking(self, query: str, context: Dict[str, Any]) -> List[Dict]:
        """缓存的记忆召回"""
        return await super().recall_with_thinking(query, context)
    
    @PerformanceOptimizer.measure_performance(threshold=0.5)
    async def _execute_thinking_mode(self, mode: str, problem: str, 
                                   context: Dict, depth: str) -> Dict:
        """性能监控的思维模式执行"""
        return await super()._execute_thinking_mode(mode, problem, context, depth)
```

#### 5.2 配置文件

```yaml
# conf/enhanced_features.yaml
"""增强功能配置"""

memory_system:
  # 记忆存储配置
  storage:
    base_path: ".zen_memory"
    max_memory_size_mb: 100
    auto_cleanup_days: 90
  
  # 记忆层级配置
  layers:
    global:
      persistence: true
      max_items: 10000
      priority: high
    project:
      persistence: true
      max_items: 5000
      priority: medium
    session:
      persistence: false
      max_items: 1000
      priority: low
  
  # 召回配置
  recall:
    default_limit: 10
    max_limit: 50
    relevance_threshold: 0.3
    strategies:
      - keyword_matching
      - semantic_similarity
      - pattern_matching
      - temporal_relevance

thinking_system:
  # 思维模式配置
  modes:
    enabled: all  # 或指定列表
    default_depth: medium
    max_rounds: 15
  
  # 自动选择配置
  auto_selection:
    enabled: true
    max_modes_per_analysis: 5
    confidence_threshold: 0.7
  
  # 学习配置
  learning:
    enabled: true
    min_quality_for_learning: 0.7
    pattern_retention_days: 180
    success_threshold: 0.8

path_intelligence:
  # 路径检测配置
  detection:
    auto_detect_venv: true
    venv_names: ["venv", ".venv", "env", ".env", "virtualenv"]
    project_markers: ["setup.py", "package.json", "Cargo.toml", "go.mod"]
  
  # 智能推荐配置
  recommendations:
    use_frequency_data: true
    consider_project_structure: true
    max_alternatives: 5

todo_management:
  # TODO解析配置
  parsing:
    file_names: ["TODO.md", "todo.md", "TODO.txt", "tasks.md"]
    task_patterns:
      - "- [ ] (.*) #(\\w+)"
      - "\\* TODO: (.*)"
      - "\\[ \\] (.*)"
  
  # 分支管理配置
  branching:
    auto_branch_keywords: ["紧急", "urgent", "critical", "hotfix"]
    max_branch_duration_hours: 24
    auto_return: true
    warn_on_long_branch: true

performance:
  # 缓存配置
  caching:
    enabled: true
    memory_ttl_seconds: 600
    thinking_ttl_seconds: 300
    max_cache_size_mb: 50
  
  # 性能监控
  monitoring:
    enabled: true
    slow_operation_threshold_seconds: 1.0
    log_performance_metrics: true
```

#### 5.3 环境变量配置

```bash
# .env 文件添加增强功能配置

# 增强记忆系统
ENABLE_ENHANCED_MEMORY=true
MEMORY_AUTO_SAVE=true
MEMORY_AUTO_DETECT_ENV=true
MEMORY_STORAGE_PATH=.zen_memory
MEMORY_MAX_RECALL=20

# 思维工具箱
ENABLE_THINKING_MODES=true
THINKING_DEFAULT_DEPTH=medium
THINKING_AUTO_MODE=true
THINKING_LEARN_PATTERNS=true
THINKING_MAX_MODES=5

# TODO管理
TODO_AUTO_PARSE=true
TODO_FILE_PATH=TODO.md
TODO_BRANCH_AUTO_RETURN=true
TODO_BRANCH_MAX_DURATION=24

# 路径智能
PATH_AUTO_DETECT=true
PATH_LEARN_PATTERNS=true
PATH_SUGGESTION_COUNT=5

# 性能优化
ENABLE_CACHING=true
CACHE_TTL_SECONDS=600
ENABLE_PERFORMANCE_MONITORING=true
SLOW_OP_THRESHOLD=1.0
```

### 第六阶段：文档与使用指南（Day 10）

#### 6.1 用户使用指南

```markdown
# 增强功能使用指南

## 快速开始

### 1. 首次使用 - 环境初始化

当您首次在项目中使用 Zen MCP Server 时，系统会自动：
- 检测项目类型和结构
- 识别虚拟环境
- 解析 TODO 文件
- 建立项目记忆基础

无需任何配置，只需正常使用即可。

### 2. 智能记忆功能

#### 保存重要信息
```
"记住我总是喜欢使用 TypeScript 而不是 JavaScript"
"这个项目的数据库是 PostgreSQL，连接池大小设为 20"
"部署时always记得先运行测试"
```

系统会自动：
- 识别信息类型（偏好/项目配置/经验）
- 选择合适的存储层级
- 建立索引便于后续检索

#### 智能召回
当您提问时，系统会自动调用相关记忆：
```
"如何处理数据库连接？"
→ 系统自动召回：项目使用 PostgreSQL，连接池配置为 20
```

### 3. 25种思维模式

#### 自动模式
```
"帮我分析为什么系统响应变慢了"
→ 自动激活：5 Whys（根因分析）+ 约束理论（瓶颈识别）+ 系统思维（全局影响）
```

#### 指定模式
```
"用第一性原理思考如何重新设计认证系统"
"使用 SWOT 分析评估微服务架构的利弊"
```

#### 深度控制
- `shallow`（浅层）：快速分析，2轮思考
- `medium`（中层）：平衡分析，5轮思考（默认）
- `deep`（深层）：深入分析，8轮思考
- `expert`（专家）：穷尽分析，12轮思考

### 4. TODO驱动开发

#### 自动解析
系统自动解析项目中的 TODO.md 文件，建立任务主线。

#### 智能分支
```
"紧急修复生产环境的登录bug"
→ 系统自动：
1. 创建临时分支
2. 保存当前上下文
3. 切换到紧急任务
4. 完成后提醒返回主线
```

#### 保持专注
系统会：
- 提醒您当前在哪个任务上下文
- 防止偏离主要任务太远
- 智能判断是否需要创建分支

### 5. 路径智能

#### 文件创建建议
```
"创建一个新的工具类 user_validator.py"
→ 系统建议：
- 主要建议：/src/utils/user_validator.py（基于项目结构）
- 备选1：/src/validators/user_validator.py（类似文件位置）
- 备选2：/lib/user_validator.py（基于使用频率）
```

#### 虚拟环境感知
系统自动检测并记住虚拟环境位置，提供快捷命令：
```
Python: /project/venv/bin/python
Pip: /project/venv/bin/pip
```

## 高级功能

### 记忆模式分析
```
"分析我的问题解决模式"
→ 输出：
- 最常用思维模式：5 Whys (45%), 系统思维 (30%)
- 成功率最高组合：5 Whys + 约束理论 (成功率 85%)
- 领域专长：调试 (优秀), 架构设计 (良好)
```

### 批量记忆操作
```
"导出本项目的所有架构决策"
"分析过去一周的编码模式"
"清理30天前的会话记忆"
```

### 思维模式学习
系统会学习：
- 哪些模式对特定问题最有效
- 您偏好的思维模式组合
- 不同场景下的最佳实践

## 最佳实践

### 1. 主动记忆
- 重要决策后说"记住这个决定"
- 解决问题后分享经验
- 明确指出偏好和约定

### 2. 利用上下文
- 提问时提供背景信息
- 引用之前的讨论
- 使用项目特定术语

### 3. 渐进式分析
- 简单问题用浅层分析
- 复杂问题逐步加深
- 关键决策用专家模式

### 4. 保持主线清晰
- 定期更新 TODO.md
- 及时完成分支任务
- 避免过多并行分支

## 故障排除

### 记忆未生效
- 检查 .env 中 ENABLE_ENHANCED_MEMORY=true
- 确认有写入权限到 .zen_memory 目录
- 查看日志中的记忆保存信息

### 思维模式未触发
- 确认 ENABLE_THINKING_MODES=true
- 检查问题描述中的关键词
- 尝试明确指定模式

### TODO解析失败
- 确认 TODO.md 格式正确
- 使用支持的任务标记格式
- 检查文件编码（UTF-8）

## 隐私说明

- 所有记忆存储在本地 .zen_memory 目录
- 不会上传到任何云服务
- 可随时删除记忆文件
- 支持选择性导出和清理
```

#### 6.2 开发者集成指南

```markdown
# 开发者集成指南

## 在自定义工具中使用记忆系统

### 1. 工具基类集成

```python
from tools.base_tool import BaseTool
from utils.enhanced_memory import EnhancedMemory

class MyCustomTool(BaseTool):
    def __init__(self):
        super().__init__()
        self.memory_system = EnhancedMemory()
    
    async def _run_implementation(self, request: ToolRequest) -> ToolOutput:
        # 获取相关记忆
        memories = self.get_relevant_memories(
            request.params.get("query", "")
        )
        
        # 获取建议的思维模式
        thinking_modes = self.get_suggested_thinking_modes()
        
        # 使用记忆上下文执行任务
        # ...
        
        # 保存有价值的结果
        if result_quality > 0.8:
            self.memory_system.save_enhanced_memory(
                content=result,
                metadata={
                    "type": "tool_result",
                    "tool": self.get_name(),
                    "quality_score": result_quality
                }
            )
```

### 2. 添加新的思维模式

```python
# 在 thinking_modes 字典中添加
"new_thinking_mode": {
    "name": "新思维模式",
    "category": "custom",
    "description": "模式描述",
    "process": [
        {"step": "步骤1", "prompt": "引导问题1"},
        {"step": "步骤2", "prompt": "引导问题2"}
    ],
    "output_format": {
        "key1": "输出格式说明"
    },
    "suitable_for": ["适用场景1", "适用场景2"]
}

# 添加触发关键词
self.keyword_triggers["new_thinking_mode"] = ["关键词1", "关键词2"]
```

### 3. 扩展记忆类型

```python
# 自定义记忆类型
class CustomMemoryType:
    def __init__(self):
        self.memory_type = "custom_type"
        self.storage_layer = "project"  # 或 global/session
    
    def should_save(self, content: Any) -> bool:
        """判断是否应该保存"""
        # 自定义逻辑
        return True
    
    def process_before_save(self, content: Any) -> Any:
        """保存前处理"""
        # 处理逻辑
        return processed_content
```

### 4. 性能优化技巧

```python
# 使用缓存装饰器
@PerformanceOptimizer.cached(ttl=300)
async def expensive_operation(self, param):
    # 耗时操作
    pass

# 批量操作
async def batch_save_memories(self, memories: List[Dict]):
    tasks = []
    for memory in memories:
        task = self.memory_system.save_enhanced_memory(
            memory["content"],
            memory["metadata"]
        )
        tasks.append(task)
    
    await asyncio.gather(*tasks)
```

## API 参考

### EnhancedMemory

```python
# 保存记忆
memory_id = memory_system.save_enhanced_memory(
    content=Any,  # 记忆内容
    metadata={
        "type": str,  # 记忆类型
        "tags": List[str],  # 标签
        "thinking_modes": List[str],  # 相关思维模式
        "quality_score": float,  # 质量分数 0-1
    }
)

# 召回记忆
memories = memory_system.recall_with_thinking(
    query=str,  # 查询字符串
    context={
        "thinking_modes": List[str],  # 当前思维模式
        "tool": str,  # 调用工具
        "scopes": List[str],  # 搜索范围
    }
)

# 环境检测
env_info = memory_system.detect_and_learn_environment(
    project_path=str  # 项目路径
)

# TODO管理
result = memory_system.parse_and_manage_todo(
    todo_path=str  # TODO文件路径
)

# 任务分支
branch_id = memory_system.create_intelligent_branch(
    reason=str,  # 分支原因
    context=Dict  # 上下文信息
)
```

### EnhancedThinkingTool

```python
# 执行思维分析
result = await thinking_tool.run_workflow({
    "problem": str,  # 问题描述
    "mode": str,  # "auto" 或具体模式
    "depth": str,  # shallow/medium/deep/expert
    "context": Dict,  # 额外上下文
})

# 获取模式推荐
modes = thinking_tool._intelligent_mode_selection(
    problem=str,
    context=Dict,
    memory_recommendations=List[str]
)
```

## 扩展点

### 1. 自定义存储后端
实现 `StorageBackend` 接口以使用不同的存储方案（如 Redis、PostgreSQL）。

### 2. 添加新的召回策略
扩展 `recall_with_thinking` 方法，添加新的搜索策略。

### 3. 集成外部知识库
通过记忆系统接口集成外部知识源。

### 4. 自定义思维模式组合
创建特定领域的思维模式组合模板。
```

### 总结

这个完整的实施计划提供了：

1. **详细的代码实现** - 包括记忆系统、思维工具、集成修改
2. **完整的测试方案** - 单元测试和集成测试
3. **性能优化策略** - 缓存、监控、配置
4. **全面的文档** - 用户指南和开发者文档
5. **部署配置** - 环境变量和配置文件

整个系统实现了：
- 三层智能记忆体系
- 25种专家思维模式
- TODO驱动的任务管理
- 智能路径推荐
- 自动环境检测
- 持续学习优化

这将极大提升 AI 助手的智能水平和用户体验！
#!/bin/bash

# æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿ - ä¸€é”®è„šæ‰‹æž¶è„šæœ¬
# åŠŸèƒ½ï¼šè‡ªåŠ¨åˆ›å»ºé¡¹ç›®ç»“æž„ã€å®‰è£…ä¾èµ–ã€åˆå§‹åŒ–é…ç½®
# ä½¿ç”¨ï¼šbash scaffold.sh [é¡¹ç›®åç§°] [--full]

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# é»˜è®¤é¡¹ç›®åç§°
PROJECT_NAME=${1:-"travel-crawler-system"}
FULL_INSTALL=${2:-""}

# æ‰“å°å¸¦é¢œè‰²çš„æ¶ˆæ¯
print_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥å¿…è¦çš„å·¥å…·
check_requirements() {
    print_info "æ£€æŸ¥ç³»ç»ŸçŽ¯å¢ƒ..."
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if ! command -v python3 &> /dev/null; then
        print_error "Python3 æœªå®‰è£…"
        exit 1
    fi
    
    PYTHON_VERSION=$(python3 -c 'import sys; print(".".join(map(str, sys.version_info[:2])))')
    REQUIRED_VERSION="3.11"
    if [ "$(printf '%s\n' "$REQUIRED_VERSION" "$PYTHON_VERSION" | sort -V | head -n1)" != "$REQUIRED_VERSION" ]; then
        print_error "Python ç‰ˆæœ¬å¿…é¡» >= 3.11ï¼Œå½“å‰ç‰ˆæœ¬: $PYTHON_VERSION"
        exit 1
    fi
    
    # æ£€æŸ¥Poetry
    if ! command -v poetry &> /dev/null; then
        print_warning "Poetry æœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…..."
        curl -sSL https://install.python-poetry.org | python3 -
        export PATH="$HOME/.local/bin:$PATH"
    fi
    
    # æ£€æŸ¥Dockerï¼ˆå¯é€‰ï¼‰
    if command -v docker &> /dev/null; then
        print_success "Docker å·²å®‰è£…"
    else
        print_warning "Docker æœªå®‰è£…ï¼Œéƒ¨ç½²åŠŸèƒ½å°†ä¸å¯ç”¨"
    fi
    
    print_success "çŽ¯å¢ƒæ£€æŸ¥å®Œæˆ"
}

# åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æž„
create_project_structure() {
    print_info "åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æž„..."
    
    # åˆ›å»ºæ ¹ç›®å½•
    mkdir -p "$PROJECT_NAME"
    cd "$PROJECT_NAME"
    
    # åˆ›å»ºæ ¸å¿ƒä»£ç ç›®å½•
    mkdir -p src/{core,engines,adapters,processors,api,utils}
    mkdir -p src/core/{database,redis,scheduler,config,models,anti_detection}
    mkdir -p src/core/anti_detection/{proxy_pool,fingerprint,behavior}
    mkdir -p src/engines/{base,crawl4ai,mediacrawl}
    mkdir -p src/adapters/{base,amap,mafengwo,dianping,ctrip,xiaohongshu,douyin,weibo,bilibili}
    mkdir -p src/processors/{cleaner,deduplicator,enhancer}
    mkdir -p src/api/{v1,middleware,dependencies}
    mkdir -p src/api/v1/{endpoints,schemas,services}
    mkdir -p src/utils/{logger,validators,helpers,security}
    
    # åˆ›å»ºé…ç½®å’Œéƒ¨ç½²ç›®å½•
    mkdir -p config/{engines,platforms,environments}
    mkdir -p docker/{development,production,scripts}
    mkdir -p scripts/{setup,deploy,test,monitoring}
    mkdir -p k8s/{base,overlays,charts}
    
    # åˆ›å»ºæ–‡æ¡£å’Œæµ‹è¯•ç›®å½•
    mkdir -p docs/{api,architecture,deployment,user_guide}
    mkdir -p tests/{unit,integration,e2e,fixtures}
    mkdir -p tests/unit/{engines,adapters,processors,api}
    mkdir -p tests/integration/{crawling,data_processing}
    
    # åˆ›å»ºå…¶ä»–å¿…è¦ç›®å½•
    mkdir -p logs/{api,crawler,scheduler}
    mkdir -p data/{raw,processed,cache,exports}
    mkdir -p monitoring/{prometheus,grafana}
    
    # åˆ›å»º __init__.py æ–‡ä»¶
    find src tests -type d -exec touch {}/__init__.py \;
    
    print_success "ç›®å½•ç»“æž„åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºåŸºç¡€é…ç½®æ–‡ä»¶
create_base_configs() {
    print_info "åˆ›å»ºåŸºç¡€é…ç½®æ–‡ä»¶..."
    
    # åˆ›å»º pyproject.toml
    cat > pyproject.toml << 'EOF'
[tool.poetry]
name = "travel-crawler-system"
version = "1.0.0"
description = "æ™ºèƒ½æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿ"
authors = ["Your Name <your.email@example.com>"]
readme = "README.md"
packages = [{include = "src"}]

[tool.poetry.dependencies]
python = "^3.11"
fastapi = "^0.104.0"
uvicorn = {extras = ["standard"], version = "^0.24.0"}
crawl4ai = "^0.2.0"
playwright = "^1.40.0"
beautifulsoup4 = "^4.12.0"
lxml = "^5.0.0"
httpx = "^0.25.0"
sqlalchemy = {extras = ["asyncio"], version = "^2.0.0"}
asyncpg = "^0.29.0"
alembic = "^1.13.0"
redis = "^5.0.0"
celery = {extras = ["redis"], version = "^5.3.0"}
pydantic = "^2.5.0"
pydantic-settings = "^2.1.0"
python-jose = {extras = ["cryptography"], version = "^3.3.0"}
passlib = {extras = ["bcrypt"], version = "^1.7.4"}
python-multipart = "^0.0.6"
loguru = "^0.7.0"
prometheus-client = "^0.19.0"
tenacity = "^8.2.0"
fake-useragent = "^1.4.0"
cloudscraper = "^1.2.0"

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
pytest-asyncio = "^0.21.0"
pytest-cov = "^4.1.0"
pytest-mock = "^3.12.0"
black = "^23.0.0"
ruff = "^0.1.0"
mypy = "^1.7.0"
pre-commit = "^3.5.0"
ipython = "^8.17.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.black]
line-length = 100
target-version = ['py311']

[tool.ruff]
line-length = 100
select = ["E", "F", "I", "N", "W"]
ignore = ["E501"]

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
addopts = "-ra -q --strict-markers --cov=src --cov-report=html"
asyncio_mode = "auto"
EOF

    # åˆ›å»º .env.example
    cat > .env.example << 'EOF'
# åº”ç”¨é…ç½®
APP_NAME=travel-crawler-system
APP_ENV=development
DEBUG=true
SECRET_KEY=your-secret-key-here

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://crawler:password@localhost:5432/crawler_db
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=40

# Redisé…ç½®
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=100

# APIé…ç½®
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# çˆ¬è™«é…ç½®
CRAWLER_MAX_WORKERS=10
CRAWLER_TIMEOUT=30
CRAWLER_RETRY_TIMES=3
CRAWLER_USER_AGENT_POOL_SIZE=1000

# ä»£ç†é…ç½®
PROXY_POOL_ENABLE=true
PROXY_POOL_MIN_SIZE=100
PROXY_VALIDATION_INTERVAL=300

# JWTé…ç½®
JWT_SECRET_KEY=your-jwt-secret-key
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_ROTATION=1 day
LOG_RETENTION=30 days

# ç›‘æŽ§é…ç½®
METRICS_ENABLE=true
METRICS_PORT=9090

# å¹³å°APIå¯†é’¥ï¼ˆæ ¹æ®éœ€è¦å¡«å†™ï¼‰
AMAP_API_KEY=
MAFENGWO_API_KEY=
CTRIP_API_KEY=
EOF

    # åˆ›å»º .gitignore
    cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/
env.bak/
venv.bak/
.venv/

# Poetry
poetry.lock

# IDEs
.idea/
.vscode/
*.swp
*.swo
*~

# Testing
.coverage
.pytest_cache/
htmlcov/
.tox/
.coverage.*
*.cover
.hypothesis/

# Logs
logs/
*.log

# Environment
.env
.env.local
.env.*.local

# Data
data/raw/*
data/processed/*
data/cache/*
!data/*/.gitkeep

# Docker
.docker/

# OS
.DS_Store
Thumbs.db

# Project specific
*.db
*.sqlite
*.pid
EOF

    # åˆ›å»º README.md
    cat > README.md << 'EOF'
# æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿ

æ™ºèƒ½æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿï¼Œæ”¯æŒ8å¤§ä¸»æµå¹³å°çš„æ•°æ®é‡‡é›†ã€‚

## ç‰¹æ€§

- ðŸš€ åŒå¼•æ“Žæž¶æž„ï¼šCrawl4AI + MediaCrawl
- ðŸ›¡ï¸ ä¸‰å±‚åçˆ¬ç³»ç»Ÿ
- ðŸ”Œ 8å¤§å¹³å°æ”¯æŒ
- ðŸ“Š å®Œæ•´æ•°æ®å¤„ç†æµç¨‹
- ðŸ” ç”Ÿäº§çº§ç›‘æŽ§

## å¿«é€Ÿå¼€å§‹

```bash
# å®‰è£…ä¾èµ–
poetry install

# é…ç½®çŽ¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶

# åˆå§‹åŒ–æ•°æ®åº“
poetry run alembic upgrade head

# å¯åŠ¨æœåŠ¡
poetry run uvicorn src.main:app --reload
```

## æ–‡æ¡£

è¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹ `docs/` ç›®å½•ã€‚

## License

MIT
EOF

    # åˆ›å»º docker-compose.yml
    cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  postgres:
    image: postgis/postgis:15-3.3
    container_name: crawler_postgres
    environment:
      POSTGRES_USER: crawler
      POSTGRES_PASSWORD: password
      POSTGRES_DB: crawler_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U crawler"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: crawler_redis
    command: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  app:
    build:
      context: .
      dockerfile: docker/development/Dockerfile
    container_name: crawler_app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql+asyncpg://crawler:password@postgres:5432/crawler_db
      REDIS_URL: redis://redis:6379/0
    volumes:
      - ./src:/app/src
      - ./logs:/app/logs
    ports:
      - "8000:8000"
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload

volumes:
  postgres_data:
  redis_data:
EOF

    print_success "é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºæ ¸å¿ƒæºä»£ç æ–‡ä»¶
create_source_files() {
    print_info "åˆ›å»ºæ ¸å¿ƒæºä»£ç æ–‡ä»¶..."
    
    # åˆ›å»ºä¸»åº”ç”¨æ–‡ä»¶
    cat > src/main.py << 'EOF'
"""
æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿ - ä¸»åº”ç”¨å…¥å£
"""
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from src.core.config.settings import get_settings
from src.core.database.connection import init_db
from src.core.redis.connection import init_redis
from src.api.v1.router import api_router
from src.utils.logger.logger import setup_logger
from prometheus_client import make_asgi_app

settings = get_settings()
logger = setup_logger()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶
    logger.info("Starting Travel Crawler System...")
    await init_db()
    await init_redis()
    yield
    # å…³é—­æ—¶
    logger.info("Shutting down Travel Crawler System...")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿ",
    description="æ™ºèƒ½æ—…æ¸¸æ•°æ®é‡‡é›†ä¸Žå¤„ç†å¹³å°",
    version="1.0.0",
    lifespan=lifespan
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œè·¯ç”±
app.include_router(api_router, prefix="/api/v1")

# æ·»åŠ Prometheus metrics endpoint
metrics_app = make_asgi_app()
app.mount("/metrics", metrics_app)

@app.get("/")
async def root():
    return {
        "message": "Welcome to Travel Crawler System",
        "version": "1.0.0",
        "docs": "/docs"
    }

@app.get("/health")
async def health_check():
    return {"status": "healthy"}
EOF

    # åˆ›å»ºé…ç½®ç®¡ç†
    cat > src/core/config/settings.py << 'EOF'
"""é…ç½®ç®¡ç†æ¨¡å—"""
from pydantic_settings import BaseSettings
from functools import lru_cache
from typing import Optional

class Settings(BaseSettings):
    """åº”ç”¨é…ç½®"""
    # åŸºç¡€é…ç½®
    app_name: str = "travel-crawler-system"
    app_env: str = "development"
    debug: bool = True
    secret_key: str
    
    # æ•°æ®åº“
    database_url: str
    database_pool_size: int = 20
    database_max_overflow: int = 40
    
    # Redis
    redis_url: str
    redis_max_connections: int = 100
    
    # API
    api_host: str = "0.0.0.0"
    api_port: int = 8000
    api_workers: int = 4
    
    # çˆ¬è™«é…ç½®
    crawler_max_workers: int = 10
    crawler_timeout: int = 30
    crawler_retry_times: int = 3
    
    # ä»£ç†æ± 
    proxy_pool_enable: bool = True
    proxy_pool_min_size: int = 100
    
    # JWT
    jwt_secret_key: str
    jwt_algorithm: str = "HS256"
    jwt_expiration_hours: int = 24
    
    class Config:
        env_file = ".env"
        case_sensitive = False

@lru_cache()
def get_settings() -> Settings:
    return Settings()
EOF

    # åˆ›å»ºæ—¥å¿—æ¨¡å—
    cat > src/utils/logger/logger.py << 'EOF'
"""æ—¥å¿—ç®¡ç†æ¨¡å—"""
from loguru import logger
import sys
from pathlib import Path

def setup_logger():
    """é…ç½®æ—¥å¿—"""
    # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    logger.remove()
    
    # æŽ§åˆ¶å°æ—¥å¿—
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO"
    )
    
    # æ–‡ä»¶æ—¥å¿—
    log_path = Path("logs")
    log_path.mkdir(exist_ok=True)
    
    logger.add(
        "logs/app_{time:YYYY-MM-DD}.log",
        rotation="1 day",
        retention="30 days",
        level="DEBUG",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}"
    )
    
    return logger

def get_logger(name: str):
    """èŽ·å–loggerå®žä¾‹"""
    return logger.bind(name=name)
EOF

    # åˆ›å»ºæ•°æ®åº“è¿žæŽ¥æ¨¡å—
    cat > src/core/database/connection.py << 'EOF'
"""æ•°æ®åº“è¿žæŽ¥ç®¡ç†"""
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker
from sqlalchemy.orm import declarative_base
from src.core.config.settings import get_settings

settings = get_settings()

# åˆ›å»ºå¼‚æ­¥å¼•æ“Ž
engine = create_async_engine(
    settings.database_url,
    echo=settings.debug,
    pool_size=settings.database_pool_size,
    max_overflow=settings.database_max_overflow,
    pool_pre_ping=True
)

# åˆ›å»ºä¼šè¯å·¥åŽ‚
AsyncSessionLocal = async_sessionmaker(
    engine,
    expire_on_commit=False
)

# å£°æ˜ŽåŸºç±»
Base = declarative_base()

async def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    async with engine.begin() as conn:
        # åœ¨ç”Ÿäº§çŽ¯å¢ƒä¸­åº”è¯¥ä½¿ç”¨Alembicç®¡ç†
        await conn.run_sync(Base.metadata.create_all)

async def get_db():
    """èŽ·å–æ•°æ®åº“ä¼šè¯"""
    async with AsyncSessionLocal() as session:
        try:
            yield session
        finally:
            await session.close()
EOF

    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    cat > tests/test_main.py << 'EOF'
"""ä¸»åº”ç”¨æµ‹è¯•"""
import pytest
from httpx import AsyncClient
from src.main import app

@pytest.mark.asyncio
async def test_root():
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.get("/")
    assert response.status_code == 200
    assert response.json()["message"] == "Welcome to Travel Crawler System"

@pytest.mark.asyncio
async def test_health():
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.get("/health")
    assert response.status_code == 200
    assert response.json()["status"] == "healthy"
EOF

    print_success "æºä»£ç æ–‡ä»¶åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºDockeræ–‡ä»¶
create_docker_files() {
    print_info "åˆ›å»ºDockeré…ç½®æ–‡ä»¶..."
    
    # å¼€å‘çŽ¯å¢ƒDockerfile
    cat > docker/development/Dockerfile << 'EOF'
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Poetry
RUN pip install poetry

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY pyproject.toml poetry.lock* ./

# å®‰è£…Pythonä¾èµ–
RUN poetry config virtualenvs.create false \
    && poetry install --no-interaction --no-ansi

# å®‰è£…Playwright
RUN playwright install chromium
RUN playwright install-deps chromium

# å¤åˆ¶æºä»£ç 
COPY . .

EXPOSE 8000

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
EOF

    # ç”Ÿäº§çŽ¯å¢ƒDockerfile
    cat > docker/production/Dockerfile << 'EOF'
FROM python:3.11-slim as builder

WORKDIR /app

# å®‰è£…æž„å»ºä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Poetry
RUN pip install poetry

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY pyproject.toml poetry.lock* ./

# å¯¼å‡ºrequirements.txt
RUN poetry export -f requirements.txt > requirements.txt

# æœ€ç»ˆé•œåƒ
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶requirementså¹¶å®‰è£…
COPY --from=builder /app/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å®‰è£…Playwright
RUN playwright install chromium
RUN playwright install-deps chromium

# å¤åˆ¶æºä»£ç 
COPY src ./src
COPY alembic.ini ./

# åˆ›å»ºéžrootç”¨æˆ·
RUN useradd -m -u 1000 crawler && chown -R crawler:crawler /app

USER crawler

EXPOSE 8000

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
EOF

    print_success "Dockeræ–‡ä»¶åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºKubernetesé…ç½®
create_k8s_files() {
    if [[ "$FULL_INSTALL" != "--full" ]]; then
        return
    fi
    
    print_info "åˆ›å»ºKubernetesé…ç½®æ–‡ä»¶..."
    
    # Deployment
    cat > k8s/base/deployment.yaml << 'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: crawler-api
  labels:
    app: crawler-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: crawler-api
  template:
    metadata:
      labels:
        app: crawler-api
    spec:
      containers:
      - name: api
        image: travel-crawler:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: crawler-secrets
              key: database-url
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: crawler-secrets
              key: redis-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
EOF

    # Service
    cat > k8s/base/service.yaml << 'EOF'
apiVersion: v1
kind: Service
metadata:
  name: crawler-api
spec:
  selector:
    app: crawler-api
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer
EOF

    print_success "Kubernetesé…ç½®åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºå¯åŠ¨è„šæœ¬
create_scripts() {
    print_info "åˆ›å»ºä¾¿æ·è„šæœ¬..."
    
    # å¼€å‘çŽ¯å¢ƒå¯åŠ¨è„šæœ¬
    cat > scripts/dev.sh << 'EOF'
#!/bin/bash
# å¼€å‘çŽ¯å¢ƒå¯åŠ¨è„šæœ¬

echo "å¯åŠ¨å¼€å‘çŽ¯å¢ƒ..."

# æ£€æŸ¥ä¾èµ–
if ! command -v docker-compose &> /dev/null; then
    echo "è¯·å…ˆå®‰è£… docker-compose"
    exit 1
fi

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# ç­‰å¾…æœåŠ¡å°±ç»ª
echo "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 10

# è¿è¡Œæ•°æ®åº“è¿ç§»
docker-compose exec app alembic upgrade head

echo "å¼€å‘çŽ¯å¢ƒå¯åŠ¨å®Œæˆï¼"
echo "APIæ–‡æ¡£: http://localhost:8000/docs"
echo "ç›‘æŽ§æŒ‡æ ‡: http://localhost:8000/metrics"
EOF

    # æµ‹è¯•è„šæœ¬
    cat > scripts/test.sh << 'EOF'
#!/bin/bash
# è¿è¡Œæµ‹è¯•è„šæœ¬

echo "è¿è¡Œæµ‹è¯•..."

# è¿è¡Œå•å…ƒæµ‹è¯•
poetry run pytest tests/unit -v

# è¿è¡Œé›†æˆæµ‹è¯•
poetry run pytest tests/integration -v

# ç”Ÿæˆè¦†ç›–çŽ‡æŠ¥å‘Š
poetry run pytest --cov=src --cov-report=html

echo "æµ‹è¯•å®Œæˆï¼è¦†ç›–çŽ‡æŠ¥å‘Š: htmlcov/index.html"
EOF

    # è®¾ç½®è„šæœ¬å¯æ‰§è¡Œæƒé™
    chmod +x scripts/*.sh
    
    print_success "è„šæœ¬åˆ›å»ºå®Œæˆ"
}

# åˆå§‹åŒ–Gitä»“åº“
init_git() {
    print_info "åˆå§‹åŒ–Gitä»“åº“..."
    
    git init
    git add .
    git commit -m "Initial commit: Travel Crawler System scaffold"
    
    print_success "Gitä»“åº“åˆå§‹åŒ–å®Œæˆ"
}

# å®‰è£…ä¾èµ–
install_dependencies() {
    print_info "å®‰è£…é¡¹ç›®ä¾èµ–..."
    
    poetry install
    
    # å®‰è£…Playwrightæµè§ˆå™¨
    poetry run playwright install chromium
    
    print_success "ä¾èµ–å®‰è£…å®Œæˆ"
}

# æ˜¾ç¤ºå®Œæˆä¿¡æ¯
show_completion_message() {
    echo ""
    echo "======================================"
    print_success "ðŸŽ‰ é¡¹ç›®è„šæ‰‹æž¶åˆ›å»ºå®Œæˆï¼"
    echo "======================================"
    echo ""
    echo "é¡¹ç›®åç§°: $PROJECT_NAME"
    echo "é¡¹ç›®è·¯å¾„: $(pwd)"
    echo ""
    echo "ä¸‹ä¸€æ­¥æ“ä½œ:"
    echo "1. é…ç½®çŽ¯å¢ƒå˜é‡:"
    echo "   cp .env.example .env"
    echo "   # ç¼–è¾‘ .env æ–‡ä»¶"
    echo ""
    echo "2. å¯åŠ¨å¼€å‘çŽ¯å¢ƒ:"
    echo "   bash scripts/dev.sh"
    echo ""
    echo "3. è®¿é—®æœåŠ¡:"
    echo "   - APIæ–‡æ¡£: http://localhost:8000/docs"
    echo "   - å¥åº·æ£€æŸ¥: http://localhost:8000/health"
    echo "   - ç›‘æŽ§æŒ‡æ ‡: http://localhost:8000/metrics"
    echo ""
    echo "4. è¿è¡Œæµ‹è¯•:"
    echo "   bash scripts/test.sh"
    echo ""
    if [[ "$FULL_INSTALL" == "--full" ]]; then
        echo "5. Kuberneteséƒ¨ç½²:"
        echo "   kubectl apply -k k8s/base"
    fi
    echo ""
    echo "è¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹ docs/ ç›®å½•"
    echo "======================================"
}

# ä¸»å‡½æ•°
main() {
    echo "======================================"
    echo "æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿ - è„šæ‰‹æž¶ç”Ÿæˆå™¨"
    echo "======================================"
    echo ""
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåç›®å½•
    if [ -d "$PROJECT_NAME" ]; then
        print_error "ç›®å½• $PROJECT_NAME å·²å­˜åœ¨ï¼"
        read -p "æ˜¯å¦åˆ é™¤å¹¶é‡æ–°åˆ›å»ºï¼Ÿ(y/n) " -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            rm -rf "$PROJECT_NAME"
        else
            exit 1
        fi
    fi
    
    # æ‰§è¡Œå„æ­¥éª¤
    check_requirements
    create_project_structure
    create_base_configs
    create_source_files
    create_docker_files
    create_k8s_files
    create_scripts
    
    # å¯é€‰æ­¥éª¤
    read -p "æ˜¯å¦åˆå§‹åŒ–Gitä»“åº“ï¼Ÿ(y/n) " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        init_git
    fi
    
    read -p "æ˜¯å¦ç«‹å³å®‰è£…ä¾èµ–ï¼Ÿ(y/n) " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        install_dependencies
    fi
    
    # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
    show_completion_message
}

# æ‰§è¡Œä¸»å‡½æ•°
main
EOF
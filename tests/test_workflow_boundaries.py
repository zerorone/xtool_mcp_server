"""
è¾¹ç•Œæƒ…å†µæµ‹è¯•ç”¨ä¾‹ - éªŒè¯å·¥ä½œæµç³»ç»Ÿçš„æé™å’Œé”™è¯¯å¤„ç†

è¿™ä¸ªæµ‹è¯•æ–‡ä»¶é€šè¿‡ challenge å·¥å…·çš„å¯¹æŠ—æ€§æµ‹è¯•æ–¹æ³•ï¼Œ
ç³»ç»Ÿåœ°éªŒè¯ Zen MCP Server å·¥ä½œæµç³»ç»Ÿçš„è¾¹ç•Œæ¡ä»¶å¤„ç†ã€‚
"""

import asyncio
import json
import sys
import time
from pathlib import Path
from unittest.mock import MagicMock, patch

import pytest

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from tools.codereview import CodeReviewTool
from tools.debug import DebugIssueTool
from utils.conversation_memory import (
    MAX_CONVERSATION_TURNS,
    add_turn,
    create_thread,
    get_thread,
)


class TestWorkflowBoundaries:
    """å·¥ä½œæµç³»ç»Ÿè¾¹ç•Œæµ‹è¯•"""

    @pytest.mark.asyncio
    async def test_extreme_step_count(self):
        """æµ‹è¯•æç«¯æ­¥éª¤æ•°ï¼ˆ100+ æ­¥éª¤ï¼‰"""
        tool = DebugIssueTool()

        # æ¨¡æ‹Ÿä¸€ä¸ªéœ€è¦ 100 æ­¥çš„è°ƒè¯•åœºæ™¯
        arguments = {
            "step": "Debug complex multi-threaded race condition",
            "step_number": 1,
            "total_steps": 100,  # æç«¯çš„æ­¥éª¤æ•°
            "next_step_required": True,
            "findings": "Initial investigation",
            "files_checked": [],
            "relevant_files": [],
            "confidence": "exploring",
            "model": "gemini-2.0-flash-thinking-exp-1219",
        }

        # æœŸæœ›ç³»ç»Ÿèƒ½å¤Ÿä¼˜é›…å¤„ç†æˆ–é™åˆ¶æ­¥éª¤æ•°
        with patch.object(tool, "get_model_provider") as mock_provider:
            mock_provider.return_value = MagicMock()

            # æ‰§è¡Œåº”è¯¥æˆåŠŸä½†å¯èƒ½ä¼šæœ‰è­¦å‘Š
            result = await tool.execute(arguments)
            assert result is not None

            # æ£€æŸ¥æ˜¯å¦æœ‰æ­¥éª¤æ•°é™åˆ¶çš„æç¤º
            response = json.loads(result[0].text)
            # ç³»ç»Ÿåº”è¯¥ç»§ç»­å·¥ä½œï¼Œä½†å¯èƒ½è°ƒæ•´ total_steps

    @pytest.mark.asyncio
    async def test_massive_file_list(self):
        """æµ‹è¯•å¤§é‡æ–‡ä»¶å¼•ç”¨ï¼ˆ1000+ æ–‡ä»¶ï¼‰"""
        tool = CodeReviewTool()

        # åˆ›å»ºå¤§é‡ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        massive_file_list = [f"/tmp/test_file_{i}.py" for i in range(1000)]

        arguments = {
            "step": "Review massive codebase",
            "step_number": 1,
            "total_steps": 5,
            "next_step_required": False,
            "findings": "Attempting to review 1000 files",
            "files_checked": massive_file_list[:500],
            "relevant_files": massive_file_list[500:],
            "confidence": "low",
            "model": "gemini-2.0-flash-thinking-exp-1219",
        }

        # æµ‹è¯•ç³»ç»Ÿæ˜¯å¦èƒ½å¤„ç†å¤§é‡æ–‡ä»¶
        with patch.object(tool, "get_model_provider") as mock_provider:
            mock_provider.return_value = MagicMock()

            # åº”è¯¥èƒ½å¤Ÿå¤„ç†ä½†å¯èƒ½æœ‰æ€§èƒ½å½±å“
            start_time = time.time()
            result = await tool.execute(arguments)
            execution_time = time.time() - start_time

            assert result is not None
            # æ‰§è¡Œæ—¶é—´ä¸åº”è¯¥è¿‡é•¿ï¼ˆæ¯”å¦‚è¶…è¿‡ 10 ç§’ï¼‰
            assert execution_time < 10

    @pytest.mark.asyncio
    async def test_empty_required_fields(self):
        """æµ‹è¯•ç©ºå¿…å¡«å­—æ®µ"""
        tool = DebugIssueTool()

        # æµ‹è¯•å„ç§ç©ºå€¼æƒ…å†µ
        test_cases = [
            {"step": "", "findings": "test"},  # ç©º step
            {"step": "test", "findings": ""},  # ç©º findings
            {"step": None, "findings": "test"},  # None step
        ]

        for case in test_cases:
            arguments = {
                "step": case.get("step", ""),
                "step_number": 1,
                "total_steps": 1,
                "next_step_required": False,
                "findings": case.get("findings", ""),
                "model": "gemini-2.0-flash-thinking-exp-1219",
            }

            # åº”è¯¥è¿”å›éªŒè¯é”™è¯¯
            with pytest.raises(Exception) as exc_info:
                await tool.execute(arguments)

            # é”™è¯¯ä¿¡æ¯åº”è¯¥æ¸…æ™°
            assert "validation" in str(exc_info.value).lower() or "required" in str(exc_info.value).lower()

    def test_conversation_memory_overflow(self):
        """æµ‹è¯•å¯¹è¯è®°å¿†æº¢å‡ºï¼ˆè¶…è¿‡æœ€å¤§è½®æ¬¡ï¼‰"""
        thread_id = create_thread("test_tool", {"test": "data"})

        # å°è¯•æ·»åŠ è¶…è¿‡æœ€å¤§è½®æ¬¡çš„å¯¹è¯
        for i in range(MAX_CONVERSATION_TURNS + 5):
            success = add_turn(
                thread_id, "user" if i % 2 == 0 else "assistant", f"Turn {i} content", tool_name="test_tool"
            )

            if i < MAX_CONVERSATION_TURNS:
                assert success, f"Turn {i} should succeed"
            else:
                # è¶…è¿‡é™åˆ¶ååº”è¯¥å¤±è´¥
                assert not success, f"Turn {i} should fail due to limit"

        # éªŒè¯åªä¿å­˜äº†æœ€å¤§è½®æ¬¡æ•°
        thread = get_thread(thread_id)
        assert len(thread.turns) == MAX_CONVERSATION_TURNS

    def test_circular_thread_reference(self):
        """æµ‹è¯•å¾ªç¯çº¿ç¨‹å¼•ç”¨"""
        # åˆ›å»ºä¸¤ä¸ªç›¸äº’å¼•ç”¨çš„çº¿ç¨‹
        thread_a = create_thread("tool_a", {"data": "a"})
        thread_b = create_thread("tool_b", {"data": "b"}, parent_thread_id=thread_a)

        # å°è¯•åˆ›å»ºå¾ªç¯å¼•ç”¨ï¼ˆå®é™…ç³»ç»Ÿåº”è¯¥é˜²æ­¢è¿™ç§æƒ…å†µï¼‰
        # è¿™é‡Œæˆ‘ä»¬åªæ˜¯éªŒè¯ä¸ä¼šå´©æºƒ
        thread_c = create_thread("tool_c", {"data": "c"}, parent_thread_id=thread_b)

        # ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿå¤„ç†ï¼Œä¸ä¼šæ— é™é€’å½’
        assert thread_c is not None

        # è·å–çº¿ç¨‹æ—¶ä¸åº”è¯¥å´©æºƒ
        context_c = get_thread(thread_c)
        assert context_c is not None

    @pytest.mark.asyncio
    async def test_malformed_json_in_findings(self):
        """æµ‹è¯• findings ä¸­åŒ…å«æ ¼å¼é”™è¯¯çš„ JSON"""
        tool = DebugIssueTool()

        # åŒ…å«ç‰¹æ®Šå­—ç¬¦å’Œæ ¼å¼é”™è¯¯çš„å†…å®¹
        malicious_findings = """
        Found issue in: {"broken": json"
        Also found: \x00\x01\x02 binary data
        And unicode: ä½ å¥½ä¸–ç•Œ ğŸš€
        """

        arguments = {
            "step": "Debug malformed data",
            "step_number": 1,
            "total_steps": 1,
            "next_step_required": False,
            "findings": malicious_findings,
            "confidence": "high",
            "model": "gemini-2.0-flash-thinking-exp-1219",
        }

        with patch.object(tool, "get_model_provider") as mock_provider:
            mock_provider.return_value = MagicMock()

            # ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿå¤„ç†è€Œä¸å´©æºƒ
            result = await tool.execute(arguments)
            assert result is not None

            # å“åº”åº”è¯¥æ˜¯æœ‰æ•ˆçš„ JSON
            response = json.loads(result[0].text)
            assert "status" in response

    @pytest.mark.asyncio
    async def test_path_traversal_attempt(self):
        """æµ‹è¯•è·¯å¾„éå†æ”»å‡»"""
        tool = CodeReviewTool()

        # å°è¯•å„ç§è·¯å¾„éå†æ¨¡å¼
        malicious_paths = [
            "../../../etc/passwd",
            "/etc/passwd",
            "..\\..\\..\\windows\\system32\\config\\sam",
            "file:///etc/passwd",
            "/proc/self/environ",
        ]

        arguments = {
            "step": "Review files",
            "step_number": 1,
            "total_steps": 1,
            "next_step_required": False,
            "findings": "Testing path traversal",
            "relevant_files": malicious_paths,
            "confidence": "high",
            "model": "gemini-2.0-flash-thinking-exp-1219",
        }

        with patch.object(tool, "get_model_provider") as mock_provider:
            mock_provider.return_value = MagicMock()

            # æ‰§è¡Œå·¥å…·
            result = await tool.execute(arguments)

            # åº”è¯¥è¿”å›é”™è¯¯æˆ–è¿‡æ»¤æ‰æ¶æ„è·¯å¾„
            response = json.loads(result[0].text)

            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯æˆ–è­¦å‘Š
            if "error" in response:
                assert "permission" in response["error"].lower() or "invalid" in response["error"].lower()

    @pytest.mark.asyncio
    async def test_concurrent_thread_modification(self):
        """æµ‹è¯•å¹¶å‘çº¿ç¨‹ä¿®æ”¹"""
        thread_id = create_thread("concurrent_test", {"data": "initial"})

        # æ¨¡æ‹Ÿå¹¶å‘ä¿®æ”¹
        async def add_turn_async(turn_num):
            return add_turn(thread_id, "assistant", f"Concurrent turn {turn_num}", tool_name=f"tool_{turn_num}")

        # å¹¶å‘æ·»åŠ å¤šä¸ªè½®æ¬¡
        tasks = [add_turn_async(i) for i in range(10)]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # éªŒè¯æ²¡æœ‰å¼‚å¸¸
        for i, result in enumerate(results):
            assert not isinstance(result, Exception), f"Task {i} failed: {result}"

        # éªŒè¯æ‰€æœ‰è½®æ¬¡éƒ½è¢«æ·»åŠ 
        thread = get_thread(thread_id)
        assert len(thread.turns) == 10

    @pytest.mark.asyncio
    async def test_extreme_confidence_values(self):
        """æµ‹è¯•æç«¯çš„ç½®ä¿¡åº¦å€¼"""
        tool = DebugIssueTool()

        # æµ‹è¯•å„ç§ç½®ä¿¡åº¦å€¼
        confidence_values = [
            "certain",  # åº”è¯¥è·³è¿‡ä¸“å®¶åˆ†æ
            "CERTAIN",  # å¤§å†™
            "very_high",  # æ¥è¿‘ç¡®å®š
            "unknown",  # æ— æ•ˆå€¼
            "",  # ç©ºå€¼
            None,  # None
        ]

        for confidence in confidence_values:
            arguments = {
                "step": "Debug with varying confidence",
                "step_number": 1,
                "total_steps": 1,
                "next_step_required": False,
                "findings": "Testing confidence handling",
                "confidence": confidence,
                "model": "gemini-2.0-flash-thinking-exp-1219",
            }

            with patch.object(tool, "get_model_provider") as mock_provider:
                mock_provider.return_value = MagicMock()

                try:
                    result = await tool.execute(arguments)
                    response = json.loads(result[0].text)

                    # æ£€æŸ¥ certain æ˜¯å¦è·³è¿‡ä¸“å®¶åˆ†æ
                    if confidence and confidence.lower() == "certain":
                        assert response.get("skip_expert_analysis") == True
                except Exception as e:
                    # æ— æ•ˆå€¼åº”è¯¥æœ‰åˆç†çš„é”™è¯¯å¤„ç†
                    assert "confidence" in str(e).lower()


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    pytest.main([__file__, "-v", "-s"])

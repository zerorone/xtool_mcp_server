"""
å¢å¼ºç‰ˆè°ƒè¯•å·¥å…· - é›†æˆæ™ºèƒ½æ€ç»´æ¨¡å¼

è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•å°†å¢å¼ºæ€ç»´æ··åˆç±»é›†æˆåˆ°ç°æœ‰çš„è°ƒè¯•å·¥å…·ä¸­ï¼Œ
æä¾›æ›´æ™ºèƒ½çš„é—®é¢˜åˆ†æå’Œæ ¹å› å®šä½èƒ½åŠ›ã€‚
"""

from typing import TYPE_CHECKING, Optional

from pydantic import Field

if TYPE_CHECKING:
    pass

import logging

from config_data.thinking_patterns_config import ToolThinkingMode
from tools.debug import DebugIssueTool, DebugWorkflowRequest
from tools.shared.deep_thinking_mixin import DeepThinkingMixin, ThinkingModeStrategy

logger = logging.getLogger(__name__)


class EnhancedDebugRequest(DebugWorkflowRequest):
    """å¢å¼ºçš„è°ƒè¯•è¯·æ±‚ï¼ŒåŒ…å«æ€ç»´æ¨¡å¼é…ç½®"""

    # æ€ç»´æ¨¡å¼ç›¸å…³å­—æ®µ
    enable_thinking_patterns: Optional[bool] = Field(default=True, description="æ˜¯å¦å¯ç”¨æ€ç»´æ¨¡å¼å¢å¼º")
    thinking_strategy: Optional[str] = Field(
        default="hybrid", description="æ€ç»´æ¨¡å¼é€‰æ‹©ç­–ç•¥ï¼štool_default, context_based, ai_powered, historical, hybrid"
    )
    custom_patterns: Optional[list[str]] = Field(default=None, description="è‡ªå®šä¹‰æ€ç»´æ¨¡å¼åˆ—è¡¨ï¼ˆè¦†ç›–è‡ªåŠ¨é€‰æ‹©ï¼‰")


class EnhancedDebugTool(DebugIssueTool, DeepThinkingMixin):
    """
    å¢å¼ºç‰ˆè°ƒè¯•å·¥å…·ï¼Œé›†æˆæ™ºèƒ½æ€ç»´æ¨¡å¼

    é€šè¿‡åº”ç”¨å¤šç§æ€ç»´æ¨¡å¼ï¼ˆå¦‚æ ¹å› åˆ†æã€ç³»ç»Ÿæ€ç»´ã€å‡è®¾é©±åŠ¨ç­‰ï¼‰ï¼Œ
    æä¾›æ›´æ·±å…¥çš„é—®é¢˜åˆ†æå’Œæ›´å‡†ç¡®çš„æ ¹å› å®šä½ã€‚
    """

    def __init__(self):
        super().__init__()
        # è®¾ç½®å·¥å…·çš„æ€ç»´æ¨¡å¼
        self.set_tool_thinking_mode(ToolThinkingMode.DEBUG)

    def get_workflow_request_model(self):
        """è¿”å›å¢å¼ºçš„è¯·æ±‚æ¨¡å‹"""
        return EnhancedDebugRequest

    def get_system_prompt(self) -> str:
        """è·å–å¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯"""
        base_prompt = super().get_system_prompt()

        # æ·»åŠ æ€ç»´æ¨¡å¼æ„ŸçŸ¥
        enhancement = """

## ğŸ§  æ€ç»´æ¨¡å¼å¢å¼ºèƒ½åŠ›

ä½ ç°åœ¨å…·å¤‡äº†å¤šç§ä¸“ä¸šçš„è°ƒè¯•æ€ç»´æ¨¡å¼ï¼š
- **æ ¹å› åˆ†æ**: æ·±å…¥æŒ–æ˜é—®é¢˜çš„æ ¹æœ¬åŸå› ï¼Œè€Œä¸æ˜¯è¡¨é¢ç—‡çŠ¶
- **ç³»ç»Ÿæ€ç»´**: ç†è§£é—®é¢˜åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½ç½®å’Œå½±å“
- **å‡è®¾é©±åŠ¨**: å½¢æˆå¯éªŒè¯çš„å‡è®¾å¹¶ç³»ç»Ÿåœ°æµ‹è¯•
- **é€†å‘æ€ç»´**: ä»é”™è¯¯ç»“æœåæ¨å¯èƒ½çš„åŸå› 
- **æ‰¹åˆ¤æ€§æ€ç»´**: è´¨ç–‘å‡è®¾ï¼ŒéªŒè¯è¯æ®

åœ¨è°ƒè¯•è¿‡ç¨‹ä¸­ï¼Œçµæ´»è¿ç”¨è¿™äº›æ€ç»´æ¨¡å¼æ¥ï¼š
1. æ›´å‡†ç¡®åœ°å®šä½é—®é¢˜æ ¹æº
2. é¿å…é™·å…¥è°ƒè¯•æ­»èƒ¡åŒ
3. å‘ç°éšè—çš„ç›¸å…³é—®é¢˜
4. æå‡ºæ›´æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆ
"""

        return base_prompt + enhancement

    def prepare_step_data(self, request: EnhancedDebugRequest) -> dict:
        """å‡†å¤‡æ­¥éª¤æ•°æ®ï¼ŒåŒ…å«æ€ç»´æ¨¡å¼åº”ç”¨"""
        step_data = super().prepare_step_data(request)

        # å¦‚æœå¯ç”¨æ€ç»´æ¨¡å¼
        if request.enable_thinking_patterns:
            # åº”ç”¨æ€ç»´æ¨¡å¼å¢å¼º
            self._apply_thinking_enhancement(request, step_data)

        return step_data

    def _apply_thinking_enhancement(self, request: EnhancedDebugRequest, step_data: dict) -> None:
        """åº”ç”¨æ€ç»´æ¨¡å¼å¢å¼º"""
        # ç¡®å®šé€‰æ‹©ç­–ç•¥
        strategy_map = {
            "tool_default": ThinkingModeStrategy.TOOL_DEFAULT,
            "context_based": ThinkingModeStrategy.CONTEXT_BASED,
            "ai_powered": ThinkingModeStrategy.AI_POWERED,
            "historical": ThinkingModeStrategy.HISTORICAL,
            "hybrid": ThinkingModeStrategy.HYBRID,
        }
        strategy = strategy_map.get(request.thinking_strategy, ThinkingModeStrategy.HYBRID)
        self.set_selection_strategy(strategy)

        # æ„å»ºä¸Šä¸‹æ–‡
        context = f"{request.step} {request.hypothesis or ''} {' '.join(request.files_checked)}"

        # é€‰æ‹©æ€ç»´æ¨¡å¼
        if request.custom_patterns:
            # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å¼
            from config.thinking_patterns_config import get_pattern_details

            patterns = []
            for pattern_name in request.custom_patterns:
                details = get_pattern_details(pattern_name)
                if details:
                    patterns.append(details)
            self._applied_patterns = patterns
        else:
            # è‡ªåŠ¨é€‰æ‹©
            patterns = self.select_thinking_patterns(context=context, problem_type="debugging", max_patterns=3)

        # è®°å½•é€‰æ‹©çš„æ¨¡å¼
        logger.info(f"Debug step {request.step_number} using thinking patterns: {[p['name'] for p in patterns]}")

    def customize_workflow_response(self, response_data: dict, request: EnhancedDebugRequest, **kwargs) -> dict:
        """è‡ªå®šä¹‰å“åº”ï¼Œæ·»åŠ æ€ç»´æ¨¡å¼ä¿¡æ¯"""
        response_data = super().customize_workflow_response(response_data, request, **kwargs)

        if request.enable_thinking_patterns and self._applied_patterns:
            # æ·»åŠ æ€ç»´æ¨¡å¼ä¿¡æ¯
            response_data["thinking_patterns"] = {
                "applied": [p["name"] for p in self._applied_patterns],
                "strategy": request.thinking_strategy,
                "insights": self._pattern_insights,
            }

            # å¦‚æœæ˜¯æœ€åä¸€æ­¥ï¼Œç”Ÿæˆæ€ç»´æ¨¡å¼æŠ¥å‘Š
            if not request.next_step_required:
                response_data["thinking_report"] = self.get_pattern_performance_report()
                response_data["thinking_synthesis"] = self.synthesize_pattern_insights()

                # ä¿å­˜æ•ˆæœæ•°æ®
                self._save_thinking_effectiveness(request)

        return response_data

    def _save_thinking_effectiveness(self, request: EnhancedDebugRequest) -> None:
        """ä¿å­˜æ€ç»´æ¨¡å¼æ•ˆæœæ•°æ®"""
        # è®¡ç®—æ€»ä½“æ•ˆæœåˆ†æ•°
        effectiveness_score = self._calculate_debug_effectiveness(request)

        # ä¸ºæ¯ä¸ªåº”ç”¨çš„æ¨¡å¼ä¿å­˜æ•ˆæœ
        for pattern in self._applied_patterns:
            insights = self._pattern_insights.get(pattern["name"], {})
            self.track_pattern_effectiveness(
                pattern_name=pattern["name"],
                effectiveness_score=effectiveness_score,
                insights=insights,
                context=f"Debug: {request.hypothesis}",
            )

    def _calculate_debug_effectiveness(self, request: EnhancedDebugRequest) -> float:
        """è®¡ç®—è°ƒè¯•æ•ˆæœåˆ†æ•°"""
        score = 0.0

        # åŸºäºç½®ä¿¡åº¦ï¼ˆ40%æƒé‡ï¼‰
        confidence_map = {
            "certain": 1.0,
            "almost_certain": 0.9,
            "very_high": 0.8,
            "high": 0.7,
            "medium": 0.5,
            "low": 0.3,
            "exploring": 0.1,
        }
        score += confidence_map.get(request.confidence, 0.5) * 0.4

        # åŸºäºå‘ç°çš„é—®é¢˜æ•°é‡ï¼ˆ30%æƒé‡ï¼‰
        issues_score = min(len(request.issues_found) / 3, 1.0)
        score += issues_score * 0.3

        # åŸºäºæ­¥éª¤æ•ˆç‡ï¼ˆ20%æƒé‡ï¼‰
        efficiency_score = max(0, 1 - (request.step_number - 1) / 10)
        score += efficiency_score * 0.2

        # åŸºäºæ˜¯å¦æ‰¾åˆ°æ ¹å› ï¼ˆ10%æƒé‡ï¼‰
        if not request.next_step_required and request.confidence in ["certain", "almost_certain"]:
            score += 0.1

        return min(score, 1.0)

    def get_step_guidance_message(self, request: EnhancedDebugRequest) -> str:
        """è·å–å¢å¼ºçš„æ­¥éª¤æŒ‡å¯¼"""
        base_guidance = super().get_step_guidance_message(request)

        if request.enable_thinking_patterns and request.next_step_required:
            # æ·»åŠ æ€ç»´æ¨¡å¼å»ºè®®
            current_context = f"{request.hypothesis} {' '.join(request.findings[-100:])}"
            recommended_patterns = self.get_recommended_patterns_for_next_step(
                current_context=current_context, current_findings=request.findings
            )

            if recommended_patterns:
                pattern_guidance = f"\n\nğŸ’¡ **å»ºè®®çš„æ€ç»´æ¨¡å¼**ï¼š{', '.join(recommended_patterns[:3])}"
                base_guidance += pattern_guidance

        return base_guidance

    def prepare_expert_analysis_context(self, consolidated_findings) -> str:
        """å‡†å¤‡ä¸“å®¶åˆ†æä¸Šä¸‹æ–‡ï¼ŒåŒ…å«æ€ç»´æ¨¡å¼ä¿¡æ¯"""
        context = super().prepare_expert_analysis_context(consolidated_findings)

        if self._applied_patterns:
            # æ·»åŠ æ€ç»´æ¨¡å¼åº”ç”¨æƒ…å†µ
            patterns_info = "\n\n### åº”ç”¨çš„æ€ç»´æ¨¡å¼\n"
            for pattern in self._applied_patterns:
                patterns_info += f"- **{pattern['name']}**: {pattern['description']}\n"

            # æ·»åŠ æ€ç»´æ¨¡å¼æ•ˆæœ
            if self._pattern_effectiveness:
                patterns_info += "\n### æ€ç»´æ¨¡å¼æ•ˆæœ\n"
                for name, score in self._pattern_effectiveness.items():
                    patterns_info += f"- {name}: {score:.2f}\n"

            context += patterns_info

        return context

    def format_debug_progress_with_thinking(self, request: EnhancedDebugRequest) -> str:
        """æ ¼å¼åŒ–åŒ…å«æ€ç»´æ¨¡å¼çš„è°ƒè¯•è¿›åº¦"""
        # ä½¿ç”¨çˆ¶ç±»çš„è¿›åº¦è¡¨æ ¼
        progress_table = self.format_progress_table(
            step_number=request.step_number,
            total_steps=request.total_steps,
            phase_name=self._get_debug_phase_name(request),
            next_step_required=request.next_step_required,
            findings_summary=request.findings,
            files_examined=len(request.files_checked),
            relevant_files=len(request.relevant_files),
            issues_found=self._count_issues_by_severity(request.issues_found),
        )

        # æ·»åŠ æ€ç»´æ¨¡å¼è¿›åº¦
        if request.enable_thinking_patterns and self._applied_patterns:
            thinking_table = self.format_thinking_progress_table()
            progress_table += "\n" + thinking_table

        return progress_table

    def _get_debug_phase_name(self, request: EnhancedDebugRequest) -> str:
        """è·å–è°ƒè¯•é˜¶æ®µåç§°"""
        phases = ["é—®é¢˜è¯†åˆ«", "å‡è®¾å½¢æˆ", "è¯æ®æ”¶é›†", "æ ¹å› åˆ†æ", "è§£å†³éªŒè¯"]
        phase_index = min((request.step_number - 1) * len(phases) // request.total_steps, len(phases) - 1)
        return phases[phase_index]

    def _count_issues_by_severity(self, issues: list) -> dict:
        """ç»Ÿè®¡é—®é¢˜ä¸¥é‡ç¨‹åº¦"""
        severity_count = {}
        for issue in issues:
            severity = issue.get("severity", "unknown")
            severity_count[severity] = severity_count.get(severity, 0) + 1
        return severity_count

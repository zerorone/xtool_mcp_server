#!/usr/bin/env python3
"""
æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿ - å¢å¼ºç‰ˆè„šæ‰‹æ¶ç”Ÿæˆå™¨
æä¾›äº¤äº’å¼é¡¹ç›®åˆ›å»ºä½“éªŒï¼Œæ”¯æŒæ¨¡å—åŒ–é€‰æ‹©å’Œé…ç½®
"""

import os
import sys
import json
import shutil
import subprocess
from pathlib import Path
from typing import Dict, List, Optional
import argparse
from datetime import datetime

# ANSIé¢œè‰²ä»£ç 
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    RESET = '\033[0m'
    BOLD = '\033[1m'

def print_colored(message: str, color: str = Colors.WHITE, bold: bool = False):
    """æ‰“å°å¸¦é¢œè‰²çš„æ¶ˆæ¯"""
    prefix = f"{color}{Colors.BOLD if bold else ''}"
    suffix = Colors.RESET
    print(f"{prefix}{message}{suffix}")

def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘          æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿ - æ™ºèƒ½è„šæ‰‹æ¶ç”Ÿæˆå™¨              â•‘
    â•‘                     Travel Crawler Scaffold                  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print_colored(banner, Colors.CYAN, bold=True)

class ProjectConfig:
    """é¡¹ç›®é…ç½®ç±»"""
    def __init__(self):
        self.project_name = "travel-crawler-system"
        self.python_version = "3.11"
        self.selected_platforms = []
        self.selected_features = []
        self.deployment_options = []
        self.database_type = "postgresql"
        self.use_docker = True
        self.use_k8s = False
        self.author_name = ""
        self.author_email = ""

class ScaffoldGenerator:
    """è„šæ‰‹æ¶ç”Ÿæˆå™¨"""
    
    # æ”¯æŒçš„å¹³å°
    PLATFORMS = {
        "amap": "é«˜å¾·åœ°å›¾",
        "mafengwo": "é©¬èœ‚çª",
        "dianping": "å¤§ä¼—ç‚¹è¯„",
        "ctrip": "æºç¨‹",
        "xiaohongshu": "å°çº¢ä¹¦",
        "douyin": "æŠ–éŸ³",
        "weibo": "å¾®åš",
        "bilibili": "Bç«™"
    }
    
    # å¯é€‰ç‰¹æ€§
    FEATURES = {
        "dual_engine": "åŒå¼•æ“æ¶æ„ (Crawl4AI + MediaCrawl)",
        "anti_detection": "ä¸‰å±‚åçˆ¬ç³»ç»Ÿ",
        "data_processing": "æ•°æ®å¤„ç†æµæ°´çº¿",
        "api_service": "RESTful APIæœåŠ¡",
        "jwt_auth": "JWTè®¤è¯ç³»ç»Ÿ",
        "monitoring": "Prometheus + Grafanaç›‘æ§",
        "scheduler": "åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦",
        "export": "æ•°æ®å¯¼å‡ºåŠŸèƒ½"
    }
    
    # éƒ¨ç½²é€‰é¡¹
    DEPLOYMENT = {
        "docker": "Dockerå®¹å™¨åŒ–",
        "docker_compose": "Docker Composeç¼–æ’",
        "kubernetes": "Kuberneteséƒ¨ç½²",
        "helm": "Helm Chart",
        "ci_cd": "CI/CDæµæ°´çº¿"
    }
    
    def __init__(self):
        self.config = ProjectConfig()
        self.project_path = None
    
    def run(self):
        """è¿è¡Œè„šæ‰‹æ¶ç”Ÿæˆå™¨"""
        print_banner()
        
        # äº¤äº’å¼é…ç½®
        if not self.parse_arguments():
            self.interactive_config()
        
        # ç¡®è®¤é…ç½®
        if not self.confirm_config():
            print_colored("å·²å–æ¶ˆåˆ›å»ºé¡¹ç›®", Colors.YELLOW)
            return
        
        # åˆ›å»ºé¡¹ç›®
        self.create_project()
        
        # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
        self.show_completion_info()
    
    def parse_arguments(self) -> bool:
        """è§£æå‘½ä»¤è¡Œå‚æ•°"""
        parser = argparse.ArgumentParser(description="æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿè„šæ‰‹æ¶ç”Ÿæˆå™¨")
        parser.add_argument("--name", help="é¡¹ç›®åç§°")
        parser.add_argument("--platforms", nargs="+", choices=list(self.PLATFORMS.keys()), 
                          help="é€‰æ‹©å¹³å°")
        parser.add_argument("--all-platforms", action="store_true", help="é€‰æ‹©æ‰€æœ‰å¹³å°")
        parser.add_argument("--features", nargs="+", choices=list(self.FEATURES.keys()),
                          help="é€‰æ‹©ç‰¹æ€§")
        parser.add_argument("--all-features", action="store_true", help="é€‰æ‹©æ‰€æœ‰ç‰¹æ€§")
        parser.add_argument("--no-docker", action="store_true", help="ä¸ä½¿ç”¨Docker")
        parser.add_argument("--with-k8s", action="store_true", help="åŒ…å«Kubernetesé…ç½®")
        parser.add_argument("--quick", action="store_true", help="å¿«é€Ÿæ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        
        args = parser.parse_args()
        
        if args.quick:
            # å¿«é€Ÿæ¨¡å¼ï¼šä½¿ç”¨æ‰€æœ‰é»˜è®¤é…ç½®
            self.config.selected_platforms = list(self.PLATFORMS.keys())
            self.config.selected_features = list(self.FEATURES.keys())
            self.config.deployment_options = ["docker", "docker_compose"]
            return True
        
        if args.name:
            self.config.project_name = args.name
        
        if args.all_platforms:
            self.config.selected_platforms = list(self.PLATFORMS.keys())
        elif args.platforms:
            self.config.selected_platforms = args.platforms
        
        if args.all_features:
            self.config.selected_features = list(self.FEATURES.keys())
        elif args.features:
            self.config.selected_features = args.features
        
        if args.no_docker:
            self.config.use_docker = False
        
        if args.with_k8s:
            self.config.use_k8s = True
            self.config.deployment_options.extend(["kubernetes", "helm"])
        
        # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œè¿”å›Trueè·³è¿‡äº¤äº’å¼é…ç½®
        return any([args.name, args.platforms, args.all_platforms, 
                   args.features, args.all_features])
    
    def interactive_config(self):
        """äº¤äº’å¼é…ç½®"""
        # é¡¹ç›®åŸºæœ¬ä¿¡æ¯
        print_colored("\nğŸ“‹ é¡¹ç›®åŸºæœ¬ä¿¡æ¯", Colors.BLUE, bold=True)
        self.config.project_name = input(f"é¡¹ç›®åç§° [{self.config.project_name}]: ") or self.config.project_name
        self.config.author_name = input("ä½œè€…å§“å: ") or "Your Name"
        self.config.author_email = input("ä½œè€…é‚®ç®±: ") or "your.email@example.com"
        
        # é€‰æ‹©å¹³å°
        print_colored("\nğŸ”Œ é€‰æ‹©è¦æ”¯æŒçš„å¹³å°", Colors.BLUE, bold=True)
        print("0. å…¨é€‰")
        for i, (key, name) in enumerate(self.PLATFORMS.items(), 1):
            print(f"{i}. {name} ({key})")
        
        platform_choices = input("è¯·é€‰æ‹©å¹³å°ï¼ˆå¤šä¸ªç”¨ç©ºæ ¼åˆ†éš”ï¼Œå¦‚: 1 2 3ï¼‰: ").strip()
        if platform_choices == "0":
            self.config.selected_platforms = list(self.PLATFORMS.keys())
        else:
            indices = [int(x) - 1 for x in platform_choices.split() if x.isdigit()]
            platform_keys = list(self.PLATFORMS.keys())
            self.config.selected_platforms = [platform_keys[i] for i in indices if 0 <= i < len(platform_keys)]
        
        # é€‰æ‹©ç‰¹æ€§
        print_colored("\nâœ¨ é€‰æ‹©é¡¹ç›®ç‰¹æ€§", Colors.BLUE, bold=True)
        print("0. å…¨é€‰ï¼ˆæ¨èï¼‰")
        for i, (key, name) in enumerate(self.FEATURES.items(), 1):
            print(f"{i}. {name}")
        
        feature_choices = input("è¯·é€‰æ‹©ç‰¹æ€§ï¼ˆå¤šä¸ªç”¨ç©ºæ ¼åˆ†éš”ï¼‰: ").strip()
        if feature_choices == "0":
            self.config.selected_features = list(self.FEATURES.keys())
        else:
            indices = [int(x) - 1 for x in feature_choices.split() if x.isdigit()]
            feature_keys = list(self.FEATURES.keys())
            self.config.selected_features = [feature_keys[i] for i in indices if 0 <= i < len(feature_keys)]
        
        # éƒ¨ç½²é€‰é¡¹
        print_colored("\nğŸš€ éƒ¨ç½²é…ç½®", Colors.BLUE, bold=True)
        use_docker = input("ä½¿ç”¨Dockerï¼Ÿ(Y/n): ").strip().lower()
        self.config.use_docker = use_docker != 'n'
        
        if self.config.use_docker:
            self.config.deployment_options.append("docker")
            use_compose = input("ä½¿ç”¨Docker Composeï¼Ÿ(Y/n): ").strip().lower()
            if use_compose != 'n':
                self.config.deployment_options.append("docker_compose")
        
        use_k8s = input("åŒ…å«Kubernetesé…ç½®ï¼Ÿ(y/N): ").strip().lower()
        if use_k8s == 'y':
            self.config.use_k8s = True
            self.config.deployment_options.extend(["kubernetes", "helm"])
    
    def confirm_config(self) -> bool:
        """ç¡®è®¤é…ç½®"""
        print_colored("\nğŸ“ é…ç½®ç¡®è®¤", Colors.GREEN, bold=True)
        print(f"é¡¹ç›®åç§°: {self.config.project_name}")
        print(f"ä½œè€…: {self.config.author_name} <{self.config.author_email}>")
        print(f"Pythonç‰ˆæœ¬: {self.config.python_version}")
        print(f"é€‰æ‹©çš„å¹³å°: {', '.join([self.PLATFORMS[p] for p in self.config.selected_platforms])}")
        print(f"é€‰æ‹©çš„ç‰¹æ€§: {', '.join([self.FEATURES[f] for f in self.config.selected_features])}")
        print(f"éƒ¨ç½²é€‰é¡¹: {', '.join(self.config.deployment_options)}")
        
        confirm = input("\nç¡®è®¤åˆ›å»ºé¡¹ç›®ï¼Ÿ(Y/n): ").strip().lower()
        return confirm != 'n'
    
    def create_project(self):
        """åˆ›å»ºé¡¹ç›®"""
        self.project_path = Path(self.config.project_name)
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if self.project_path.exists():
            overwrite = input(f"\nâš ï¸  ç›®å½• {self.config.project_name} å·²å­˜åœ¨ï¼Œæ˜¯å¦è¦†ç›–ï¼Ÿ(y/N): ").strip().lower()
            if overwrite != 'y':
                print_colored("å·²å–æ¶ˆåˆ›å»º", Colors.YELLOW)
                sys.exit(0)
            shutil.rmtree(self.project_path)
        
        print_colored(f"\nğŸ”¨ å¼€å§‹åˆ›å»ºé¡¹ç›®: {self.config.project_name}", Colors.GREEN, bold=True)
        
        # åˆ›å»ºç›®å½•ç»“æ„
        self._create_directory_structure()
        
        # åˆ›å»ºé…ç½®æ–‡ä»¶
        self._create_config_files()
        
        # åˆ›å»ºæºä»£ç 
        self._create_source_code()
        
        # åˆ›å»ºDockeræ–‡ä»¶
        if self.config.use_docker:
            self._create_docker_files()
        
        # åˆ›å»ºKubernetesæ–‡ä»¶
        if self.config.use_k8s:
            self._create_k8s_files()
        
        # åˆ›å»ºæ–‡æ¡£
        self._create_documentation()
        
        # åˆå§‹åŒ–Git
        self._init_git()
        
        print_colored("âœ… é¡¹ç›®åˆ›å»ºå®Œæˆï¼", Colors.GREEN, bold=True)
    
    def _create_directory_structure(self):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        print("  ğŸ“ åˆ›å»ºç›®å½•ç»“æ„...")
        
        # åŸºç¡€ç›®å½•
        directories = [
            "src/core/config",
            "src/core/database",
            "src/core/redis",
            "src/core/models",
            "src/utils/logger",
            "src/utils/validators",
            "src/utils/helpers",
            "src/api/v1/endpoints",
            "src/api/v1/schemas",
            "src/api/middleware",
            "tests/unit",
            "tests/integration",
            "tests/fixtures",
            "docs/api",
            "docs/guides",
            "scripts/setup",
            "scripts/deploy",
            "logs",
            "data/raw",
            "data/processed",
            "data/cache",
        ]
        
        # æ ¹æ®é€‰æ‹©çš„ç‰¹æ€§æ·»åŠ ç›®å½•
        if "dual_engine" in self.config.selected_features:
            directories.extend([
                "src/engines/base",
                "src/engines/crawl4ai",
                "src/engines/mediacrawl"
            ])
        
        if "anti_detection" in self.config.selected_features:
            directories.extend([
                "src/core/anti_detection/proxy_pool",
                "src/core/anti_detection/fingerprint",
                "src/core/anti_detection/behavior"
            ])
        
        if "data_processing" in self.config.selected_features:
            directories.extend([
                "src/processors/cleaner",
                "src/processors/deduplicator",
                "src/processors/enhancer"
            ])
        
        if "scheduler" in self.config.selected_features:
            directories.append("src/core/scheduler")
        
        if "monitoring" in self.config.selected_features:
            directories.extend([
                "monitoring/prometheus",
                "monitoring/grafana/dashboards"
            ])
        
        # å¹³å°é€‚é…å™¨ç›®å½•
        directories.append("src/adapters/base")
        for platform in self.config.selected_platforms:
            directories.append(f"src/adapters/{platform}")
        
        # Dockerç›®å½•
        if self.config.use_docker:
            directories.extend([
                "docker/development",
                "docker/production"
            ])
        
        # Kubernetesç›®å½•
        if self.config.use_k8s:
            directories.extend([
                "k8s/base",
                "k8s/overlays/dev",
                "k8s/overlays/prod",
                "k8s/charts"
            ])
        
        # åˆ›å»ºæ‰€æœ‰ç›®å½•
        for directory in directories:
            (self.project_path / directory).mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»º__init__.pyæ–‡ä»¶
        for root, dirs, _ in os.walk(self.project_path / "src"):
            for dir_name in dirs:
                init_file = Path(root) / dir_name / "__init__.py"
                init_file.touch()
        
        # åˆ›å»º.gitkeepæ–‡ä»¶
        for data_dir in ["raw", "processed", "cache"]:
            gitkeep = self.project_path / "data" / data_dir / ".gitkeep"
            gitkeep.touch()
    
    def _create_config_files(self):
        """åˆ›å»ºé…ç½®æ–‡ä»¶"""
        print("  ğŸ“„ åˆ›å»ºé…ç½®æ–‡ä»¶...")
        
        # pyproject.toml
        dependencies = {
            "python": "^3.11",
            "fastapi": "^0.104.0",
            "uvicorn": {"extras": ["standard"], "version": "^0.24.0"},
            "sqlalchemy": {"extras": ["asyncio"], "version": "^2.0.0"},
            "asyncpg": "^0.29.0",
            "redis": "^5.0.0",
            "pydantic": "^2.5.0",
            "pydantic-settings": "^2.1.0",
            "loguru": "^0.7.0",
            "httpx": "^0.25.0",
            "beautifulsoup4": "^4.12.0",
            "lxml": "^5.0.0"
        }
        
        # æ ¹æ®é€‰æ‹©çš„ç‰¹æ€§æ·»åŠ ä¾èµ–
        if "dual_engine" in self.config.selected_features:
            dependencies["crawl4ai"] = "^0.2.0"
            dependencies["playwright"] = "^1.40.0"
        
        if "jwt_auth" in self.config.selected_features:
            dependencies["python-jose"] = {"extras": ["cryptography"], "version": "^3.3.0"}
            dependencies["passlib"] = {"extras": ["bcrypt"], "version": "^1.7.4"}
            dependencies["python-multipart"] = "^0.0.6"
        
        if "scheduler" in self.config.selected_features:
            dependencies["celery"] = {"extras": ["redis"], "version": "^5.3.0"}
        
        if "monitoring" in self.config.selected_features:
            dependencies["prometheus-client"] = "^0.19.0"
        
        if "anti_detection" in self.config.selected_features:
            dependencies["fake-useragent"] = "^1.4.0"
            dependencies["cloudscraper"] = "^1.2.0"
        
        pyproject_content = {
            "tool": {
                "poetry": {
                    "name": self.config.project_name,
                    "version": "1.0.0",
                    "description": "æ™ºèƒ½æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿ",
                    "authors": [f"{self.config.author_name} <{self.config.author_email}>"],
                    "readme": "README.md",
                    "packages": [{"include": "src"}],
                    "dependencies": dependencies,
                    "group": {
                        "dev": {
                            "dependencies": {
                                "pytest": "^7.4.0",
                                "pytest-asyncio": "^0.21.0",
                                "pytest-cov": "^4.1.0",
                                "black": "^23.0.0",
                                "ruff": "^0.1.0",
                                "mypy": "^1.7.0",
                                "pre-commit": "^3.5.0"
                            }
                        }
                    }
                },
                "black": {
                    "line-length": 100,
                    "target-version": ["py311"]
                },
                "ruff": {
                    "line-length": 100,
                    "select": ["E", "F", "I", "N", "W"],
                    "ignore": ["E501"]
                },
                "pytest": {
                    "ini_options": {
                        "testpaths": ["tests"],
                        "python_files": ["test_*.py", "*_test.py"],
                        "addopts": "-ra -q --strict-markers",
                        "asyncio_mode": "auto"
                    }
                }
            },
            "build-system": {
                "requires": ["poetry-core"],
                "build-backend": "poetry.core.masonry.api"
            }
        }
        
        with open(self.project_path / "pyproject.toml", "w") as f:
            # ç®€åŒ–çš„TOMLå†™å…¥ï¼ˆå®é™…åº”ä½¿ç”¨tomlåº“ï¼‰
            f.write("[tool.poetry]\n")
            f.write(f'name = "{pyproject_content["tool"]["poetry"]["name"]}"\n')
            f.write(f'version = "{pyproject_content["tool"]["poetry"]["version"]}"\n')
            f.write(f'description = "{pyproject_content["tool"]["poetry"]["description"]}"\n')
            f.write(f'authors = {pyproject_content["tool"]["poetry"]["authors"]}\n')
            f.write('readme = "README.md"\n')
            f.write('packages = [{include = "src"}]\n\n')
            
            f.write("[tool.poetry.dependencies]\n")
            for dep, version in dependencies.items():
                if isinstance(version, dict):
                    extras = version.get("extras", [])
                    ver = version["version"]
                    if extras:
                        f.write(f'{dep} = {{extras = {extras}, version = "{ver}"}}\n')
                    else:
                        f.write(f'{dep} = "{ver}"\n')
                else:
                    f.write(f'{dep} = "{version}"\n')
            
            f.write("\n[tool.poetry.group.dev.dependencies]\n")
            for dep, version in pyproject_content["tool"]["poetry"]["group"]["dev"]["dependencies"].items():
                f.write(f'{dep} = "{version}"\n')
            
            f.write("\n[build-system]\n")
            f.write('requires = ["poetry-core"]\n')
            f.write('build-backend = "poetry.core.masonry.api"\n')
        
        # .env.example
        self._create_env_example()
        
        # .gitignore
        self._create_gitignore()
        
        # README.md
        self._create_readme()
    
    def _create_env_example(self):
        """åˆ›å»º.env.exampleæ–‡ä»¶"""
        env_content = f"""# åº”ç”¨é…ç½®
APP_NAME={self.config.project_name}
APP_ENV=development
DEBUG=true
SECRET_KEY=your-secret-key-here

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://crawler:password@localhost:5432/crawler_db
DATABASE_POOL_SIZE=20

# Redisé…ç½®
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=100

# APIé…ç½®
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
"""
        
        if "dual_engine" in self.config.selected_features:
            env_content += """
# çˆ¬è™«å¼•æ“é…ç½®
CRAWLER_MAX_WORKERS=10
CRAWLER_TIMEOUT=30
CRAWLER_RETRY_TIMES=3
"""
        
        if "anti_detection" in self.config.selected_features:
            env_content += """
# åçˆ¬é…ç½®
PROXY_POOL_ENABLE=true
PROXY_POOL_MIN_SIZE=100
USER_AGENT_POOL_SIZE=1000
"""
        
        if "jwt_auth" in self.config.selected_features:
            env_content += """
# JWTé…ç½®
JWT_SECRET_KEY=your-jwt-secret-key
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24
"""
        
        if "monitoring" in self.config.selected_features:
            env_content += """
# ç›‘æ§é…ç½®
METRICS_ENABLE=true
METRICS_PORT=9090
"""
        
        # å¹³å°APIå¯†é’¥
        env_content += "\n# å¹³å°APIå¯†é’¥\n"
        for platform in self.config.selected_platforms:
            env_content += f"{platform.upper()}_API_KEY=\n"
        
        with open(self.project_path / ".env.example", "w") as f:
            f.write(env_content)
    
    def _create_gitignore(self):
        """åˆ›å»º.gitignoreæ–‡ä»¶"""
        gitignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
.venv/
*.egg-info/

# Poetry
poetry.lock

# IDE
.idea/
.vscode/
*.swp
*.swo

# Testing
.coverage
.pytest_cache/
htmlcov/
.tox/

# Logs
logs/
*.log

# Environment
.env
.env.*

# Data
data/raw/*
data/processed/*
data/cache/*
!data/*/.gitkeep

# OS
.DS_Store
Thumbs.db

# Project specific
*.db
*.sqlite
"""
        
        with open(self.project_path / ".gitignore", "w") as f:
            f.write(gitignore_content)
    
    def _create_readme(self):
        """åˆ›å»ºREADME.md"""
        platforms_list = "\n".join([f"- {self.PLATFORMS[p]}" for p in self.config.selected_platforms])
        features_list = "\n".join([f"- {self.FEATURES[f]}" for f in self.config.selected_features])
        
        readme_content = f"""# {self.config.project_name}

æ™ºèƒ½æ—…æ¸¸å¹³å°æ•°æ®çˆ¬è™«ç³»ç»Ÿï¼Œæ”¯æŒå¤šå¹³å°æ•°æ®é‡‡é›†ä¸å¤„ç†ã€‚

## æ”¯æŒçš„å¹³å°

{platforms_list}

## æ ¸å¿ƒç‰¹æ€§

{features_list}

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python {self.config.python_version}+
- PostgreSQL 15+
- Redis 7+
"""
        
        if self.config.use_docker:
            readme_content += """
### Dockeréƒ¨ç½²

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```
"""
        
        readme_content += """
### æœ¬åœ°å¼€å‘

```bash
# å®‰è£…ä¾èµ–
poetry install

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶

# è¿è¡Œæ•°æ®åº“è¿ç§»
poetry run alembic upgrade head

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
poetry run uvicorn src.main:app --reload
```

## APIæ–‡æ¡£

å¯åŠ¨æœåŠ¡åè®¿é—®: http://localhost:8000/docs

## é¡¹ç›®ç»“æ„

```
{}/
â”œâ”€â”€ src/                    # æºä»£ç 
â”‚   â”œâ”€â”€ core/              # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ engines/           # çˆ¬è™«å¼•æ“
â”‚   â”œâ”€â”€ adapters/          # å¹³å°é€‚é…å™¨
â”‚   â”œâ”€â”€ processors/        # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ api/              # APIæ¥å£
â”‚   â””â”€â”€ utils/            # å·¥å…·å‡½æ•°
â”œâ”€â”€ tests/                 # æµ‹è¯•ä»£ç 
â”œâ”€â”€ docs/                  # æ–‡æ¡£
â”œâ”€â”€ scripts/               # è„šæœ¬å·¥å…·
â””â”€â”€ docker/                # Dockeré…ç½®
```

## è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## License

MIT License

---

Created with â¤ï¸ by {}
""".format(self.config.project_name, self.config.author_name)
        
        with open(self.project_path / "README.md", "w") as f:
            f.write(readme_content)
    
    def _create_source_code(self):
        """åˆ›å»ºæºä»£ç """
        print("  ğŸ’» åˆ›å»ºæºä»£ç ...")
        
        # ä¸»åº”ç”¨å…¥å£
        self._create_main_app()
        
        # é…ç½®ç®¡ç†
        self._create_settings()
        
        # æ—¥å¿—æ¨¡å—
        self._create_logger()
        
        # æ•°æ®åº“è¿æ¥
        self._create_database()
        
        # APIè·¯ç”±
        self._create_api_router()
        
        # æ ¹æ®é€‰æ‹©çš„ç‰¹æ€§åˆ›å»ºç›¸åº”ä»£ç 
        if "dual_engine" in self.config.selected_features:
            self._create_engine_base()
        
        if "anti_detection" in self.config.selected_features:
            self._create_anti_detection_base()
        
        # åˆ›å»ºå¹³å°é€‚é…å™¨åŸºç±»
        self._create_adapter_base()
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        self._create_test_files()
    
    def _create_main_app(self):
        """åˆ›å»ºä¸»åº”ç”¨æ–‡ä»¶"""
        imports = [
            "from fastapi import FastAPI",
            "from fastapi.middleware.cors import CORSMiddleware",
            "from contextlib import asynccontextmanager",
            "from src.core.config.settings import get_settings",
            "from src.core.database.connection import init_db",
            "from src.api.v1.router import api_router",
            "from src.utils.logger.logger import setup_logger"
        ]
        
        if "monitoring" in self.config.selected_features:
            imports.append("from prometheus_client import make_asgi_app")
        
        main_content = f"""\"\"\"
{self.config.project_name} - ä¸»åº”ç”¨å…¥å£
\"\"\"
{chr(10).join(imports)}

settings = get_settings()
logger = setup_logger()

@asynccontextmanager
async def lifespan(app: FastAPI):
    \"\"\"åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†\"\"\"
    logger.info("Starting {self.config.project_name}...")
    await init_db()
    yield
    logger.info("Shutting down {self.config.project_name}...")

app = FastAPI(
    title="{self.config.project_name}",
    description="æ™ºèƒ½æ—…æ¸¸æ•°æ®é‡‡é›†ä¸å¤„ç†å¹³å°",
    version="1.0.0",
    lifespan=lifespan
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œè·¯ç”±
app.include_router(api_router, prefix="/api/v1")
"""
        
        if "monitoring" in self.config.selected_features:
            main_content += """
# Prometheus metrics
metrics_app = make_asgi_app()
app.mount("/metrics", metrics_app)
"""
        
        main_content += """
@app.get("/")
async def root():
    return {
        "message": f"Welcome to {settings.app_name}",
        "version": "1.0.0",
        "docs": "/docs"
    }

@app.get("/health")
async def health_check():
    return {"status": "healthy"}
"""
        
        with open(self.project_path / "src" / "main.py", "w") as f:
            f.write(main_content)
    
    def _create_settings(self):
        """åˆ›å»ºé…ç½®æ–‡ä»¶"""
        settings_content = f'''"""é…ç½®ç®¡ç†æ¨¡å—"""
from pydantic_settings import BaseSettings
from functools import lru_cache
from typing import Optional

class Settings(BaseSettings):
    """åº”ç”¨é…ç½®"""
    # åŸºç¡€é…ç½®
    app_name: str = "{self.config.project_name}"
    app_env: str = "development"
    debug: bool = True
    secret_key: str
    
    # æ•°æ®åº“
    database_url: str
    database_pool_size: int = 20
    
    # Redis
    redis_url: str
    redis_max_connections: int = 100
    
    # API
    api_host: str = "0.0.0.0"
    api_port: int = 8000
'''
        
        if "dual_engine" in self.config.selected_features:
            settings_content += '''
    # çˆ¬è™«é…ç½®
    crawler_max_workers: int = 10
    crawler_timeout: int = 30
    crawler_retry_times: int = 3
'''
        
        if "jwt_auth" in self.config.selected_features:
            settings_content += '''
    # JWT
    jwt_secret_key: str
    jwt_algorithm: str = "HS256"
    jwt_expiration_hours: int = 24
'''
        
        settings_content += '''
    class Config:
        env_file = ".env"
        case_sensitive = False

@lru_cache()
def get_settings() -> Settings:
    return Settings()
'''
        
        with open(self.project_path / "src" / "core" / "config" / "settings.py", "w") as f:
            f.write(settings_content)
    
    def _create_logger(self):
        """åˆ›å»ºæ—¥å¿—æ¨¡å—"""
        logger_content = '''"""æ—¥å¿—ç®¡ç†æ¨¡å—"""
from loguru import logger
import sys
from pathlib import Path

def setup_logger():
    """é…ç½®æ—¥å¿—"""
    logger.remove()
    
    # æ§åˆ¶å°æ—¥å¿—
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO"
    )
    
    # æ–‡ä»¶æ—¥å¿—
    log_path = Path("logs")
    log_path.mkdir(exist_ok=True)
    
    logger.add(
        "logs/app_{time:YYYY-MM-DD}.log",
        rotation="1 day",
        retention="30 days",
        level="DEBUG"
    )
    
    return logger

def get_logger(name: str):
    return logger.bind(name=name)
'''
        
        with open(self.project_path / "src" / "utils" / "logger" / "logger.py", "w") as f:
            f.write(logger_content)
    
    def _create_database(self):
        """åˆ›å»ºæ•°æ®åº“æ¨¡å—"""
        db_content = '''"""æ•°æ®åº“è¿æ¥ç®¡ç†"""
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker
from sqlalchemy.orm import declarative_base
from src.core.config.settings import get_settings

settings = get_settings()

engine = create_async_engine(
    settings.database_url,
    echo=settings.debug,
    pool_size=settings.database_pool_size
)

AsyncSessionLocal = async_sessionmaker(engine, expire_on_commit=False)
Base = declarative_base()

async def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

async def get_db():
    """è·å–æ•°æ®åº“ä¼šè¯"""
    async with AsyncSessionLocal() as session:
        try:
            yield session
        finally:
            await session.close()
'''
        
        with open(self.project_path / "src" / "core" / "database" / "connection.py", "w") as f:
            f.write(db_content)
    
    def _create_api_router(self):
        """åˆ›å»ºAPIè·¯ç”±"""
        router_content = '''"""APIè·¯ç”±é…ç½®"""
from fastapi import APIRouter
from src.api.v1.endpoints import crawler, data, platform

api_router = APIRouter()

# çˆ¬è™«ç›¸å…³è·¯ç”±
api_router.include_router(
    crawler.router,
    prefix="/crawler",
    tags=["çˆ¬è™«ç®¡ç†"]
)

# æ•°æ®ç›¸å…³è·¯ç”±
api_router.include_router(
    data.router,
    prefix="/data",
    tags=["æ•°æ®ç®¡ç†"]
)

# å¹³å°ç›¸å…³è·¯ç”±
api_router.include_router(
    platform.router,
    prefix="/platform",
    tags=["å¹³å°ç®¡ç†"]
)
'''
        
        with open(self.project_path / "src" / "api" / "v1" / "router.py", "w") as f:
            f.write(router_content)
        
        # åˆ›å»ºç¤ºä¾‹ç«¯ç‚¹
        crawler_endpoint = '''"""çˆ¬è™«ç®¡ç†ç«¯ç‚¹"""
from fastapi import APIRouter, HTTPException
from typing import Dict, Any

router = APIRouter()

@router.post("/task")
async def create_crawl_task(task_data: Dict[str, Any]):
    """åˆ›å»ºçˆ¬å–ä»»åŠ¡"""
    return {"task_id": "example-task-id", "status": "pending"}

@router.get("/task/{task_id}")
async def get_task_status(task_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    return {"task_id": task_id, "status": "running", "progress": 50}
'''
        
        with open(self.project_path / "src" / "api" / "v1" / "endpoints" / "crawler.py", "w") as f:
            f.write(crawler_endpoint)
        
        # åˆ›å»ºç©ºçš„å…¶ä»–ç«¯ç‚¹æ–‡ä»¶
        for endpoint in ["data", "platform"]:
            endpoint_content = f'''"""ï¿„{endpoint.capitalize()}ç®¡ç†ç«¯ç‚¹"""
from fastapi import APIRouter

router = APIRouter()

@router.get("/")
async def get_{endpoint}_list():
    """è·å–{endpoint}åˆ—è¡¨"""
    return []
'''
            with open(self.project_path / "src" / "api" / "v1" / "endpoints" / f"{endpoint}.py", "w") as f:
                f.write(endpoint_content)
    
    def _create_engine_base(self):
        """åˆ›å»ºå¼•æ“åŸºç±»"""
        engine_base = '''"""çˆ¬è™«å¼•æ“åŸºç±»"""
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from dataclasses import dataclass
from enum import Enum

class EngineType(Enum):
    CRAWL4AI = "crawl4ai"
    MEDIACRAWL = "mediacrawl"

@dataclass
class CrawlTask:
    """çˆ¬å–ä»»åŠ¡"""
    task_id: str
    url: str
    platform: str
    engine_type: EngineType
    headers: Optional[Dict[str, str]] = None
    params: Optional[Dict[str, Any]] = None
    timeout: int = 30

class BaseEngine(ABC):
    """å¼•æ“åŸºç±»"""
    
    @abstractmethod
    async def crawl(self, task: CrawlTask) -> Dict[str, Any]:
        """æ‰§è¡Œçˆ¬å–"""
        pass
    
    @abstractmethod
    async def init(self):
        """åˆå§‹åŒ–å¼•æ“"""
        pass
    
    @abstractmethod
    async def close(self):
        """å…³é—­å¼•æ“"""
        pass
'''
        
        with open(self.project_path / "src" / "engines" / "base" / "engine_interface.py", "w") as f:
            f.write(engine_base)
    
    def _create_anti_detection_base(self):
        """åˆ›å»ºåçˆ¬åŸºç¡€æ¨¡å—"""
        proxy_manager = '''"""ä»£ç†æ± ç®¡ç†å™¨"""
from typing import List, Optional
import random

class ProxyPoolManager:
    """ä»£ç†æ± ç®¡ç†"""
    
    def __init__(self):
        self.proxies: List[str] = []
        self.failed_proxies: set = set()
    
    async def get_proxy(self) -> Optional[str]:
        """è·å–å¯ç”¨ä»£ç†"""
        available = [p for p in self.proxies if p not in self.failed_proxies]
        return random.choice(available) if available else None
    
    async def mark_failed(self, proxy: str):
        """æ ‡è®°å¤±è´¥ä»£ç†"""
        self.failed_proxies.add(proxy)
    
    async def refresh_pool(self):
        """åˆ·æ–°ä»£ç†æ± """
        # å®ç°ä»£ç†æ± åˆ·æ–°é€»è¾‘
        pass
'''
        
        with open(self.project_path / "src" / "core" / "anti_detection" / "proxy_pool" / "manager.py", "w") as f:
            f.write(proxy_manager)
    
    def _create_adapter_base(self):
        """åˆ›å»ºé€‚é…å™¨åŸºç±»"""
        adapter_base = '''"""å¹³å°é€‚é…å™¨åŸºç±»"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional

class PlatformAdapter(ABC):
    """å¹³å°é€‚é…å™¨åŸºç±»"""
    
    def __init__(self):
        self.platform_name = ""
        self.base_url = ""
    
    @abstractmethod
    async def search(self, keyword: str, **kwargs) -> List[Dict[str, Any]]:
        """æœç´¢æ•°æ®"""
        pass
    
    @abstractmethod
    async def get_detail(self, item_id: str) -> Dict[str, Any]:
        """è·å–è¯¦æƒ…"""
        pass
    
    @abstractmethod
    async def parse_data(self, raw_data: Any) -> Dict[str, Any]:
        """è§£ææ•°æ®"""
        pass
'''
        
        with open(self.project_path / "src" / "adapters" / "base" / "adapter_interface.py", "w") as f:
            f.write(adapter_base)
    
    def _create_test_files(self):
        """åˆ›å»ºæµ‹è¯•æ–‡ä»¶"""
        test_main = '''"""ä¸»åº”ç”¨æµ‹è¯•"""
import pytest
from httpx import AsyncClient
from src.main import app

@pytest.mark.asyncio
async def test_root():
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.get("/")
    assert response.status_code == 200

@pytest.mark.asyncio
async def test_health():
    async with AsyncClient(app=app, base_url="http://test") as client:
        response = await client.get("/health")
    assert response.status_code == 200
    assert response.json()["status"] == "healthy"
'''
        
        with open(self.project_path / "tests" / "test_main.py", "w") as f:
            f.write(test_main)
    
    def _create_docker_files(self):
        """åˆ›å»ºDockeræ–‡ä»¶"""
        print("  ğŸ³ åˆ›å»ºDockeré…ç½®...")
        
        # Docker Compose
        compose_content = f"""version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: crawler
      POSTGRES_PASSWORD: password
      POSTGRES_DB: crawler_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  app:
    build:
      context: .
      dockerfile: docker/development/Dockerfile
    depends_on:
      - postgres
      - redis
    environment:
      DATABASE_URL: postgresql+asyncpg://crawler:password@postgres:5432/crawler_db
      REDIS_URL: redis://redis:6379/0
    volumes:
      - ./src:/app/src
    ports:
      - "8000:8000"
"""
        
        if "monitoring" in self.config.selected_features:
            compose_content += """
  prometheus:
    image: prom/prometheus
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana
    depends_on:
      - prometheus
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    ports:
      - "3000:3000"
"""
        
        compose_content += """
volumes:
  postgres_data:
  redis_data:"""
        
        if "monitoring" in self.config.selected_features:
            compose_content += """
  prometheus_data:
  grafana_data:"""
        
        with open(self.project_path / "docker-compose.yml", "w") as f:
            f.write(compose_content)
        
        # Development Dockerfile
        dockerfile_content = f"""FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \\
    gcc \\
    curl \\
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Poetry
RUN pip install poetry

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY pyproject.toml poetry.lock* ./

# å®‰è£…ä¾èµ–
RUN poetry config virtualenvs.create false \\
    && poetry install --no-interaction
"""
        
        if "dual_engine" in self.config.selected_features:
            dockerfile_content += """
# å®‰è£…Playwright
RUN playwright install chromium
RUN playwright install-deps chromium
"""
        
        dockerfile_content += """
# å¤åˆ¶æºä»£ç 
COPY . .

EXPOSE 8000

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
"""
        
        with open(self.project_path / "docker" / "development" / "Dockerfile", "w") as f:
            f.write(dockerfile_content)
    
    def _create_k8s_files(self):
        """åˆ›å»ºKubernetesæ–‡ä»¶"""
        print("  â˜¸ï¸  åˆ›å»ºKubernetesé…ç½®...")
        
        # Deployment
        deployment_content = f"""apiVersion: apps/v1
kind: Deployment
metadata:
  name: {self.config.project_name}-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: {self.config.project_name}-api
  template:
    metadata:
      labels:
        app: {self.config.project_name}-api
    spec:
      containers:
      - name: api
        image: {self.config.project_name}:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: {self.config.project_name}-secrets
              key: database-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
"""
        
        with open(self.project_path / "k8s" / "base" / "deployment.yaml", "w") as f:
            f.write(deployment_content)
        
        # Service
        service_content = f"""apiVersion: v1
kind: Service
metadata:
  name: {self.config.project_name}-api
spec:
  selector:
    app: {self.config.project_name}-api
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer
"""
        
        with open(self.project_path / "k8s" / "base" / "service.yaml", "w") as f:
            f.write(service_content)
    
    def _create_documentation(self):
        """åˆ›å»ºæ–‡æ¡£"""
        print("  ğŸ“š åˆ›å»ºæ–‡æ¡£...")
        
        # APIæ–‡æ¡£è¯´æ˜
        api_doc = f"""# {self.config.project_name} APIæ–‡æ¡£

## æ¦‚è¿°

æœ¬æ–‡æ¡£æè¿°äº†{self.config.project_name}çš„APIæ¥å£ã€‚

## è®¤è¯

"""
        
        if "jwt_auth" in self.config.selected_features:
            api_doc += """æ‰€æœ‰APIè¯·æ±‚éœ€è¦åœ¨Headerä¸­åŒ…å«JWT Tokenï¼š

```
Authorization: Bearer <token>
```

### è·å–Token

POST /api/v1/auth/login
"""
        else:
            api_doc += "å½“å‰APIä¸éœ€è¦è®¤è¯ã€‚"
        
        api_doc += """

## æ¥å£åˆ—è¡¨

### çˆ¬è™«ç®¡ç†

- POST /api/v1/crawler/task - åˆ›å»ºçˆ¬å–ä»»åŠ¡
- GET /api/v1/crawler/task/{task_id} - è·å–ä»»åŠ¡çŠ¶æ€

### æ•°æ®ç®¡ç†

- GET /api/v1/data - è·å–æ•°æ®åˆ—è¡¨
- GET /api/v1/data/{id} - è·å–æ•°æ®è¯¦æƒ…

### å¹³å°ç®¡ç†

- GET /api/v1/platform - è·å–æ”¯æŒçš„å¹³å°åˆ—è¡¨
"""
        
        with open(self.project_path / "docs" / "api" / "README.md", "w") as f:
            f.write(api_doc)
        
        # éƒ¨ç½²æŒ‡å—
        deploy_guide = f"""# éƒ¨ç½²æŒ‡å—

## ç¯å¢ƒè¦æ±‚

- Python {self.config.python_version}+
- PostgreSQL 15+
- Redis 7+
"""
        
        if self.config.use_docker:
            deploy_guide += """
## Dockeréƒ¨ç½²

### å¼€å‘ç¯å¢ƒ

```bash
docker-compose up -d
```

### ç”Ÿäº§ç¯å¢ƒ

```bash
docker build -f docker/production/Dockerfile -t {project_name}:latest .
docker run -d -p 8000:8000 --env-file .env {project_name}:latest
```
""".format(project_name=self.config.project_name)
        
        if self.config.use_k8s:
            deploy_guide += """
## Kuberneteséƒ¨ç½²

### ä½¿ç”¨kubectl

```bash
kubectl apply -k k8s/base
```

### ä½¿ç”¨Helm

```bash
helm install {project_name} ./k8s/charts/{project_name}
```
""".format(project_name=self.config.project_name)
        
        with open(self.project_path / "docs" / "guides" / "deployment.md", "w") as f:
            f.write(deploy_guide)
    
    def _init_git(self):
        """åˆå§‹åŒ–Gitä»“åº“"""
        print("  ğŸ“¦ åˆå§‹åŒ–Gitä»“åº“...")
        
        try:
            subprocess.run(["git", "init"], cwd=self.project_path, check=True, capture_output=True)
            subprocess.run(["git", "add", "."], cwd=self.project_path, check=True, capture_output=True)
            subprocess.run(
                ["git", "commit", "-m", "Initial commit: Project scaffold"], 
                cwd=self.project_path, 
                check=True, 
                capture_output=True
            )
        except subprocess.CalledProcessError:
            print_colored("    âš ï¸  Gitåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨åˆå§‹åŒ–", Colors.YELLOW)
    
    def show_completion_info(self):
        """æ˜¾ç¤ºå®Œæˆä¿¡æ¯"""
        print()
        print_colored("="*60, Colors.GREEN)
        print_colored(f"ğŸ‰ é¡¹ç›® {self.config.project_name} åˆ›å»ºæˆåŠŸï¼", Colors.GREEN, bold=True)
        print_colored("="*60, Colors.GREEN)
        print()
        
        print_colored("ğŸ“‹ é¡¹ç›®ä¿¡æ¯", Colors.BLUE, bold=True)
        print(f"  è·¯å¾„: {self.project_path.absolute()}")
        print(f"  å¹³å°: {len(self.config.selected_platforms)}ä¸ª")
        print(f"  ç‰¹æ€§: {len(self.config.selected_features)}ä¸ª")
        print()
        
        print_colored("ğŸš€ å¿«é€Ÿå¼€å§‹", Colors.BLUE, bold=True)
        print(f"  1. cd {self.config.project_name}")
        print("  2. cp .env.example .env")
        print("  3. # ç¼–è¾‘ .env æ–‡ä»¶é…ç½®æ•°æ®åº“ç­‰ä¿¡æ¯")
        
        if self.config.use_docker:
            print("  4. docker-compose up -d")
            print("  5. è®¿é—® http://localhost:8000/docs")
        else:
            print("  4. poetry install")
            print("  5. poetry run uvicorn src.main:app --reload")
            print("  6. è®¿é—® http://localhost:8000/docs")
        
        print()
        print_colored("ğŸ“š ç›¸å…³æ–‡æ¡£", Colors.BLUE, bold=True)
        print("  - APIæ–‡æ¡£: docs/api/README.md")
        print("  - éƒ¨ç½²æŒ‡å—: docs/guides/deployment.md")
        print("  - é¡¹ç›®è¯´æ˜: README.md")
        
        if "monitoring" in self.config.selected_features and self.config.use_docker:
            print()
            print_colored("ğŸ“Š ç›‘æ§æœåŠ¡", Colors.BLUE, bold=True)
            print("  - Prometheus: http://localhost:9090")
            print("  - Grafana: http://localhost:3000")
        
        print()
        print_colored("ç¥æ‚¨å¼€å‘æ„‰å¿«ï¼ğŸš€", Colors.GREEN, bold=True)

def main():
    """ä¸»å‡½æ•°"""
    generator = ScaffoldGenerator()
    generator.run()

if __name__ == "__main__":
    main()
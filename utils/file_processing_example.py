"""
æ–‡ä»¶å¤„ç†ä¼˜åŒ–ä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•åœ¨ç°æœ‰å·¥å…·ä¸­é›†æˆå¢å¼ºçš„æ–‡ä»¶å¤„ç†åŠŸèƒ½
"""

import asyncio
import logging
from typing import Any, Dict, List, Optional, Set

from utils.enhanced_file_processor import get_enhanced_file_processor
from utils.file_processing_integration import OptimizedFileHandler

logger = logging.getLogger(__name__)


class ExampleToolWithOptimizedFiles:
    """
    ç¤ºä¾‹å·¥å…·ï¼šå±•ç¤ºå¦‚ä½•é›†æˆä¼˜åŒ–çš„æ–‡ä»¶å¤„ç†

    è¿™ä¸ªä¾‹å­å±•ç¤ºäº†ç°æœ‰å·¥å…·å¦‚ä½•æ— ç¼å‡çº§åˆ°ä½¿ç”¨ä¼˜åŒ–çš„æ–‡ä»¶å¤„ç†
    """

    def __init__(self, tool_name: str = "example_tool"):
        self.tool_name = tool_name

    async def process_files_traditionally(self, files: List[str], max_tokens: int = 50000) -> str:
        """ä¼ ç»Ÿçš„æ–‡ä»¶å¤„ç†æ–¹å¼ï¼ˆç”¨äºå¯¹æ¯”ï¼‰"""

        from utils.file_utils import read_files

        logger.info(f"[{self.tool_name}] ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•å¤„ç† {len(files)} ä¸ªæ–‡ä»¶")

        # ä¼ ç»Ÿæ–¹æ³•ï¼šåŒæ­¥è¯»å–ï¼Œæ— ç¼“å­˜ï¼Œæ— ä¼˜åŒ–
        content = read_files(files, max_tokens=max_tokens, include_line_numbers=True)

        return content

    async def process_files_optimized(
        self, files: List[str], max_tokens: int = 50000, existing_files: Optional[Set[str]] = None
    ) -> tuple[str, Dict[str, Any]]:
        """ä¼˜åŒ–çš„æ–‡ä»¶å¤„ç†æ–¹å¼"""

        logger.info(f"[{self.tool_name}] ä½¿ç”¨ä¼˜åŒ–æ–¹æ³•å¤„ç† {len(files)} ä¸ªæ–‡ä»¶")

        # ä¼˜åŒ–æ–¹æ³•ï¼šå¼‚æ­¥è¯»å–ï¼Œæ™ºèƒ½ç¼“å­˜ï¼Œæ–‡ä»¶æ‘˜è¦
        content, processed_files, stats = await OptimizedFileHandler.prepare_file_content_optimized(
            request_files=files,
            max_tokens=max_tokens,
            existing_files=existing_files,
            tool_name=self.tool_name,
            include_line_numbers=True,
        )

        return content, stats

    async def demonstrate_optimization_benefits(self, test_files: List[str]):
        """æ¼”ç¤ºä¼˜åŒ–æ•ˆæœ"""

        print(f"\nğŸ§ª {self.tool_name} æ–‡ä»¶å¤„ç†ä¼˜åŒ–æ¼”ç¤º")
        print("=" * 60)

        # æµ‹è¯•ä¼ ç»Ÿæ–¹æ³•
        print("\nğŸ“„ ä¼ ç»Ÿå¤„ç†æ–¹æ³•:")
        traditional_start = asyncio.get_event_loop().time()
        traditional_content = await self.process_files_traditionally(test_files)
        traditional_time = asyncio.get_event_loop().time() - traditional_start

        print(f"   - å¤„ç†æ—¶é—´: {traditional_time:.3f} ç§’")
        print(f"   - å†…å®¹é•¿åº¦: {len(traditional_content):,} å­—ç¬¦")
        print(f"   - æ–‡ä»¶æ•°é‡: {len(test_files)}")

        # æµ‹è¯•ä¼˜åŒ–æ–¹æ³•ï¼ˆé¦–æ¬¡ï¼‰
        print("\nğŸš€ ä¼˜åŒ–å¤„ç†æ–¹æ³•ï¼ˆé¦–æ¬¡ï¼‰:")
        optimized_start = asyncio.get_event_loop().time()
        optimized_content, stats = await self.process_files_optimized(test_files)
        optimized_time = asyncio.get_event_loop().time() - optimized_start

        print(f"   - å¤„ç†æ—¶é—´: {optimized_time:.3f} ç§’")
        print(f"   - å†…å®¹é•¿åº¦: {len(optimized_content):,} å­—ç¬¦")
        print(f"   - å¤„ç†æ–¹æ³•: {stats.get('method', 'unknown')}")
        print(f"   - ç¼“å­˜å‘½ä¸­: {stats.get('cache_hits', 0)}")
        print(f"   - ç¼“å­˜æœªå‘½ä¸­: {stats.get('cache_misses', 0)}")
        print(f"   - æ‘˜è¦æ–‡ä»¶: {stats.get('files_summarized', 0)}")

        # æµ‹è¯•ä¼˜åŒ–æ–¹æ³•ï¼ˆç¬¬äºŒæ¬¡ï¼Œå±•ç¤ºç¼“å­˜æ•ˆæœï¼‰
        print("\nâš¡ ä¼˜åŒ–å¤„ç†æ–¹æ³•ï¼ˆç¬¬äºŒæ¬¡ï¼Œç¼“å­˜æ•ˆæœï¼‰:")
        cached_start = asyncio.get_event_loop().time()
        cached_content, cached_stats = await self.process_files_optimized(test_files)
        cached_time = asyncio.get_event_loop().time() - cached_start

        print(f"   - å¤„ç†æ—¶é—´: {cached_time:.3f} ç§’")
        print(f"   - å†…å®¹é•¿åº¦: {len(cached_content):,} å­—ç¬¦")
        print(f"   - å¤„ç†æ–¹æ³•: {cached_stats.get('method', 'unknown')}")
        print(f"   - ç¼“å­˜å‘½ä¸­: {cached_stats.get('cache_hits', 0)}")
        print(f"   - ç¼“å­˜æœªå‘½ä¸­: {cached_stats.get('cache_misses', 0)}")

        # æ€§èƒ½å¯¹æ¯”
        print("\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
        speed_improvement = (traditional_time - cached_time) / traditional_time * 100
        print(f"   - ä¼ ç»Ÿæ–¹æ³•: {traditional_time:.3f} ç§’")
        print(f"   - ä¼˜åŒ–æ–¹æ³•ï¼ˆé¦–æ¬¡ï¼‰: {optimized_time:.3f} ç§’")
        print(f"   - ä¼˜åŒ–æ–¹æ³•ï¼ˆç¼“å­˜ï¼‰: {cached_time:.3f} ç§’")
        print(f"   - æ€§èƒ½æå‡: {speed_improvement:.1f}%")

        # ç¼“å­˜ç»Ÿè®¡
        processor = get_enhanced_file_processor()
        cache_stats = processor.get_cache_stats()

        print("\nğŸ’¾ ç¼“å­˜çŠ¶æ€:")
        memory_cache = cache_stats["cache_stats"]["memory_cache"]
        print(f"   - å†…å­˜ç¼“å­˜é¡¹: {memory_cache['items']}")
        print(f"   - å†…å­˜ä½¿ç”¨: {memory_cache['size_mb']:.2f} MB / {memory_cache['max_size_mb']} MB")

        disk_cache = cache_stats["cache_stats"]["disk_cache"]
        print(f"   - ç£ç›˜ç¼“å­˜é¡¹: {disk_cache['items']}")
        print(f"   - ç£ç›˜ä½¿ç”¨: {disk_cache['size_mb']:.2f} MB / {disk_cache['max_size_mb']} MB")


async def run_example():
    """è¿è¡Œæ–‡ä»¶å¤„ç†ä¼˜åŒ–ç¤ºä¾‹"""

    # åˆ›å»ºç¤ºä¾‹å·¥å…·
    example_tool = ExampleToolWithOptimizedFiles("file_optimization_demo")

    # ä½¿ç”¨é¡¹ç›®ä¸­çš„å®é™…æ–‡ä»¶è¿›è¡Œæµ‹è¯•
    test_files = [
        "config.py",
        "server.py",
        "utils/file_utils.py",
        "utils/enhanced_file_processor.py",
        "tools/shared/base_tool.py",
    ]

    # è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
    import os

    existing_files = [f for f in test_files if os.path.exists(f)]

    if existing_files:
        await example_tool.demonstrate_optimization_benefits(existing_files)
        print("\nğŸ‰ æ–‡ä»¶å¤„ç†ä¼˜åŒ–æ¼”ç¤ºå®Œæˆï¼")
    else:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶ï¼Œè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤ç¤ºä¾‹")


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.basicConfig(level=logging.INFO)

    # è¿è¡Œç¤ºä¾‹
    asyncio.run(run_example())
